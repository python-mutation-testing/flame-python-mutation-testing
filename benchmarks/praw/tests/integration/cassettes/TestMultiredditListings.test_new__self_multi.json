{
  "http_interactions": [
    {
      "recorded_at": "2016-07-17T15:02:00",
      "request": {
        "body": {
          "encoding": "utf-8",
          "string": "grant_type=password&password=<PASSWORD>&username=<USERNAME>"
        },
        "headers": {
          "Accept": "*/*",
          "Accept-Encoding": "identity",
          "Authorization": "Basic <BASIC_AUTH>",
          "Connection": "keep-alive",
          "Content-Length": "57",
          "Content-Type": "application/x-www-form-urlencoded",
          "User-Agent": "<USER_AGENT> PRAW/4.0.0b9 prawcore/0.0.12"
        },
        "method": "POST",
        "uri": "https://www.reddit.com/api/v1/access_token"
      },
      "response": {
        "body": {
          "encoding": "UTF-8",
          "string": "{\"access_token\": \"z7vTyaXRj3JhdEnRAFd4yLCXpS0\", \"token_type\": \"bearer\", \"expires_in\": 3600, \"scope\": \"*\"}"
        },
        "headers": {
          "CF-RAY": "2c3e928b899a228e-LAX",
          "Connection": "keep-alive",
          "Content-Length": "105",
          "Content-Type": "application/json; charset=UTF-8",
          "Date": "Sun, 17 Jul 2016 15:02:00 GMT",
          "Server": "cloudflare-nginx",
          "Set-Cookie": "__cfduid=db1c9e9a950c554b3e8c4f4ea4eff97311468767720; expires=Mon, 17-Jul-17 15:02:00 GMT; path=/; domain=.reddit.com; HttpOnly",
          "Strict-Transport-Security": "max-age=15552000; includeSubDomains; preload",
          "X-Moose": "majestic",
          "cache-control": "max-age=0, must-revalidate",
          "x-content-type-options": "nosniff",
          "x-frame-options": "SAMEORIGIN",
          "x-xss-protection": "1; mode=block"
        },
        "status": {
          "code": 200,
          "message": "OK"
        },
        "url": "https://www.reddit.com/api/v1/access_token"
      }
    },
    {
      "recorded_at": "2016-07-17T15:02:00",
      "request": {
        "body": {
          "encoding": "utf-8",
          "string": ""
        },
        "headers": {
          "Accept": "*/*",
          "Accept-Encoding": "identity",
          "Authorization": "bearer z7vTyaXRj3JhdEnRAFd4yLCXpS0",
          "Connection": "keep-alive",
          "Cookie": "__cfduid=db1c9e9a950c554b3e8c4f4ea4eff97311468767720; loidcreated=2016-07-17T15%3A02%3A00.296Z; loid=kKIQjymGvEs3i3rMGe",
          "User-Agent": "<USER_AGENT> PRAW/4.0.0b9 prawcore/0.0.12"
        },
        "method": "GET",
        "uri": "https://oauth.reddit.com/api/multi/mine/?raw_json=1"
      },
      "response": {
        "body": {
          "encoding": "UTF-8",
          "string": "[{\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"PRAW Renamed\", \"name\": \"praw_renamed\", \"description_html\": \"\", \"created\": 1432649032.0, \"copied_from\": \"/user/pyapitestuser2/m/praw_z2ggpt0vkr\", \"icon_url\": null, \"subreddits\": [{\"name\": \"redditdev\"}], \"created_utc\": 1432620232.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/praw_renamed\", \"description_md\": \"\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"PRAW_7IJJLETR54\", \"name\": \"praw_zwategsdje\", \"description_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003Ecopied from \\u003Ca href=\\\"/user/<USERNAME>/m/praw_32dm76iiu0\\\"\\u003E/user/<USERNAME>/m/praw_32dm76iiu0\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"created\": 1432647766.0, \"copied_from\": \"/user/<USERNAME>/m/praw_7ijjletr54\", \"icon_url\": null, \"subreddits\": [{\"name\": \"<TEST_SUBREDDIT>\"}], \"created_utc\": 1432618966.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/praw_zwategsdje\", \"description_md\": \"copied from [/user/<USERNAME>/m/praw_32dm76iiu0](/user/<USERNAME>/m/praw_32dm76iiu0)\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"publicempty\", \"name\": \"publicempty\", \"description_html\": \"\", \"created\": 1416450706.0, \"copied_from\": null, \"icon_url\": null, \"subreddits\": [], \"created_utc\": 1416421906.0, \"key_color\": \"#cee3f8\", \"visibility\": \"public\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/publicempty\", \"description_md\": \"\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"PRAW_vyqqgesbgf\", \"name\": \"renamed_2e9nfvc\", \"description_html\": \"\", \"created\": 1432649270.0, \"copied_from\": \"/user/<USERNAME>/m/praw_vyqqgesbgf\", \"icon_url\": null, \"subreddits\": [], \"created_utc\": 1432620470.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/renamed_2e9nfvc\", \"description_md\": \"\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"praw_ivatd8q8uk\", \"name\": \"renamed_6bty6x0\", \"description_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EPRAW_gxgpobcx2q\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"created\": 1432648343.0, \"copied_from\": \"/user/pyapitestuser2/m/praw_ivatd8q8uk\", \"icon_url\": null, \"subreddits\": [], \"created_utc\": 1432619543.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/renamed_6bty6x0\", \"description_md\": \"PRAW_gxgpobcx2q\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"praw_jmbeafjsgb\", \"name\": \"renamed_8usb6x1\", \"description_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EPRAW_qnkboqko2k\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Ecopied from \\u003Ca href=\\\"/user/<USERNAME>/m/praw_otefaapb78\\\"\\u003E/user/<USERNAME>/m/praw_otefaapb78\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"created\": 1432648343.0, \"copied_from\": \"/user/pyapitestuser2/m/praw_jmbeafjsgb\", \"icon_url\": null, \"subreddits\": [], \"created_utc\": 1432619543.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/renamed_8usb6x1\", \"description_md\": \"PRAW_qnkboqko2k\\n\\ncopied from [/user/<USERNAME>/m/praw_otefaapb78](/user/<USERNAME>/m/praw_otefaapb78)\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"renamed_d2xvrt2\", \"name\": \"renamed_d2xvrt2\", \"description_html\": \"\", \"created\": 1432648863.0, \"copied_from\": \"/user/<USERNAME>/m/praw_i5xfu909bv\", \"icon_url\": null, \"subreddits\": [], \"created_utc\": 1432620063.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/renamed_d2xvrt2\", \"description_md\": \"\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"praw_rzcnhcf14r\", \"name\": \"renamed_eylvv7z\", \"description_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EPRAW_i2e1xmlmp8\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"created\": 1432648343.0, \"copied_from\": \"/user/pyapitestuser2/m/praw_rzcnhcf14r\", \"icon_url\": null, \"subreddits\": [], \"created_utc\": 1432619543.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/renamed_eylvv7z\", \"description_md\": \"PRAW_i2e1xmlmp8\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"PRAW_a01plsdh6k\", \"name\": \"renamed_mne1m9w\", \"description_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EBLAH\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Ecopied from \\u003Ca href=\\\"/user/<USERNAME>/m/praw_32dm76iiu0\\\"\\u003E/user/<USERNAME>/m/praw_32dm76iiu0\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"created\": 1432647766.0, \"copied_from\": \"/user/<USERNAME>/m/praw_a01plsdh6k\", \"icon_url\": null, \"subreddits\": [{\"name\": \"<TEST_SUBREDDIT>\"}], \"created_utc\": 1432618966.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/renamed_mne1m9w\", \"description_md\": \"BLAH\\n\\ncopied from [/user/<USERNAME>/m/praw_32dm76iiu0](/user/<USERNAME>/m/praw_32dm76iiu0)\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"praw_48e2k784z0\", \"name\": \"renamed_o71kopk\", \"description_html\": \"\", \"created\": 1432648527.0, \"copied_from\": \"/user/<USERNAME>/m/praw_ln88ua1fd6\", \"icon_url\": null, \"subreddits\": [], \"created_utc\": 1432619727.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/renamed_o71kopk\", \"description_md\": \"\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"praw_otefaapb78\", \"name\": \"renamed_p93yyel\", \"description_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EPRAW_kifa24b018\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"created\": 1432648343.0, \"copied_from\": \"/user/pyapitestuser2/m/praw_otefaapb78\", \"icon_url\": null, \"subreddits\": [{\"name\": \"<TEST_SUBREDDIT>\"}], \"created_utc\": 1432619543.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/renamed_p93yyel\", \"description_md\": \"PRAW_kifa24b018\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"PRAW_hrgjtlofk9\", \"name\": \"renamed_ppil2bq\", \"description_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EPRAW_xd2vmw4py7\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"created\": 1432647766.0, \"copied_from\": \"/user/<USERNAME>/m/praw_hrgjtlofk9\", \"icon_url\": null, \"subreddits\": [{\"name\": \"<TEST_SUBREDDIT>\"}], \"created_utc\": 1432618966.0, \"key_color\": \"#cee3f8\", \"visibility\": \"public\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/renamed_ppil2bq\", \"description_md\": \"PRAW_xd2vmw4py7\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"PRAW_7gcyw6pl0d\", \"name\": \"renamed_rwgn0us\", \"description_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003Ecopied from \\u003Ca href=\\\"/user/<USERNAME>/m/praw_32dm76iiu0\\\"\\u003E/user/<USERNAME>/m/praw_32dm76iiu0\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"created\": 1432647766.0, \"copied_from\": \"/user/<USERNAME>/m/praw_ky972wv5uk\", \"icon_url\": null, \"subreddits\": [{\"name\": \"<TEST_SUBREDDIT>\"}], \"created_utc\": 1432618966.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/renamed_rwgn0us\", \"description_md\": \"copied from [/user/<USERNAME>/m/praw_32dm76iiu0](/user/<USERNAME>/m/praw_32dm76iiu0)\"}}, {\"kind\": \"LabeledMulti\", \"data\": {\"can_edit\": true, \"display_name\": \"tmp\", \"name\": \"tmp\", \"description_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003Ecopied from \\u003Ca href=\\\"/user/<USERNAME>/m/publicempty\\\"\\u003E/user/<USERNAME>/m/publicempty\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"created\": 1416450706.0, \"copied_from\": \"/user/<USERNAME>/m/publicempty\", \"icon_url\": null, \"subreddits\": [], \"created_utc\": 1416421906.0, \"key_color\": \"#cee3f8\", \"visibility\": \"private\", \"icon_name\": \"\", \"weighting_scheme\": \"classic\", \"path\": \"/user/<USERNAME>/m/tmp\", \"description_md\": \"copied from [/user/<USERNAME>/m/publicempty](/user/<USERNAME>/m/publicempty)\"}}]"
        },
        "headers": {
          "CF-RAY": "2c3e928f49a60673-LAX",
          "Connection": "keep-alive",
          "Content-Type": "application/json; charset=UTF-8",
          "Date": "Sun, 17 Jul 2016 15:02:00 GMT",
          "Server": "cloudflare-nginx",
          "Strict-Transport-Security": "max-age=15552000; includeSubDomains; preload",
          "Transfer-Encoding": "chunked",
          "Vary": "accept-encoding",
          "X-Moose": "majestic",
          "cache-control": "private, s-maxage=0, max-age=0, must-revalidate",
          "expires": "-1",
          "x-content-type-options": "nosniff",
          "x-frame-options": "SAMEORIGIN",
          "x-ratelimit-remaining": "599.0",
          "x-ratelimit-reset": "480",
          "x-ratelimit-used": "1",
          "x-reddit-tracking": "https://pixel.redditmedia.com/pixel/of_destiny.png?v=RHhQo6Jx4WaR6vZfkJuNU8ztCMBp0LfTWVJGwPs%2B3xhE6b%2FZDtUKcutoOsNR4kevDp8BxfALFUhJ9Ctnfa%2Bk7yJ3kSdicXb7",
          "x-ua-compatible": "IE=edge",
          "x-xss-protection": "1; mode=block"
        },
        "status": {
          "code": 200,
          "message": "OK"
        },
        "url": "https://oauth.reddit.com/api/multi/mine/?raw_json=1"
      }
    },
    {
      "recorded_at": "2016-07-17T15:02:02",
      "request": {
        "body": {
          "encoding": "utf-8",
          "string": ""
        },
        "headers": {
          "Accept": "*/*",
          "Accept-Encoding": "identity",
          "Authorization": "bearer z7vTyaXRj3JhdEnRAFd4yLCXpS0",
          "Connection": "keep-alive",
          "Cookie": "__cfduid=db1c9e9a950c554b3e8c4f4ea4eff97311468767720; loidcreated=2016-07-17T15%3A02%3A00.296Z; loid=kKIQjymGvEs3i3rMGe",
          "User-Agent": "<USER_AGENT> PRAW/4.0.0b9 prawcore/0.0.12"
        },
        "method": "GET",
        "uri": "https://oauth.reddit.com/user/<USERNAME>/m/praw_renamed/new?raw_json=1&limit=100"
      },
      "response": {
        "body": {
          "encoding": "UTF-8",
          "string": "{\"kind\": \"Listing\", \"data\": {\"modhash\": null, \"children\": [{\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi Everyone, \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;ve been playing with the APIs for a few hours but I couldn\\u0026#39;t find any way to get the list of up and down votes on a post or a comment... \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EIs it possible to get this info somehow? \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi Everyone, \\n\\nI've been playing with the APIs for a few hours but I couldn't find any way to get the list of up and down votes on a post or a comment... \\n\\nIs it possible to get this info somehow? \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4t9ut3\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"dwarfy\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": true, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4t9ut3/getting_a_list_of_votes/\", \"locked\": false, \"name\": \"t3_4t9ut3\", \"created\": 1468794792.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4t9ut3/getting_a_list_of_votes/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Getting a list of votes\", \"created_utc\": 1468765992.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": null, \"selftext\": \"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4t7ayy\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"theo65_theo01\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4t7ayy/whats_the_best_nodejs_api_wrapper/\", \"locked\": false, \"name\": \"t3_4t7ayy\", \"created\": 1468744134.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4t7ayy/whats_the_best_nodejs_api_wrapper/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Whats the best Node.js api wrapper?\", \"created_utc\": 1468715334.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cpre\\u003E\\u003Ccode\\u003Emod_mail = subreddit.get_mod_mail()\\nfor each_mail in mod_mail:\\n    print each_mail.parent_id\\n    print each_mail.first_message_name\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EBoth \\u003Ccode\\u003Eparent_id\\u003C/code\\u003E and \\u003Ccode\\u003Efirst_message_name\\u003C/code\\u003E return \\u003Ccode\\u003ENone\\u003C/code\\u003E, but when I load \\u003Ccode\\u003Ehttps://www.reddit.com/message/messages/\\u0026lt;message_id\\u0026gt;.json\\u003C/code\\u003Ein a browser, I can see both attributes display the actual attributes. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHow can I get around this? Ideally I can just add an argument to \\u003Ccode\\u003Eget_mod_mail()\\u003C/code\\u003E to pull more complete data. Do I need to use \\u003Ccode\\u003Erequest_json()\\u003C/code\\u003E? I keep getting \\u003Ccode\\u003EForbidden\\u003C/code\\u003E errors when I try that. \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"    mod_mail = subreddit.get_mod_mail()\\n    for each_mail in mod_mail:\\n        print each_mail.parent_id\\n        print each_mail.first_message_name\\n\\n\\nBoth `parent_id` and `first_message_name` return `None`, but when I load `https://www.reddit.com/message/messages/\\u003Cmessage_id\\u003E.json`in a browser, I can see both attributes display the actual attributes. \\n\\nHow can I get around this? Ideally I can just add an argument to `get_mod_mail()` to pull more complete data. Do I need to use `request_json()`? I keep getting `Forbidden` errors when I try that. \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4t4ape\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"j33perscr33pers\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4t4ape/get_mod_mail_returns_parent_id_as_none_but/\", \"locked\": false, \"name\": \"t3_4t4ape\", \"created\": 1468699686.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4t4ape/get_mod_mail_returns_parent_id_as_none_but/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"get_mod_mail() returns .parent_id as 'None', but appending .json to the URL in browser shows correct .parent_id\", \"created_utc\": 1468670886.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHere is the code I\\u0026#39;m using. The issue is when I call this method once, it returns the body of the first comment it gets, deletes it, and its done. Which is working as intended. However if I call this function multiple times consecutively it will return the same comment twice, and only delete one comment (the one it deleted the first time). I think it has something to do with the thread not updating, but I\\u0026#39;ve tried setting the thread to None each time, and trying it that way. Still getting the same behavior. Any ideas as to what I\\u0026#39;m missing? Do I need to do anything special after deleting a comment in a thread? \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Edef remove_some_comment:\\n    r = praw.Reddit(some_agent)\\n    r.login(username, password, disable_warning=True)\\n    thread = r.get_submission(submission_id=some_id)\\n\\n\\n    for comment in thread.comments:\\n        if comment.is_root:            \\n            return_comment  = comment.body\\n            comment.delete()\\n            return return_comment  \\n\\n\\nprint(remove_some_comment())\\n\\u0026gt;\\u0026gt;\\u0026gt; First Comment In Thread\\nprint(remove_some_comment())\\n\\u0026gt;\\u0026gt;\\u0026gt; First Comment In Thread\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Here is the code I'm using. The issue is when I call this method once, it returns the body of the first comment it gets, deletes it, and its done. Which is working as intended. However if I call this function multiple times consecutively it will return the same comment twice, and only delete one comment (the one it deleted the first time). I think it has something to do with the thread not updating, but I've tried setting the thread to None each time, and trying it that way. Still getting the same behavior. Any ideas as to what I'm missing? Do I need to do anything special after deleting a comment in a thread? \\n\\n    def remove_some_comment:\\n        r = praw.Reddit(some_agent)\\n        r.login(username, password, disable_warning=True)\\n        thread = r.get_submission(submission_id=some_id)\\n\\n\\n        for comment in thread.comments:\\n            if comment.is_root:            \\n                return_comment  = comment.body\\n                comment.delete()\\n                return return_comment  \\n\\n\\n    print(remove_some_comment())\\n    \\u003E\\u003E\\u003E First Comment In Thread\\n    print(remove_some_comment())\\n    \\u003E\\u003E\\u003E First Comment In Thread\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4t33rn\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"HelioOne\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1468644083.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4t33rn/issue_with_deleting_a_comment_in_submission/\", \"locked\": false, \"name\": \"t3_4t33rn\", \"created\": 1468672484.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4t33rn/issue_with_deleting_a_comment_in_submission/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Issue with deleting a comment in submission\", \"created_utc\": 1468643684.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo this is part of a reddit bot that I\\u0026#39;m writing so I\\u0026#39;m not quite sure where else to ask it, although what I\\u0026#39;m asking does not relate directly to the reddit API. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003ERight now my code has a function that queries amazon for a product with a search term. I\\u0026#39;m having trouble determining what to return. The problem I\\u0026#39;m trying to solve is when we search on amazon, the first item that pops up isn\\u0026#39;t always the one we want. For example, if we search of a chromecast on amazon it will return a fire stick because amazon does not sell chromecasts. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m trying to use python\\u0026#39;s difflib to no avail as so:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Etry:\\n    products = amazon.search_n(20, Keywords=item, SearchIndex=\\u0026#39;All\\u0026#39;) #pulls the top 20 results from amazon based on item\\n    titles = [product.title for product in products]\\n    matches = difflib.get_close_matches(item, titles)\\n    if len(matches) \\u0026gt; 0:\\n        return next(product for product in products if product.title == matches[0]) #tries to pull out the \\u0026#39;best\\u0026#39; match\\n    else:\\n        return None\\nexcept AmazonException:\\n    return None    \\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EIf any of you have recommendations on how I might solve this that would be awesome! It essentially boils down to how do I determine what amazon returns is actually what the user queried for?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So this is part of a reddit bot that I'm writing so I'm not quite sure where else to ask it, although what I'm asking does not relate directly to the reddit API. \\n\\nRight now my code has a function that queries amazon for a product with a search term. I'm having trouble determining what to return. The problem I'm trying to solve is when we search on amazon, the first item that pops up isn't always the one we want. For example, if we search of a chromecast on amazon it will return a fire stick because amazon does not sell chromecasts. \\n\\nI'm trying to use python's difflib to no avail as so:\\n\\n    try:\\n        products = amazon.search_n(20, Keywords=item, SearchIndex='All') #pulls the top 20 results from amazon based on item\\n        titles = [product.title for product in products]\\n        matches = difflib.get_close_matches(item, titles)\\n        if len(matches) \\u003E 0:\\n            return next(product for product in products if product.title == matches[0]) #tries to pull out the 'best' match\\n        else:\\n            return None\\n    except AmazonException:\\n        return None    \\n\\n\\nIf any of you have recommendations on how I might solve this that would be awesome! It essentially boils down to how do I determine what amazon returns is actually what the user queried for?\\n\\nThanks\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4t2sre\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"KmatthewC\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1468638395.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4t2sre/make_sure_im_returning_a_product_that_a_user/\", \"locked\": false, \"name\": \"t3_4t2sre\", \"created\": 1468666979.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4t2sre/make_sure_im_returning_a_product_that_a_user/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Make sure I'm returning a product that a user actually queried for?\", \"created_utc\": 1468638179.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIf you \\u003Ca href=\\\"/r/redditdev/comments/4t06bn/redditmobile_bug_report_broken_dependencies/\\\"\\u003Ecan\\u0026#39;t\\u003C/a\\u003E or don\\u0026#39;t want to use the new \\u003Ca href=\\\"https://github.com/reddit/reddit-mobile#reddit-mobile\\\"\\u003E\\u003Ccode\\u003Ereddit-mobile\\u003C/code\\u003E\\u003C/a\\u003E plugin for mobile support, there is (for now, at least) still the legacy mobile front-end that, conventionally, is accessed by \\u003Ccode\\u003Ehttps://i.domain.com\\u003C/code\\u003E.  Unless you have a wildcard certificate, though, chances are that URL will throw an invalid SSL certificate when clients try to connect to it.  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EFortunately, you can emulate the same behaviour by appending \\u003Ccode\\u003E.compact\\u003C/code\\u003E to reddit URLs.  Nothing special is required for this to work, but it\\u0026#39;s not very user-friendly.  To make things simpler for mobile users, the following patch does two things:\\u003C/p\\u003E\\n\\n\\u003Cul\\u003E\\n\\u003Cli\\u003Echanges the \\u0026#39;SWITCH TO MOBILE VERSION\\u0026#39; button (shown by the desktop version when a mobile UA is detected) to point to the \\u003Ccode\\u003E.compact\\u003C/code\\u003E URL at the primary domain rather than \\u003Ccode\\u003Em.domain.com\\u003C/code\\u003E (or \\u003Ccode\\u003Ei.domain.com\\u003C/code\\u003E), and\\u003C/li\\u003E\\n\\u003Cli\\u003Edisables the invitation to \\u003Ccode\\u003Em.domain.com\\u003C/code\\u003E (the reddit-mobile interface) when in the compact renderstyle.\\u003C/li\\u003E\\n\\u003C/ul\\u003E\\n\\n\\u003Cp\\u003EYou might also consider adding an nginx vhost for \\u003Ccode\\u003Em.domain.com\\u003C/code\\u003E and \\u003Ccode\\u003Ei.domain.com\\u003C/code\\u003E to redirect to \\u003Ccode\\u003Ehttps://domain.com/.compact\\u003C/code\\u003E.  Trying to do anything fancier will sometimes break and still won\\u0026#39;t work for https://.\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Ediff --git a/r2/r2/public/static/js/compact.js b/r2/r2/public/static/js/compact.js\\nindex 6868092..9df348c 100644\\n--- a/r2/r2/public/static/js/compact.js\\n+++ b/r2/r2/public/static/js/compact.js\\n@@ -155,6 +155,8 @@ function fetch_more() {\\n }\\n\\n $(function() {\\n+    // Disable invitation to reddit-mobile extension for now.\\n+    return;\\n     if (!!store.safeGet(\\u0026#39;mobile-web-redirect-opted\\u0026#39;)) {\\n         return;\\n     }\\ndiff --git a/r2/r2/public/static/js/ui.js b/r2/r2/public/static/js/ui.js\\nindex 7f282e7..c47c50a 100644\\n--- a/r2/r2/public/static/js/ui.js\\n+++ b/r2/r2/public/static/js/ui.js\\n@@ -17,7 +17,10 @@ r.ui.init = function() {\\n     if (smallScreen \\u0026amp;\\u0026amp; onFrontPage \\u0026amp;\\u0026amp; r.config.renderstyle != \\u0026#39;compact\\u0026#39; \\u0026amp;\\u0026amp; !r.ui.inMobileWebBlacklist()) {\\n         var a = document.createElement(\\u0026#39;a\\u0026#39;);\\n         a.href = window.location;\\n-        a.host = \\u0026#39;m.\\u0026#39; + r.config.cur_domain;\\n+        // Don\\u0026#39;t change hosts (because of SSL);\\n+        //a.host = \\u0026#39;m.\\u0026#39; + r.config.cur_domain;\\n+        // instead, append .compact renderstyle\\n+        a.pathname += \\u0026#39;.compact\\u0026#39;;\\n         a.search += (a.search ? \\u0026#39;\\u0026amp;\\u0026#39; : \\u0026#39;?\\u0026#39;) + \\u0026#39;ref=mobile_beta_banner\\u0026amp;ref_source=desktop\\u0026#39;\\n         var url = a.href;\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"If you [can't](/r/redditdev/comments/4t06bn/redditmobile_bug_report_broken_dependencies/) or don't want to use the new [`reddit-mobile`](https://github.com/reddit/reddit-mobile#reddit-mobile) plugin for mobile support, there is (for now, at least) still the legacy mobile front-end that, conventionally, is accessed by `https://i.domain.com`.  Unless you have a wildcard certificate, though, chances are that URL will throw an invalid SSL certificate when clients try to connect to it.  \\n\\nFortunately, you can emulate the same behaviour by appending `.compact` to reddit URLs.  Nothing special is required for this to work, but it's not very user-friendly.  To make things simpler for mobile users, the following patch does two things:\\n\\n* changes the 'SWITCH TO MOBILE VERSION' button (shown by the desktop version when a mobile UA is detected) to point to the `.compact` URL at the primary domain rather than `m.domain.com` (or `i.domain.com`), and\\n* disables the invitation to `m.domain.com` (the reddit-mobile interface) when in the compact renderstyle.\\n\\nYou might also consider adding an nginx vhost for `m.domain.com` and `i.domain.com` to redirect to `https://domain.com/.compact`.  Trying to do anything fancier will sometimes break and still won't work for https://.\\n\\n    diff --git a/r2/r2/public/static/js/compact.js b/r2/r2/public/static/js/compact.js\\n    index 6868092..9df348c 100644\\n    --- a/r2/r2/public/static/js/compact.js\\n    +++ b/r2/r2/public/static/js/compact.js\\n    @@ -155,6 +155,8 @@ function fetch_more() {\\n     }\\n\\n     $(function() {\\n    +    // Disable invitation to reddit-mobile extension for now.\\n    +    return;\\n         if (!!store.safeGet('mobile-web-redirect-opted')) {\\n             return;\\n         }\\n    diff --git a/r2/r2/public/static/js/ui.js b/r2/r2/public/static/js/ui.js\\n    index 7f282e7..c47c50a 100644\\n    --- a/r2/r2/public/static/js/ui.js\\n    +++ b/r2/r2/public/static/js/ui.js\\n    @@ -17,7 +17,10 @@ r.ui.init = function() {\\n         if (smallScreen \\u0026\\u0026 onFrontPage \\u0026\\u0026 r.config.renderstyle != 'compact' \\u0026\\u0026 !r.ui.inMobileWebBlacklist()) {\\n             var a = document.createElement('a');\\n             a.href = window.location;\\n    -        a.host = 'm.' + r.config.cur_domain;\\n    +        // Don't change hosts (because of SSL);\\n    +        //a.host = 'm.' + r.config.cur_domain;\\n    +        // instead, append .compact renderstyle\\n    +        a.pathname += '.compact';\\n             a.search += (a.search ? '\\u0026' : '?') + 'ref=mobile_beta_banner\\u0026ref_source=desktop'\\n             var url = a.href;\\n\\n\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4t12st\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"StrixTechnica\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4t12st/howto_use_the_legacy_mobile_frontend_without/\", \"locked\": false, \"name\": \"t3_4t12st\", \"created\": 1468642177.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4t12st/howto_use_the_legacy_mobile_frontend_without/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"HOWTO: Use the legacy mobile front-end without subdomains\", \"created_utc\": 1468613377.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ECurrently with oauth2 the json api is \\u003Ca href=\\\"https://github.com/reddit/reddit/blob/master/r2/r2/controllers/reddit_base.py#L1126\\\"\\u003Eforced\\u003C/a\\u003E. However, this is counterintuitive for web apps, such as those that would be able to make use of .embed / .json-html / .json-compact (both with and without a callback). Any chance that can be changed / what\\u0026#39;s the reason against it?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Currently with oauth2 the json api is [forced](https://github.com/reddit/reddit/blob/master/r2/r2/controllers/reddit_base.py#L1126). However, this is counterintuitive for web apps, such as those that would be able to make use of .embed / .json-html / .json-compact (both with and without a callback). Any chance that can be changed / what's the reason against it?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4t0ibn\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"13steinj\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4t0ibn/request_allow_jsonhtml_jsoncompact_and_embed/\", \"locked\": false, \"name\": \"t3_4t0ibn\", \"created\": 1468635430.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4t0ibn/request_allow_jsonhtml_jsoncompact_and_embed/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Request: allow json-html, json-compact, and embed extensions with the oauth api\", \"created_utc\": 1468606630.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EThe plugin \\u003Ccode\\u003Ereddit-mobile\\u003C/code\\u003E cannot be installed on a stock Ubuntu 14.04 server on which reddit has been installed using the installer script because the \\u003Ca href=\\\"https://github.com/reddit/reddit-mobile#getting-up-and-running\\\"\\u003Ereddit-mobile \\u0026#39;Getting up and running\\u0026#39; instructions\\u003C/a\\u003E are impossible to follow as things currently stand.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe problem begins with the first line:\\u003C/p\\u003E\\n\\n\\u003Cblockquote\\u003E\\n\\u003Cp\\u003EInstall node.js v4.2 and npm 3.5\\u003C/p\\u003E\\n\\u003C/blockquote\\u003E\\n\\n\\u003Cp\\u003Enodejs version \\u003Ccode\\u003E4.1.2-1reddit1~trusty1\\u003C/code\\u003E is installed from \\u003Ccode\\u003Eppa:reddit/ppa\\u003C/code\\u003E by \\u003Ccode\\u003Einstall/install_apt.sh\\u003C/code\\u003E.  There are two problems:\\u003C/p\\u003E\\n\\n\\u003Col\\u003E\\n\\u003Cli\\u003E The PPA nodjes stipulates \\u003Ccode\\u003Enpm (\\u0026lt;= 1.2.14)\\u003C/code\\u003E but, according to my apt-cache, the current version of npm is \\u003Ccode\\u003E1.3.10~dfsg-1\\u003C/code\\u003E and 1.2.14 doesn\\u0026#39;t appear to be in the Ubuntu repo (or else it\\u0026#39;s just missing from my mirror), so npm won\\u0026#39;t install, and\\u003C/li\\u003E\\n\\u003Cli\\u003E Regardless of whether I could find npm 1.2.14, the PPA nodejs is apparently older than the version required by \\u003Ccode\\u003Ereddit-mobile\\u003C/code\\u003E.\\u003C/li\\u003E\\n\\u003C/ol\\u003E\\n\\n\\u003Cp\\u003ESo: things are a little broken at the moment.  I gather that production reddit doesn\\u0026#39;t use that PPA, so presumably it must be using a more recent nodejs from somewhere else.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECould somebody from reddit please publish a nodejs 4.2 PPA, or otherwise indicate a source of a nodejs that resolves these dependency problems?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"The plugin `reddit-mobile` cannot be installed on a stock Ubuntu 14.04 server on which reddit has been installed using the installer script because the [reddit-mobile 'Getting up and running' instructions](https://github.com/reddit/reddit-mobile#getting-up-and-running) are impossible to follow as things currently stand.\\n\\nThe problem begins with the first line:\\n\\n\\u003E Install node.js v4.2 and npm 3.5\\n\\nnodejs version `4.1.2-1reddit1~trusty1` is installed from `ppa:reddit/ppa` by `install/install_apt.sh`.  There are two problems:\\n\\n1.  The PPA nodjes stipulates `npm (\\u003C= 1.2.14)` but, according to my apt-cache, the current version of npm is `1.3.10~dfsg-1` and 1.2.14 doesn't appear to be in the Ubuntu repo (or else it's just missing from my mirror), so npm won't install, and\\n2.  Regardless of whether I could find npm 1.2.14, the PPA nodejs is apparently older than the version required by `reddit-mobile`.\\n\\nSo: things are a little broken at the moment.  I gather that production reddit doesn't use that PPA, so presumably it must be using a more recent nodejs from somewhere else.\\n\\nCould somebody from reddit please publish a nodejs 4.2 PPA, or otherwise indicate a source of a nodejs that resolves these dependency problems?\\n\\nThanks.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4t06bn\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"StrixTechnica\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1468603093.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4t06bn/redditmobile_bug_report_broken_dependencies/\", \"locked\": false, \"name\": \"t3_4t06bn\", \"created\": 1468631534.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4t06bn/redditmobile_bug_report_broken_dependencies/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[reddit-mobile] \\\"Bug\\\" report: Broken dependencies\", \"created_utc\": 1468602734.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ERight now I\\u0026#39;m on a Windows environment and have a number of Python modules/packages and everything is working just fine locally.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhat is my next step to get everything packaged up and able to run on a remote EC2 instance? Does Python have something like the equivalent of a Java Jar that I can bundle everything up into or how does that work?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe bot will run and check stuff constantly with a \\u003Ccode\\u003Ewhile True\\u003C/code\\u003E loop if that changes anything. I\\u0026#39;m also using PRAW so I\\u0026#39;ll have to make sure I get all the correct modules installed on the instance.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Right now I'm on a Windows environment and have a number of Python modules/packages and everything is working just fine locally.\\n\\nWhat is my next step to get everything packaged up and able to run on a remote EC2 instance? Does Python have something like the equivalent of a Java Jar that I can bundle everything up into or how does that work?\\n\\nThe bot will run and check stuff constantly with a `while True` loop if that changes anything. I'm also using PRAW so I'll have to make sure I get all the correct modules installed on the instance.\\n\\nThanks!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4szkrk\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"hinayu\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 6, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1468596141.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4szkrk/packaging_up_python_bot_to_run_remotely/\", \"locked\": false, \"name\": \"t3_4szkrk\", \"created\": 1468624560.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4szkrk/packaging_up_python_bot_to_run_remotely/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Packaging up Python bot to run remotely\", \"created_utc\": 1468595760.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi, I want to compare the active userbase of different subreddits for which I would like to retrieve all the authors of all threads and all comments ever made with respective timestamps. I am struggeling to achieve this since with PRAW 4.0 since all the documentation I can find only deals with a previous version. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHow would I go about achieving this?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi, I want to compare the active userbase of different subreddits for which I would like to retrieve all the authors of all threads and all comments ever made with respective timestamps. I am struggeling to achieve this since with PRAW 4.0 since all the documentation I can find only deals with a previous version. \\n\\nHow would I go about achieving this?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4szgnw\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"kimjongok\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4szgnw/praw400b8_help_getting_authors_of_all_threads/\", \"locked\": false, \"name\": \"t3_4szgnw\", \"created\": 1468623173.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4szgnw/praw400b8_help_getting_authors_of_all_threads/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"PRAW[4.0.0b8]: Help getting authors of all threads ever made in a subreddit.\", \"created_utc\": 1468594373.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;ve searched through the posts and can\\u0026#39;t get my head around why the response json is so large.  I am creating an app for a popular subreddit.  I\\u0026#39;ve noticed to get the front page, the data can be up to 1 mb, so while looking at the json, i can see that selftext is duplicated, once with escaped chars and once without.  Why? why not have one escaped and let the developer handle it.  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHere is what i want to figure out is how to get the title of a post, how to retrieve the selftext and paginate back and forth.  Is there a way to do this?  I can\\u0026#39;t find anything in the search so hoping someone can explain why the response json is the way it is.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ETbh my biggest concern is that amount of data and the effect it will have an people who don\\u0026#39;t have unlimited data plans on their mobiles :(\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EPS: Any pointers to which documents i should be reading would be much appreciated!\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi,\\n\\nI've searched through the posts and can't get my head around why the response json is so large.  I am creating an app for a popular subreddit.  I've noticed to get the front page, the data can be up to 1 mb, so while looking at the json, i can see that selftext is duplicated, once with escaped chars and once without.  Why? why not have one escaped and let the developer handle it.  \\n\\nHere is what i want to figure out is how to get the title of a post, how to retrieve the selftext and paginate back and forth.  Is there a way to do this?  I can't find anything in the search so hoping someone can explain why the response json is the way it is.\\n\\nTbh my biggest concern is that amount of data and the effect it will have an people who don't have unlimited data plans on their mobiles :(\\n\\nPS: Any pointers to which documents i should be reading would be much appreciated!\\n\\nThanks\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4sy1tm\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Steedsofwar\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4sy1tm/why_is_the_response_json_the_way_it_is/\", \"locked\": false, \"name\": \"t3_4sy1tm\", \"created\": 1468597682.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4sy1tm/why_is_the_response_json_the_way_it_is/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Why is the response json the way it is?\", \"created_utc\": 1468568882.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI like to know all the user\\u0026#39;s username who are up-voted to a post. Is it possible to find out that using praw ?  \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I like to know all the user's username who are up-voted to a post. Is it possible to find out that using praw ?  \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4sxlcd\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"asony111\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4sxlcd/how_to_get_all_the_upvoters_of_a_post/\", \"locked\": false, \"name\": \"t3_4sxlcd\", \"created\": 1468588242.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4sxlcd/how_to_get_all_the_upvoters_of_a_post/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How to get all the up-voters of a post ?\", \"created_utc\": 1468559442.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIs there a way to do this? The documentation doesn\\u0026#39;t show what type of kwargs I would use. I was assuming it was something like:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Efor item in subreddit.get_mod_que(limit=None, **{\\u0026#39;only\\u0026#39;:\\u0026#39;comments\\u0026#39;}):\\n#  blah\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Ebut that\\u0026#39;s not working. Can\\u0026#39;t find any examples anywhere.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Is there a way to do this? The documentation doesn't show what type of kwargs I would use. I was assuming it was something like:\\n\\n    for item in subreddit.get_mod_que(limit=None, **{'only':'comments'}):\\n    #  blah\\n\\nbut that's not working. Can't find any examples anywhere.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4sx03g\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"exoendo\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4sx03g/how_to_get_only_comments_from_the_modqueue/\", \"locked\": false, \"name\": \"t3_4sx03g\", \"created\": 1468578269.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4sx03g/how_to_get_only_comments_from_the_modqueue/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How to get only comments from the modqueue?\", \"created_utc\": 1468549469.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m trying to sort my comments (retrieved using get_comments) by the time of their votes, whether up or down. I can get the comments using get_comment_replies, where one element has an upvote, downvote instance; but these are for upvoting and downvoting posts, when what I\\u0026#39;d like is merely their current scores. \\u003Ca href=\\\"https://np.reddit.com/r/redditdev/comments/29i58s/reddit_change_api_availability_controversiality/\\\"\\u003EAn older post\\u003C/a\\u003E suggests there is a score attribute, which seems to have gone missing, isn\\u0026#39;t available on every comment, or isn\\u0026#39;t praw-accessible. So what gives here? My code follows:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Eimport argparse\\nfrom collections import defaultdict\\nimport datetime\\nimport logging\\n\\nimport praw\\n\\n\\nDEFAULT_SCORE = 1\\n\\nif __name__ == \\u0026#39;__main__\\u0026#39;:\\n    scores = defaultdict(lambda: DEFAULT_SCORE)\\n    start = long(datetime.datetime.now().strftime(\\u0026#39;%s\\u0026#39;))\\n    logging.basicConfig(level=logging.DEBUG)\\n    r = praw.Reddit(\\u0026#39;Comment Score update reporter by u/cruyff8\\u0026#39;)\\n    args = argparse.ArgumentParser(description=\\u0026#39;Find out which of your comments were most recently up/down voted\\u0026#39;)\\n    args.add_argument(\\u0026#39;user\\u0026#39;, default=\\u0026#39;cruyff8\\u0026#39;, type=str, action=\\u0026#39;store\\u0026#39;)\\n    args.add_argument(\\u0026#39;password\\u0026#39;, type=str, action=\\u0026#39;store\\u0026#39;)\\n    parsed = args.parse_args()\\n\\n    r.login(parsed.user, parsed.password, disable_warning=True)\\n    logging.info(\\u0026#39;Logged in\\u0026#39;)\\n    while True:\\n        comments = [c for c in r.get_comment_replies()]\\n        changed = []\\n        for c in comments:\\n            logging.debug(sorted(dir(c)))\\n            score = c.score\\n            if scores[c.id] != score and c.id in scores:\\n                changed.append(c)\\n            scores[c.id] = c.score\\n\\n    runtime = time.time()-start\\n    if changed:\\n        print \\u0026#39;Newly voted comment bodies\\u0026#39;\\n    print [\\u0026#39;{0}\\\\n-------------------------------------------------------------------------------------------------\\\\n\\u0026#39;.format(c.body) for c in changed]\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm trying to sort my comments (retrieved using get_comments) by the time of their votes, whether up or down. I can get the comments using get_comment_replies, where one element has an upvote, downvote instance; but these are for upvoting and downvoting posts, when what I'd like is merely their current scores. [An older post](https://np.reddit.com/r/redditdev/comments/29i58s/reddit_change_api_availability_controversiality/) suggests there is a score attribute, which seems to have gone missing, isn't available on every comment, or isn't praw-accessible. So what gives here? My code follows:\\n    \\n    import argparse\\n    from collections import defaultdict\\n    import datetime\\n    import logging\\n    \\n    import praw\\n    \\n    \\n    DEFAULT_SCORE = 1\\n    \\n    if __name__ == '__main__':\\n        scores = defaultdict(lambda: DEFAULT_SCORE)\\n        start = long(datetime.datetime.now().strftime('%s'))\\n        logging.basicConfig(level=logging.DEBUG)\\n        r = praw.Reddit('Comment Score update reporter by u/cruyff8')\\n        args = argparse.ArgumentParser(description='Find out which of your comments were most recently up/down voted')\\n        args.add_argument('user', default='cruyff8', type=str, action='store')\\n        args.add_argument('password', type=str, action='store')\\n        parsed = args.parse_args()\\n    \\n        r.login(parsed.user, parsed.password, disable_warning=True)\\n        logging.info('Logged in')\\n        while True:\\n            comments = [c for c in r.get_comment_replies()]\\n            changed = []\\n            for c in comments:\\n                logging.debug(sorted(dir(c)))\\n                score = c.score\\n                if scores[c.id] != score and c.id in scores:\\n                    changed.append(c)\\n                scores[c.id] = c.score\\n    \\n        runtime = time.time()-start\\n        if changed:\\n            print 'Newly voted comment bodies'\\n        print ['{0}\\\\n-------------------------------------------------------------------------------------------------\\\\n'.format(c.body) for c in changed]\\n    \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4swcp7\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"cruyff8\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4swcp7/how_to_determine_which_commentslinks_were_voted/\", \"locked\": false, \"name\": \"t3_4swcp7\", \"created\": 1468568667.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4swcp7/how_to_determine_which_commentslinks_were_voted/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How to Determine which Comments/links were Voted on in the past 24 hours Using praw\", \"created_utc\": 1468539867.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EWhen using \\u003Ca href=\\\"/u/teaearlgraycold\\\"\\u003E/u/teaearlgraycold\\u003C/a\\u003E\\u0026#39;s Python \\u003Ca href=\\\"https://github.com/teaearlgraycold/puni\\\"\\u003Epuni module\\u003C/a\\u003E with PRAW to prune \\u003Ca href=\\\"/r/GlobalOffensiveTrade\\\"\\u003E/r/GlobalOffensiveTrade\\u003C/a\\u003E\\u0026#39;s full /wiki/usernotes, I\\u0026#39;m getting this error:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003ETraceback (most recent call last):\\n  File \\u0026quot;/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/praw/internal.py\\u0026quot;, line 213, in _raise_response_exceptions\\n    response.raise_for_status()  # These should all be directly mapped\\n  File \\u0026quot;/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/requests/models.py\\u0026quot;, line 844, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\nrequests.exceptions.HTTPError: 413 Client Error: Request Entity Too Large for url: https://oauth.reddit.com/api/wiki/edit/.json\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m aware that the max wiki page size is 524288 characters, however before actually \\u003Ccode\\u003Er.edit_wiki_page()\\u003C/code\\u003Eing the page, I\\u0026#39;m printing the length of the JSON which appears to be 517728 characters.\\u003C/p\\u003E\\n\\n\\u003Chr/\\u003E\\n\\n\\u003Cp\\u003EAny help would be appreciated!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"When using /u/teaearlgraycold's Python [puni module](https://github.com/teaearlgraycold/puni) with PRAW to prune /r/GlobalOffensiveTrade's full /wiki/usernotes, I'm getting this error:\\n\\n    Traceback (most recent call last):\\n      File \\\"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/praw/internal.py\\\", line 213, in _raise_response_exceptions\\n        response.raise_for_status()  # These should all be directly mapped\\n      File \\\"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/requests/models.py\\\", line 844, in raise_for_status\\n        raise HTTPError(http_error_msg, response=self)\\n    requests.exceptions.HTTPError: 413 Client Error: Request Entity Too Large for url: https://oauth.reddit.com/api/wiki/edit/.json\\n\\nI'm aware that the max wiki page size is 524288 characters, however before actually `r.edit_wiki_page()`ing the page, I'm printing the length of the JSON which appears to be 517728 characters.\\n\\n----\\n\\nAny help would be appreciated!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4suzea\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Shubbler\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 7, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4suzea/praw_httperror_413_client_error_when_uploading/\", \"locked\": false, \"name\": \"t3_4suzea\", \"created\": 1468551718.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4suzea/praw_httperror_413_client_error_when_uploading/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] HTTPError: 413 Client Error when uploading new Usernotes using Puni\", \"created_utc\": 1468522918.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI was wondering if you\\u0026#39;re considering adding an \\u003Ccode\\u003Eomitscript\\u003C/code\\u003E/\\u003Ccode\\u003Eomit_script\\u003C/code\\u003E argument to return the embed code without the script? It\\u0026#39;s handy for CMS developers (like myself) who want to allow our users to embed things easily, and seems to be a pretty solid convention across a number of oembed apis (\\u003Ca href=\\\"https://www.instagram.com/developer/embedding/\\\"\\u003EInstagram\\u003C/a\\u003E, \\u003Ca href=\\\"https://dev.twitter.com/rest/reference/get/statuses/oembed\\\"\\u003ETwitter\\u003C/a\\u003E).\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EIn terms of api response, it would simply remove the script tag, so \\u003Ca href=\\\"https://gist.github.com/yoshokatana/7f909e16620d0134b5ba549fd1781237\\\"\\u003Ethis\\u003C/a\\u003E would simply change to \\u003Ca href=\\\"https://gist.github.com/yoshokatana/2965bf3523d529690747842478fcb192\\\"\\u003Ethis\\u003C/a\\u003E.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThoughts?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I was wondering if you're considering adding an `omitscript`/`omit_script` argument to return the embed code without the script? It's handy for CMS developers (like myself) who want to allow our users to embed things easily, and seems to be a pretty solid convention across a number of oembed apis ([Instagram](https://www.instagram.com/developer/embedding/), [Twitter](https://dev.twitter.com/rest/reference/get/statuses/oembed)).\\n\\nIn terms of api response, it would simply remove the script tag, so [this](https://gist.github.com/yoshokatana/7f909e16620d0134b5ba549fd1781237) would simply change to [this](https://gist.github.com/yoshokatana/2965bf3523d529690747842478fcb192).\\n\\nThoughts?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4stlsl\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Yoshokatana\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4stlsl/feature_request_add_omitscript_argument_to_oembed/\", \"locked\": false, \"name\": \"t3_4stlsl\", \"created\": 1468536311.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4stlsl/feature_request_add_omitscript_argument_to_oembed/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Feature Request: Add omitscript argument to oembed endpoint\", \"created_utc\": 1468507511.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi all, I\\u0026#39;m having some difficulties with verifying whether the user has already granted access to my client app.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI am hitting \\u003Ca href=\\\"https://ssl.reddit.com/api/v1/authorize?client_id=CLIENT_ID\\u0026amp;response_type=code\\u0026amp;\\\"\\u003Ehttps://ssl.reddit.com/api/v1/authorize?client_id=CLIENT_ID\\u0026amp;response_type=code\\u0026amp;\\u003C/a\\u003E... which always creates a new grant code.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThis would be fine but because I am linking the access \\u0026amp; refresh tokens to my system\\u0026#39;s user account I need an endpoint (or a workaround) that verifies whether the user has already granted access to my client app so I can determine whether I have a user registered against those tokens.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks for the halp in advance! =)\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi all, I'm having some difficulties with verifying whether the user has already granted access to my client app.\\n\\nI am hitting https://ssl.reddit.com/api/v1/authorize?client_id=CLIENT_ID\\u0026response_type=code\\u0026... which always creates a new grant code.\\n\\nThis would be fine but because I am linking the access \\u0026 refresh tokens to my system's user account I need an endpoint (or a workaround) that verifies whether the user has already granted access to my client app so I can determine whether I have a user registered against those tokens.\\n\\nThanks for the halp in advance! =)\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4st37m\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"benqus\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4st37m/verifying_client_authorization/\", \"locked\": false, \"name\": \"t3_4st37m\", \"created\": 1468529484.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4st37m/verifying_client_authorization/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"verifying client authorization\", \"created_utc\": 1468500684.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI have Python 3 downloaded which should have PIP preinstalled, right? I heard about this API for Reddit botting but I forgot what it was called. I want to make a bot to target specific link posts and make an archive link for them (in the case of stuff like gawker media, etc). Would anyone be willing to answer questions of mine or even mentor me? Thanks! \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I have Python 3 downloaded which should have PIP preinstalled, right? I heard about this API for Reddit botting but I forgot what it was called. I want to make a bot to target specific link posts and make an archive link for them (in the case of stuff like gawker media, etc). Would anyone be willing to answer questions of mine or even mentor me? Thanks! \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4sr88k\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"BlinkPlays\", \"media\": null, \"score\": 7, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 8, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4sr88k/im_programming_in_python_for_the_very_first_time/\", \"locked\": false, \"name\": \"t3_4sr88k\", \"created\": 1468496232.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4sr88k/im_programming_in_python_for_the_very_first_time/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"I'm programming in Python for the very first time, and I want to make a Reddit bot.\", \"created_utc\": 1468467432.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 7}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m using \\u003Ca href=\\\"https://github.com/csu/export-saved-reddit\\\"\\u003Ethis website\\u003C/a\\u003E to try and export my saved links to chrome bookmarks but I\\u0026#39;m missing something. I installed everything the requirements of are asking, done git clone, downloaded the zip file and all that... But in the end of the \\u003Cem\\u003EUsage\\u003C/em\\u003E instructions it says: Back in your shell, \\u003Cstrong\\u003Erun python export-saved.py\\u003C/strong\\u003E but I can\\u0026#39;t find that file in the folder, just trying to know if anyone can help me out with this.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm using [this website](https://github.com/csu/export-saved-reddit) to try and export my saved links to chrome bookmarks but I'm missing something. I installed everything the requirements of are asking, done git clone, downloaded the zip file and all that... But in the end of the *Usage* instructions it says: Back in your shell, **run python export-saved.py** but I can't find that file in the folder, just trying to know if anyone can help me out with this.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4spyqh\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"kikodoze123\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4spyqh/can_someone_help_exporting_my_saved_reddit_links/\", \"locked\": false, \"name\": \"t3_4spyqh\", \"created\": 1468478818.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4spyqh/can_someone_help_exporting_my_saved_reddit_links/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Can someone help exporting my saved reddit links to chrome bookmarks?\", \"created_utc\": 1468450018.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHello, so in my own reddit instance, I can create a subreddit. It ends up in the search results (using Solr), but if I try to go to it, it\\u0026#39;s as if it doesn\\u0026#39;t exist (redirects to search).\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ETo actually be able to access the subreddit, I have to \\u003Ccode\\u003Esudo initctl restart memcached\\u003C/code\\u003E and \\u003Ccode\\u003Esudo reddit-restart\\u003C/code\\u003E.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhy is the cache not working properly... or... any idea as to what could be wrong and how I could fix this? Thank you\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Eroot@reddit:~# initctl list\\navahi-daemon start/running, process 995\\nmountnfs-bootclean.sh start/running\\nreddit-mcrouter-global start/running, process 1181\\nrsyslog start/running, process 970\\ntty4 start/running, process 1086\\nudev start/running, process 423\\nupstart-udev-bridge start/running, process 418\\navahi-cups-reload stop/waiting\\nmountall-net stop/waiting\\npasswd stop/waiting\\nreddit-job-update_sr_names stop/waiting\\nstartpar-bridge stop/waiting\\nureadahead-other stop/waiting\\nrc stop/waiting\\napport start/running\\nsystemd-logind start/running, process 954\\ntty5 start/running, process 1089\\nzookeeper start/running, process 1151\\nconsole-setup stop/waiting\\nhwclock-save stop/waiting\\nidmapd-mounting stop/waiting\\nirqbalance stop/waiting\\nplymouth-log stop/waiting\\npollinate stop/waiting\\nreddit-gold-servername stop/waiting\\nreddit-job-queue_promo_reports stop/waiting\\nrpcbind-boot stop/waiting\\nmountall.sh start/running\\nstatd start/running, process 774\\nfailsafe stop/waiting\\nreddit-consumer-event_collector_q stop/waiting\\nreddit-consumer-vote_link_q (1) start/running, process 7349\\natd start/running, process 1161\\ndbus start/running, process 864\\nresolvconf start/running\\nmounted-var stop/waiting\\nplymouth-shutdown stop/waiting\\nreddit-job-broken_things stop/waiting\\nreddit-job-liveupdate_activity stop/waiting\\nudev-fallback-graphics stop/waiting\\nssh start/running, process 1633\\nplymouth stop/waiting\\ncheckroot.sh start/running\\ncontrol-alt-delete stop/waiting\\nhwclock stop/waiting\\nmounted-proc stop/waiting\\nreddit-consumer-search_q (1) start/running, process 7329\\nreddit-job-gold_servernames stop/waiting\\nreddit-job-hourly_traffic stop/waiting\\nreddit-job-trylater stop/waiting\\nreddit-consumer-del_account_q (1) start/running, process 7287\\nreddit-consumer-modmail_email_q stop/waiting\\nreddit-job-update_popular_subreddits stop/waiting\\nreddit-websockets start/running, process 7254\\nsetvtrgb stop/waiting\\nshutdown stop/waiting\\nstatd-mounting stop/waiting\\ncron start/running, process 1160\\nmountkernfs.sh start/running\\nrpcbind start/running, process 697\\ncloud-init-container stop/waiting\\nmountall stop/waiting\\nmounted-debugfs stop/waiting\\nreddit-consumer-adzerk_q stop/waiting\\nreddit-job-update_gold_users stop/waiting\\nreddit-job-update_trending_subreddits stop/waiting\\ncloud-config stop/waiting\\ncloud-log-shutdown stop/waiting\\nconsole stop/waiting\\nmounted-run stop/waiting\\nreddit-consumer-markread_q (1) start/running, process 7300\\nreddit-job-clean_up_hardcache stop/waiting\\nreddit-job-write_location_inventory stop/waiting\\nacpid start/running, process 1159\\ncheckfs.sh start/running\\ncheckroot-bootclean.sh start/running\\nmountnfs.sh start/running\\nufw start/running\\nkmod stop/waiting\\nplymouth-stop stop/waiting\\nrcS stop/waiting\\nreddit-consumer-scraper_q (1) start/running, process 7320\\nreddit-consumers-restart stop/waiting\\nwait-for-state stop/waiting\\nmemcached start/running, process 7233\\nbootmisc.sh start/running\\nflush-early-job-log stop/waiting\\nfriendly-recovery stop/waiting\\ngssd-mounting stop/waiting\\nrc-sysinit stop/waiting\\nreddit-boot stop/waiting\\nreddit-consumer-log_q stop/waiting\\nreddit-consumer-newcomments_q (1) start/running, process 7312\\nreddit-consumer-vote_comment_q (1) start/running, process 7340\\nreddit-consumer-vote_fastlane_q stop/waiting\\nreddit-consumers-start stop/waiting\\nupstart-socket-bridge start/running, process 794\\nreddit-activity start/running, process 7309\\nreddit-consumer-automoderator_q stop/waiting\\ncryptdisks start/running\\nmountdevsubfs.sh start/running\\ntty2 start/running, process 1098\\nupstart-file-bridge start/running, process 1031\\ncloud-final stop/waiting\\ncloud-init stop/waiting\\nreddit-job-update_geoip stop/waiting\\nreddit-job-update_promo_metrics stop/waiting\\nudevtrigger stop/waiting\\nmongodb start/running, process 1153\\nmtab.sh start/running\\ntty3 start/running, process 1100\\ncloud-init-nonet stop/waiting\\ncontainer-detect stop/waiting\\nmcrouter stop/waiting\\nmounted-dev stop/waiting\\nreddit-job-update_reddits stop/waiting\\nudev-finish stop/waiting\\ncryptdisks-udev stop/waiting\\nhostname stop/waiting\\nmountall-reboot stop/waiting\\nreddit-consumer-adzerk_reporting_q stop/waiting\\nreddit-consumer-commentstree_q (commentstree_q1) start/running, process 7277\\nreddit-job-gold_accounting stop/waiting\\nreddit-job-rising stop/waiting\\nnetwork-interface (lo) start/running\\nnetwork-interface (eth0) start/running\\nnetwork-interface (eth1) start/running\\ngssd stop/waiting\\nmountall-shell stop/waiting\\nmounted-tmp stop/waiting\\nplymouth-ready stop/waiting\\nplymouth-splash stop/waiting\\nportmap-wait stop/waiting\\nreddit-consumer-butler_q (1) start/running, process 7261\\nreddit-consumer-liveupdate_scraper_q stop/waiting\\nreddit-paster start/running, process 7264\\ntty1 start/running, process 2282\\nudevmonitor stop/waiting\\nplymouth-upstart-bridge stop/waiting\\nmountall-bootclean.sh start/running\\nnetwork-interface-security (network-interface/eth1) start/running\\nnetwork-interface-security (network-interface/eth0) start/running\\nnetwork-interface-security (network-interface/lo) start/running\\nnetwork-interface-security (networking) start/running\\nnetworking start/running\\ntty6 start/running, process 1102\\ndmesg stop/waiting\\nprocps stop/waiting\\nreddit-job-email stop/waiting\\nreddit-job-subscribers stop/waiting\\nreddit-job-update_promos stop/waiting\\nttyS0 stop/waiting\\nidmapd start/running, process 912\\ncloud-init-local stop/waiting\\nconsole-font stop/waiting\\nnetwork-interface-container stop/waiting\\nreddit-job-update_keyword_targets stop/waiting\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAlso, the \\u0026quot;Gunicorn workers\\u0026quot; failed to start because the overlay in /home/vagrant/src is mounted after it\\u0026#39;s supposed to start.. but I started them manually anyway with \\u003Ccode\\u003E/etc/init.d/gunicorn start\\u003C/code\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Eedit: \\u003Cem\\u003EMaybe it has something to do with the latest commits related to CMemCache or whatever it is, and g.cache?..\\u003C/em\\u003E\\nedit: Pulled changes. Same thing still happens. Vagrant box is pretty much the default one running Ubuntu 14.04.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hello, so in my own reddit instance, I can create a subreddit. It ends up in the search results (using Solr), but if I try to go to it, it's as if it doesn't exist (redirects to search).\\n\\n\\nTo actually be able to access the subreddit, I have to `sudo initctl restart memcached` and `sudo reddit-restart`.\\n\\n\\nWhy is the cache not working properly... or... any idea as to what could be wrong and how I could fix this? Thank you\\n\\n    root@reddit:~# initctl list\\n    avahi-daemon start/running, process 995\\n    mountnfs-bootclean.sh start/running\\n    reddit-mcrouter-global start/running, process 1181\\n    rsyslog start/running, process 970\\n    tty4 start/running, process 1086\\n    udev start/running, process 423\\n    upstart-udev-bridge start/running, process 418\\n    avahi-cups-reload stop/waiting\\n    mountall-net stop/waiting\\n    passwd stop/waiting\\n    reddit-job-update_sr_names stop/waiting\\n    startpar-bridge stop/waiting\\n    ureadahead-other stop/waiting\\n    rc stop/waiting\\n    apport start/running\\n    systemd-logind start/running, process 954\\n    tty5 start/running, process 1089\\n    zookeeper start/running, process 1151\\n    console-setup stop/waiting\\n    hwclock-save stop/waiting\\n    idmapd-mounting stop/waiting\\n    irqbalance stop/waiting\\n    plymouth-log stop/waiting\\n    pollinate stop/waiting\\n    reddit-gold-servername stop/waiting\\n    reddit-job-queue_promo_reports stop/waiting\\n    rpcbind-boot stop/waiting\\n    mountall.sh start/running\\n    statd start/running, process 774\\n    failsafe stop/waiting\\n    reddit-consumer-event_collector_q stop/waiting\\n    reddit-consumer-vote_link_q (1) start/running, process 7349\\n    atd start/running, process 1161\\n    dbus start/running, process 864\\n    resolvconf start/running\\n    mounted-var stop/waiting\\n    plymouth-shutdown stop/waiting\\n    reddit-job-broken_things stop/waiting\\n    reddit-job-liveupdate_activity stop/waiting\\n    udev-fallback-graphics stop/waiting\\n    ssh start/running, process 1633\\n    plymouth stop/waiting\\n    checkroot.sh start/running\\n    control-alt-delete stop/waiting\\n    hwclock stop/waiting\\n    mounted-proc stop/waiting\\n    reddit-consumer-search_q (1) start/running, process 7329\\n    reddit-job-gold_servernames stop/waiting\\n    reddit-job-hourly_traffic stop/waiting\\n    reddit-job-trylater stop/waiting\\n    reddit-consumer-del_account_q (1) start/running, process 7287\\n    reddit-consumer-modmail_email_q stop/waiting\\n    reddit-job-update_popular_subreddits stop/waiting\\n    reddit-websockets start/running, process 7254\\n    setvtrgb stop/waiting\\n    shutdown stop/waiting\\n    statd-mounting stop/waiting\\n    cron start/running, process 1160\\n    mountkernfs.sh start/running\\n    rpcbind start/running, process 697\\n    cloud-init-container stop/waiting\\n    mountall stop/waiting\\n    mounted-debugfs stop/waiting\\n    reddit-consumer-adzerk_q stop/waiting\\n    reddit-job-update_gold_users stop/waiting\\n    reddit-job-update_trending_subreddits stop/waiting\\n    cloud-config stop/waiting\\n    cloud-log-shutdown stop/waiting\\n    console stop/waiting\\n    mounted-run stop/waiting\\n    reddit-consumer-markread_q (1) start/running, process 7300\\n    reddit-job-clean_up_hardcache stop/waiting\\n    reddit-job-write_location_inventory stop/waiting\\n    acpid start/running, process 1159\\n    checkfs.sh start/running\\n    checkroot-bootclean.sh start/running\\n    mountnfs.sh start/running\\n    ufw start/running\\n    kmod stop/waiting\\n    plymouth-stop stop/waiting\\n    rcS stop/waiting\\n    reddit-consumer-scraper_q (1) start/running, process 7320\\n    reddit-consumers-restart stop/waiting\\n    wait-for-state stop/waiting\\n    memcached start/running, process 7233\\n    bootmisc.sh start/running\\n    flush-early-job-log stop/waiting\\n    friendly-recovery stop/waiting\\n    gssd-mounting stop/waiting\\n    rc-sysinit stop/waiting\\n    reddit-boot stop/waiting\\n    reddit-consumer-log_q stop/waiting\\n    reddit-consumer-newcomments_q (1) start/running, process 7312\\n    reddit-consumer-vote_comment_q (1) start/running, process 7340\\n    reddit-consumer-vote_fastlane_q stop/waiting\\n    reddit-consumers-start stop/waiting\\n    upstart-socket-bridge start/running, process 794\\n    reddit-activity start/running, process 7309\\n    reddit-consumer-automoderator_q stop/waiting\\n    cryptdisks start/running\\n    mountdevsubfs.sh start/running\\n    tty2 start/running, process 1098\\n    upstart-file-bridge start/running, process 1031\\n    cloud-final stop/waiting\\n    cloud-init stop/waiting\\n    reddit-job-update_geoip stop/waiting\\n    reddit-job-update_promo_metrics stop/waiting\\n    udevtrigger stop/waiting\\n    mongodb start/running, process 1153\\n    mtab.sh start/running\\n    tty3 start/running, process 1100\\n    cloud-init-nonet stop/waiting\\n    container-detect stop/waiting\\n    mcrouter stop/waiting\\n    mounted-dev stop/waiting\\n    reddit-job-update_reddits stop/waiting\\n    udev-finish stop/waiting\\n    cryptdisks-udev stop/waiting\\n    hostname stop/waiting\\n    mountall-reboot stop/waiting\\n    reddit-consumer-adzerk_reporting_q stop/waiting\\n    reddit-consumer-commentstree_q (commentstree_q1) start/running, process 7277\\n    reddit-job-gold_accounting stop/waiting\\n    reddit-job-rising stop/waiting\\n    network-interface (lo) start/running\\n    network-interface (eth0) start/running\\n    network-interface (eth1) start/running\\n    gssd stop/waiting\\n    mountall-shell stop/waiting\\n    mounted-tmp stop/waiting\\n    plymouth-ready stop/waiting\\n    plymouth-splash stop/waiting\\n    portmap-wait stop/waiting\\n    reddit-consumer-butler_q (1) start/running, process 7261\\n    reddit-consumer-liveupdate_scraper_q stop/waiting\\n    reddit-paster start/running, process 7264\\n    tty1 start/running, process 2282\\n    udevmonitor stop/waiting\\n    plymouth-upstart-bridge stop/waiting\\n    mountall-bootclean.sh start/running\\n    network-interface-security (network-interface/eth1) start/running\\n    network-interface-security (network-interface/eth0) start/running\\n    network-interface-security (network-interface/lo) start/running\\n    network-interface-security (networking) start/running\\n    networking start/running\\n    tty6 start/running, process 1102\\n    dmesg stop/waiting\\n    procps stop/waiting\\n    reddit-job-email stop/waiting\\n    reddit-job-subscribers stop/waiting\\n    reddit-job-update_promos stop/waiting\\n    ttyS0 stop/waiting\\n    idmapd start/running, process 912\\n    cloud-init-local stop/waiting\\n    console-font stop/waiting\\n    network-interface-container stop/waiting\\n    reddit-job-update_keyword_targets stop/waiting\\n\\nAlso, the \\\"Gunicorn workers\\\" failed to start because the overlay in /home/vagrant/src is mounted after it's supposed to start.. but I started them manually anyway with `/etc/init.d/gunicorn start`\\n\\nedit: *Maybe it has something to do with the latest commits related to CMemCache or whatever it is, and g.cache?..*\\nedit: Pulled changes. Same thing still happens. Vagrant box is pretty much the default one running Ubuntu 14.04.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4spuu4\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"pcoutin\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1468529972.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4spuu4/subreddits_not_being_created_properly/\", \"locked\": false, \"name\": \"t3_4spuu4\", \"created\": 1468477400.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4spuu4/subreddits_not_being_created_properly/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Subreddits not being created properly?\", \"created_utc\": 1468448600.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESirCmpwn recently decided to mark the repository as unmaintained and stopped taking pull requests. I asked him to transfer the repository to me so I could maintain it. He refused but did add me as a contributor. I\\u0026#39;ve now been removed as a contributor and all pull requests and issues were closed out.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;ve hard forked the repostiory \\u003Ca href=\\\"https://github.com/CrustyJew/RedditSharp\\\"\\u003Ehere\\u003C/a\\u003E and will be maintaining it. I have an issue in to the main Reddit repo to update the wiki accordingly.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"SirCmpwn recently decided to mark the repository as unmaintained and stopped taking pull requests. I asked him to transfer the repository to me so I could maintain it. He refused but did add me as a contributor. I've now been removed as a contributor and all pull requests and issues were closed out.\\n\\nI've hard forked the repostiory [here](https://github.com/CrustyJew/RedditSharp) and will be maintaining it. I have an issue in to the main Reddit repo to update the wiki accordingly.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4snxfl\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Meepster23\", \"media\": null, \"score\": 13, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 17, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4snxfl/psa_for_anyone_using_redditsharp/\", \"locked\": false, \"name\": \"t3_4snxfl\", \"created\": 1468454825.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4snxfl/psa_for_anyone_using_redditsharp/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"PSA For Anyone Using RedditSharp!\", \"created_utc\": 1468426025.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 13}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI installed reddit using the installation steps listed here: \\u003Ca href=\\\"https://github.com/reddit/reddit/wiki/reddit-install-script-for-Ubuntu\\\"\\u003Ehttps://github.com/reddit/reddit/wiki/reddit-install-script-for-Ubuntu\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Eafter which reddit is accessible from within the box via curl, question is how can i expose it publicly through the box\\u0026#39;s address because reddit.local is not accessible publicly\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I installed reddit using the installation steps listed here: https://github.com/reddit/reddit/wiki/reddit-install-script-for-Ubuntu\\n\\nafter which reddit is accessible from within the box via curl, question is how can i expose it publicly through the box's address because reddit.local is not accessible publicly\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4smomt\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"megabosx\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4smomt/cannot_access_installed_reddit_clone_copy/\", \"locked\": false, \"name\": \"t3_4smomt\", \"created\": 1468438372.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4smomt/cannot_access_installed_reddit_clone_copy/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"cannot access installed reddit clone copy\", \"created_utc\": 1468409572.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": null, \"selftext\": \"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4sgp5y\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Shubbler\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4sgp5y/praw_most_efficient_way_to_find_if_a_redditor_is/\", \"locked\": false, \"name\": \"t3_4sgp5y\", \"created\": 1468354805.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4sgp5y/praw_most_efficient_way_to_find_if_a_redditor_is/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] Most efficient way to find if a Redditor is banned/deleted?\", \"created_utc\": 1468326005.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI know this is probably a dumb question but I want to make a comment and have multple lines. I have tried submitting the comment with \\\\n, two spaces, \\\\r. Im using \\u003Ca href=\\\"https://not-an-aardvark.github.io/snoowrap/Comment.html#reply__anchor\\\"\\u003Esnoowrap\\u003C/a\\u003E to use the reddit API. What is the characer/markdown to create a newline though the API?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I know this is probably a dumb question but I want to make a comment and have multple lines. I have tried submitting the comment with \\\\n, two spaces, \\\\r. Im using [snoowrap](https://not-an-aardvark.github.io/snoowrap/Comment.html#reply__anchor) to use the reddit API. What is the characer/markdown to create a newline though the API?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4sejvc\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"appleiscool13\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4sejvc/node_how_to_post_a_new_line_character/\", \"locked\": false, \"name\": \"t3_4sejvc\", \"created\": 1468316739.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4sejvc/node_how_to_post_a_new_line_character/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[Node] How to post a new line character?\", \"created_utc\": 1468287939.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI haven\\u0026#39;t used the reddit API for about a year, and I am not understanding OAuth at all.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ESo, I just want a simple commenting bot. Is OAuth necessary for this? I\\u0026#39;ll need to send hourly POST requests asking for a new access token? Or is there a simpler way to do this?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I haven't used the reddit API for about a year, and I am not understanding OAuth at all.\\n\\nSo, I just want a simple commenting bot. Is OAuth necessary for this? I'll need to send hourly POST requests asking for a new access token? Or is there a simpler way to do this?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4s98q3\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"charredgrass\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4s98q3/question_about_converting_to_oauth/\", \"locked\": false, \"name\": \"t3_4s98q3\", \"created\": 1468241267.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4s98q3/question_about_converting_to_oauth/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Question about converting to OAuth\", \"created_utc\": 1468212467.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m working on an app that serves as a \\u0026quot;layer\\u0026quot; over a particular sub-reddit community. I want users to be able to read and add to comments without even needing to know what Reddit is. (the idea is for even my Mom to be able to use this app).\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe UX I\\u0026#39;m aiming for is for the end user to just see a \\u0026quot;comment as _______\\u0026quot; field where they fill in the box with the username and I create the account for them. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003ESo if a user entered \\u0026quot;dave\\u0026quot; I\\u0026#39;d do a check for the \\u0026quot;dave\\u0026quot; username, see that it\\u0026#39;s taken, and automagically generate something like \\u0026quot;dave84324\\u0026quot; for the end user so s/he can start commenting right away.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm working on an app that serves as a \\\"layer\\\" over a particular sub-reddit community. I want users to be able to read and add to comments without even needing to know what Reddit is. (the idea is for even my Mom to be able to use this app).\\n\\nThe UX I'm aiming for is for the end user to just see a \\\"comment as _______\\\" field where they fill in the box with the username and I create the account for them. \\n\\nSo if a user entered \\\"dave\\\" I'd do a check for the \\\"dave\\\" username, see that it's taken, and automagically generate something like \\\"dave84324\\\" for the end user so s/he can start commenting right away.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4s8o8v\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"da_realest_bamf\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 11, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4s8o8v/how_to_create_accounts_through_my_app/\", \"locked\": false, \"name\": \"t3_4s8o8v\", \"created\": 1468232199.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4s8o8v/how_to_create_accounts_through_my_app/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How to create accounts through my app transparently for users?\", \"created_utc\": 1468203399.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIn compliance with reddit\\u0026#39;s api guide, I need to set the user agent of my requests made to the API to a custom string identifying my app. I am a newish dev and no matter what I try, how many searches for answers I make, or how many different methods I attempt I can not make this work.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI could post my code here but honestly it\\u0026#39;s an absolute mess at the moment after so many failed attempts. Is there anyone here kind enough to post how to do this and help me make it work?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"In compliance with reddit's api guide, I need to set the user agent of my requests made to the API to a custom string identifying my app. I am a newish dev and no matter what I try, how many searches for answers I make, or how many different methods I attempt I can not make this work.\\n\\n\\n\\nI could post my code here but honestly it's an absolute mess at the moment after so many failed attempts. Is there anyone here kind enough to post how to do this and help me make it work?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4s8ak2\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"TheKingHippo\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 15, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1468260610.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4s8ak2/please_help_me_change_the_useragent_of_an/\", \"locked\": false, \"name\": \"t3_4s8ak2\", \"created\": 1468226551.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4s8ak2/please_help_me_change_the_useragent_of_an/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Please help me change the User-Agent of an HttpClient in C#\", \"created_utc\": 1468197751.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI had just updated my local install, and the front page and \\u003Ca href=\\\"/r/all\\\"\\u003E/r/all\\u003C/a\\u003E fail because they fetch a query and iterate through them, in the process, calling \\u003Ccode\\u003Eg.gencache.set\\u003C/code\\u003E. Restarting the memcached service does nothing. \\u003Ccode\\u003Etelnet\\u003C/code\\u003Eing to it and \\u003Ccode\\u003Eflush_all\\u003C/code\\u003E makes the error change to an unknown read error, which according to the libmemcached docs means there\\u0026#39;s a bug in the server somewhere. Reinstalling libmemcached and pylibmc just brings me to the same Memcached.set setfailed error. \\u003Ca href=\\\"https://gist.github.com/13steinj/9a7ed185522c3d9685f1905b6fd68599\\\"\\u003ETraceback\\u003C/a\\u003E, and some \\u003Ca href=\\\"https://i.redd.it/2zugt5lw3h8x.png\\\"\\u003Eother data\\u003C/a\\u003E regarding the cache keys and values and such.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEdit: all cases where g.gencache is set fail in the same manner, ex, changing preferences.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I had just updated my local install, and the front page and /r/all fail because they fetch a query and iterate through them, in the process, calling `g.gencache.set`. Restarting the memcached service does nothing. `telnet`ing to it and `flush_all` makes the error change to an unknown read error, which according to the libmemcached docs means there's a bug in the server somewhere. Reinstalling libmemcached and pylibmc just brings me to the same Memcached.set setfailed error. [Traceback](https://gist.github.com/13steinj/9a7ed185522c3d9685f1905b6fd68599), and some [other data](https://i.redd.it/2zugt5lw3h8x.png) regarding the cache keys and values and such.\\n\\nEdit: all cases where g.gencache is set fail in the same manner, ex, changing preferences.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4s7cix\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"13steinj\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1468184814.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4s7cix/mcrouter_sets_fail_for_r2liborganicorganic_links/\", \"locked\": false, \"name\": \"t3_4s7cix\", \"created\": 1468213124.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4s7cix/mcrouter_sets_fail_for_r2liborganicorganic_links/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"MCRouter sets fail for r2/lib/organic.organic_links\", \"created_utc\": 1468184324.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI like to know the user\\u0026#39;s location from where they have posted or commented on reddit or user\\u0026#39;s living location. Is it possible to know using praw api ? \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I like to know the user's location from where they have posted or commented on reddit or user's living location. Is it possible to know using praw api ? \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4s4d38\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"asony111\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 8, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4s4d38/how_can_i_able_to_get_users_location/\", \"locked\": false, \"name\": \"t3_4s4d38\", \"created\": 1468160531.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4s4d38/how_can_i_able_to_get_users_location/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How can i able to get user's location ?\", \"created_utc\": 1468131731.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003Eif I wanted to search for a link to asdf.com but it was in square brackets like [this](asdf.com), how would i get it?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"if I wanted to search for a link to asdf.com but it was in square brackets like [this](asdf.com), how would i get it?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4s1z3r\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"K-a-Z-e\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 5, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4s1z3r/check_for_a_link_within_squared_brackets/\", \"locked\": false, \"name\": \"t3_4s1z3r\", \"created\": 1468123239.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4s1z3r/check_for_a_link_within_squared_brackets/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Check for a link within squared brackets\", \"created_utc\": 1468094439.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": null, \"selftext\": \"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4s17co\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Baashha\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 6, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4s17co/how_can_i_get_the_list_of_subscribers_to_a/\", \"locked\": false, \"name\": \"t3_4s17co\", \"created\": 1468113137.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4s17co/how_can_i_get_the_list_of_subscribers_to_a/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"how can i get the list of subscribers to a subreddit?\", \"created_utc\": 1468084337.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cpre\\u003E\\u003Ccode\\u003Estream = praw.helpers.comment_stream(r, subreddit, limit=None, verbosity=1)\\nfor comment in stream:\\n\\n    #Get submission and title\\n    submission = r.get_submission(comment_id=comment)\\n    title = submission.title\\n\\n    #Get submitter\\n    submitter = submission.author.name\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m trying to grab the submission\\u0026#39;s author name from the comment the submission is in. Search has failed me, anyone know?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEDIT: Solved! Didn\\u0026#39;t need to go as far as author.name, just .author was fine!\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Estream = praw.helpers.comment_stream(r, subreddit, limit=None, verbosity=1)\\n\\n#Parse Comments in Stream\\nfor comment in stream:\\n    #Get submission and title\\n    submission = r.get_submission(comment_id=comment)\\n    title = submission.title\\n\\n    #Get submitter\\n    author = submission.author\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"    stream = praw.helpers.comment_stream(r, subreddit, limit=None, verbosity=1)\\n    for comment in stream:\\n    \\n        #Get submission and title\\n        submission = r.get_submission(comment_id=comment)\\n        title = submission.title\\n    \\n        #Get submitter\\n        submitter = submission.author.name\\n\\nI'm trying to grab the submission's author name from the comment the submission is in. Search has failed me, anyone know?\\n\\nEDIT: Solved! Didn't need to go as far as author.name, just .author was fine!\\n\\n    stream = praw.helpers.comment_stream(r, subreddit, limit=None, verbosity=1)\\n    \\n    #Parse Comments in Stream\\n    for comment in stream:\\n        #Get submission and title\\n        submission = r.get_submission(comment_id=comment)\\n        title = submission.title\\n    \\n        #Get submitter\\n        author = submission.author\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4rxo27\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"zuffdaddy\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1468021932.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4rxo27/praw_get_submission_author_from_comment/\", \"locked\": false, \"name\": \"t3_4rxo27\", \"created\": 1468050049.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4rxo27/praw_get_submission_author_from_comment/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] Get submission author from comment?\", \"created_utc\": 1468021249.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EWhenever I run the browser \\u003Ca href=\\\"https://www.reddit.com/r/askscience/new?count=50\\u0026amp;before=4qdc03\\\"\\u003Ehttps://www.reddit.com/r/askscience/new?count=50\\u0026amp;before=4qdc03\\u003C/a\\u003E I get new posts.  When I do the same in praw:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E(Pdb) sr.get_new(limit=\\u0026#39;none\\u0026#39;, params={\\u0026#39;before\\u0026#39;:thing})\\n\\u0026lt;generator object get_content at 0xb735d5a4\\u0026gt;\\n(Pdb) sr.get_new(limit=\\u0026#39;none\\u0026#39;, params={\\u0026#39;before\\u0026#39;:thing}).next()\\n*** StopIteration:\\n(Pdb) thing\\nu\\u0026#39;t3_4qdc03\\u0026#39;\\n(Pdb) subr.display_name\\nu\\u0026#39;askscience\\u0026#39;\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Esr is defined to be:\\n    sr = self.r.get_subreddit(subr.display_name)\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAny ideas for this strange behaviour.  The unusual thing is this code seems to work sometimes but not other times.  Initially I thought it was some kind of rate limit problem but no rate limit exception is being thrown.  It just silently fails and its only over these few lines of code.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Whenever I run the browser https://www.reddit.com/r/askscience/new?count=50\\u0026before=4qdc03 I get new posts.  When I do the same in praw:\\n\\n    (Pdb) sr.get_new(limit='none', params={'before':thing})\\n    \\u003Cgenerator object get_content at 0xb735d5a4\\u003E\\n    (Pdb) sr.get_new(limit='none', params={'before':thing}).next()\\n    *** StopIteration:\\n    (Pdb) thing\\n    u't3_4qdc03'\\n    (Pdb) subr.display_name\\n    u'askscience'\\n\\n\\nsr is defined to be:\\n    sr = self.r.get_subreddit(subr.display_name)\\n\\nAny ideas for this strange behaviour.  The unusual thing is this code seems to work sometimes but not other times.  Initially I thought it was some kind of rate limit problem but no rate limit exception is being thrown.  It just silently fails and its only over these few lines of code.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4rwmh3\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"kiwiheretic\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 8, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4rwmh3/get_new_returning_no_posts_but_browser_equivalent/\", \"locked\": false, \"name\": \"t3_4rwmh3\", \"created\": 1468036837.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4rwmh3/get_new_returning_no_posts_but_browser_equivalent/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"get_new returning no posts but browser equivalent does\", \"created_utc\": 1468008037.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"dinosaurscode.xyz\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": null, \"selftext\": \"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4rvkty\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"xDinomode\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": false, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4rvkty/golang_and_reddits_api/\", \"locked\": false, \"name\": \"t3_4rvkty\", \"created\": 1468024865.0, \"url\": \"https://dinosaurscode.xyz/go/2016/07/08/golang-and-reddit-api-tutorial/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Golang and Reddit's API\", \"created_utc\": 1467996065.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIn \\u003Ca href=\\\"/r/fixingmovies\\\"\\u003E/r/fixingmovies\\u003C/a\\u003E , if you click on \\u0026quot;my subreddits\\u0026quot;, your subreddits appears UNDER the comments text box (\\u003Ca href=\\\"http://imgur.com/cGGzrRO\\\"\\u003Ehttp://imgur.com/cGGzrRO\\u003C/a\\u003E). I think you can fix it like this example :\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHTML\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u0026lt;div class=\\u0026quot;dashed-box\\u0026quot;\\u0026gt;Dashed box\\n  \\u0026lt;span class=\\u0026quot;gold-box\\u0026quot;\\u0026gt;Gold box\\u0026lt;/span\\u0026gt;\\n  \\u0026lt;span class=\\u0026quot;green-box\\u0026quot;\\u0026gt;Green box\\u0026lt;/span\\u0026gt;\\n\\u0026lt;/div\\u0026gt;\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECSS\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E.dashed-box { \\n  position: relative;\\n  z-index: 1;\\n  border: dashed;\\n  height: 8em;\\n  margin-bottom: 1em;\\n  margin-top: 2em;\\n}\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E.gold-box { \\n  position: absolute;\\n  z-index: 3; /* put .gold-box above .green-box and .dashed-box */\\n  background: gold;\\n  width: 80%;\\n  left: 60px;\\n  top: 3em;\\n}\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E.green-box { \\n  position: absolute;\\n  z-index: 2; /* put .green-box above .dashed-box */\\n  background: lightgreen;\\n  width: 20%;\\n  left: 65%;\\n  top: -25px;\\n  height: 7em;\\n  opacity: 0.9;\\n}\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe result should look like something like that : \\u003Ca href=\\\"http://imgur.com/qBETH1F\\\"\\u003Ehttp://imgur.com/qBETH1F\\u003C/a\\u003E .\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EObviously replace the css names with the names of the reddit elements. Sorry for my bad english :/\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EFound the code here : \\u003Ca href=\\\"https://developer.mozilla.org/en-US/docs/Web/CSS/z-index\\\"\\u003Ehttps://developer.mozilla.org/en-US/docs/Web/CSS/z-index\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"In /r/fixingmovies , if you click on \\\"my subreddits\\\", your subreddits appears UNDER the comments text box (http://imgur.com/cGGzrRO). I think you can fix it like this example :\\n\\nHTML\\n\\n\\u003Cdiv class=\\\"dashed-box\\\"\\u003EDashed box\\n  \\u003Cspan class=\\\"gold-box\\\"\\u003EGold box\\u003C/span\\u003E\\n  \\u003Cspan class=\\\"green-box\\\"\\u003EGreen box\\u003C/span\\u003E\\n\\u003C/div\\u003E\\n\\nCSS\\n\\n.dashed-box { \\n  position: relative;\\n  z-index: 1;\\n  border: dashed;\\n  height: 8em;\\n  margin-bottom: 1em;\\n  margin-top: 2em;\\n}\\n\\n.gold-box { \\n  position: absolute;\\n  z-index: 3; /* put .gold-box above .green-box and .dashed-box */\\n  background: gold;\\n  width: 80%;\\n  left: 60px;\\n  top: 3em;\\n}\\n\\n.green-box { \\n  position: absolute;\\n  z-index: 2; /* put .green-box above .dashed-box */\\n  background: lightgreen;\\n  width: 20%;\\n  left: 65%;\\n  top: -25px;\\n  height: 7em;\\n  opacity: 0.9;\\n}\\n\\nThe result should look like something like that : http://imgur.com/qBETH1F .\\n\\nObviously replace the css names with the names of the reddit elements. Sorry for my bad english :/\\n\\nFound the code here : https://developer.mozilla.org/en-US/docs/Web/CSS/z-index\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ru4uq\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"DraxFromSteam\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ru4uq/stacking_error_in_rfixing_movies/\", \"locked\": false, \"name\": \"t3_4ru4uq\", \"created\": 1468004444.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ru4uq/stacking_error_in_rfixing_movies/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Stacking error in /r/fixing movies\", \"created_utc\": 1467975644.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EWith Vagrant..\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECopypasted from my post in \\u003Ca href=\\\"https://www.reddit.com/r/redditdev/comments/4ndp3t/clean_checkout_vagrant_build_appears_broken/\\\"\\u003Ehttps://www.reddit.com/r/redditdev/comments/4ndp3t/clean_checkout_vagrant_build_appears_broken/\\u003C/a\\u003E because it\\u0026#39;s buried \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EBy printing the key and self.raw_data before the crash in r2/r2/lib/configparse.py line 126 from the traceback, the last key printed was az_selfserve_network_id, which has an empty value, of course, explaining the error...\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhy hasn\\u0026#39;t this been fixed in master? Or maybe I AM supposed to edit the ini to get it to even work, or maybe disable some plugins...\\nOkay, so I set it to 420 in development.update, ran make ini, and... get some other weird errors. Something about \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Epycassa.cassandra.ttypes.InvalidRequestException: InvalidRequestException(\\n    why=\\u0026#39;Cannot add already existing column family \\u0026quot;PromotedLinkRoadblock\\u0026quot; to keyspace \\u0026quot;reddit\\u0026quot;\\u0026#39;)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EHmm, maybe some of the data was already injected.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWell, at least now I get a WebError Traceback instead of a 503, no server for whatever. With this:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003ENameError: name \\u0026#39;vary_pagecache_on_experiments\\u0026#39; is not defined\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EI ran sudo reddit-stop, then make on ~/src/reddit/r2 as vagrant and it worked. Then sudo reddit-start. Still, when I go to \\u003Ca href=\\\"http://reddit.local\\\"\\u003Ehttp://reddit.local\\u003C/a\\u003E on the host, I get the same pagecache error. And if I keep pressing F5, it alternates between that and some other screen with \\u0026quot;Extra Data\\u0026quot; and \\u0026quot;no source code to display\\u0026quot;\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EStrange. Inconsistent clone or something? Pagecache was removed... in 6dbe772e03841041ac2c89d37fda55e02e299789, the last commit on my clone. I still see that vary_pagecache_on_experiments thing only on two .py files. master head has been broken for over a month?!\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI commented out those @vary_... decorators, and got yet another error!!\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EInvalidRequestException: InvalidRequestException( why=\\u0026#39;Cannot add already existing column family \\u0026quot;PerformedRulesByThing\\u0026quot; to keyspace \\u0026quot;reddit\\u0026quot;\\u0026#39;)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EI had to run\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Esudo reddit-stop\\ncassandra-cli\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Ethen\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EDROP KEYSPACE reddit;\\nCREATE KEYSPACE reddit;\\nuse reddit;\\ncreate column family permacache with column_type = \\u0026#39;Standard\\u0026#39; and comparator = \\u0026#39;BytesType\\u0026#39;;\\n^D\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Ethen\\n    sudo reddit-start\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Ethen\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EInvalidRequestException: InvalidRequestException( why=\\u0026#39;Cannot add already existing column family \\u0026quot;LabeledMultiByOwner\\u0026quot; to keyspace \\u0026quot;reddit\\u0026quot;\\u0026#39;)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Ew h y\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Edid make clean as well\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Eoh, and reddit-shell now gives me\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EImportError: No module named _utils\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Eof course, I need to make to build at least the stuff written in C?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Ealso removed adzerk and meatspace from plugins, we\\u0026#39;ll see how that goes\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Ebut why the cassandra thing... I just dropped and remade it again. Now..\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Ereddit-shell:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Evagrant@reddit:~/src/reddit/r2$ reddit-shell\\nWarning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\nWarning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\nOverriding g.--plugin to r2\\nreddit.local:15567 started 6dbe772 at 00:25:58 (took 0.82s)\\n/usr/lib/python2.7/dist-packages/IPython/frontend.py:30: UserWarning: The top-level `frontend` package has been deprecated. All its subpackages have been moved to the top `IPython` level.\\n  warn(\\u0026quot;The top-level `frontend` package has been deprecated. \\u0026quot;\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAaaaand it finally seems to work!?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"With Vagrant..\\n\\nCopypasted from my post in https://www.reddit.com/r/redditdev/comments/4ndp3t/clean_checkout_vagrant_build_appears_broken/ because it's buried \\n\\nBy printing the key and self.raw_data before the crash in r2/r2/lib/configparse.py line 126 from the traceback, the last key printed was az_selfserve_network_id, which has an empty value, of course, explaining the error...\\n\\n\\nWhy hasn't this been fixed in master? Or maybe I AM supposed to edit the ini to get it to even work, or maybe disable some plugins...\\nOkay, so I set it to 420 in development.update, ran make ini, and... get some other weird errors. Something about \\n\\n\\n    pycassa.cassandra.ttypes.InvalidRequestException: InvalidRequestException(\\n        why='Cannot add already existing column family \\\"PromotedLinkRoadblock\\\" to keyspace \\\"reddit\\\"')\\n\\nHmm, maybe some of the data was already injected.\\n\\nWell, at least now I get a WebError Traceback instead of a 503, no server for whatever. With this:\\n\\n    NameError: name 'vary_pagecache_on_experiments' is not defined\\n\\nI ran sudo reddit-stop, then make on ~/src/reddit/r2 as vagrant and it worked. Then sudo reddit-start. Still, when I go to http://reddit.local on the host, I get the same pagecache error. And if I keep pressing F5, it alternates between that and some other screen with \\\"Extra Data\\\" and \\\"no source code to display\\\"\\n\\nStrange. Inconsistent clone or something? Pagecache was removed... in 6dbe772e03841041ac2c89d37fda55e02e299789, the last commit on my clone. I still see that vary_pagecache_on_experiments thing only on two .py files. master head has been broken for over a month?!\\n\\nI commented out those @vary_... decorators, and got yet another error!!\\n\\n    InvalidRequestException: InvalidRequestException( why='Cannot add already existing column family \\\"PerformedRulesByThing\\\" to keyspace \\\"reddit\\\"')\\n\\nI had to run\\n\\n    sudo reddit-stop\\n    cassandra-cli\\n\\nthen\\n\\n    DROP KEYSPACE reddit;\\n    CREATE KEYSPACE reddit;\\n    use reddit;\\n    create column family permacache with column_type = 'Standard' and comparator = 'BytesType';\\n    ^D\\n\\nthen\\n    sudo reddit-start\\n\\nthen\\n\\n    InvalidRequestException: InvalidRequestException( why='Cannot add already existing column family \\\"LabeledMultiByOwner\\\" to keyspace \\\"reddit\\\"')\\n\\nw h y\\n\\ndid make clean as well\\n\\noh, and reddit-shell now gives me\\n\\n    ImportError: No module named _utils\\n\\nof course, I need to make to build at least the stuff written in C?\\n\\nalso removed adzerk and meatspace from plugins, we'll see how that goes\\n\\nbut why the cassandra thing... I just dropped and remade it again. Now..\\n\\nreddit-shell:\\n\\n    vagrant@reddit:~/src/reddit/r2$ reddit-shell\\n    Warning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\n    Warning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\n    Overriding g.--plugin to r2\\n    reddit.local:15567 started 6dbe772 at 00:25:58 (took 0.82s)\\n    /usr/lib/python2.7/dist-packages/IPython/frontend.py:30: UserWarning: The top-level `frontend` package has been deprecated. All its subpackages have been moved to the top `IPython` level.\\n      warn(\\\"The top-level `frontend` package has been deprecated. \\\"\\n\\nAaaaand it finally seems to work!?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4rlp1g\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"pcoutin\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 9, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1467998868.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4rlp1g/clean_clone_from_master_broken/\", \"locked\": false, \"name\": \"t3_4rlp1g\", \"created\": 1467880199.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4rlp1g/clean_clone_from_master_broken/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"clean clone from master broken?\", \"created_utc\": 1467851399.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003E\\u003Ca href=\\\"http://pastebin.com/59MN5ryB\\\"\\u003Ehttp://pastebin.com/59MN5ryB\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEver since I moved to a new hosting server, I\\u0026#39;ve been getting that traceback after the bot has been running for ~8 hours or so.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EIt looks like there is some TypeError but I\\u0026#39;ve never seen it when I host on my machine :/\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"http://pastebin.com/59MN5ryB\\n\\nEver since I moved to a new hosting server, I've been getting that traceback after the bot has been running for ~8 hours or so.\\n\\nIt looks like there is some TypeError but I've never seen it when I host on my machine :/\\n\\n\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4rjm2m\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"GTAVbeastya\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4rjm2m/bots_were_at_one_point_crashing_with_a_forbidden/\", \"locked\": false, \"name\": \"t3_4rjm2m\", \"created\": 1467854495.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4rjm2m/bots_were_at_one_point_crashing_with_a_forbidden/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Bots were at one point crashing with a Forbidden error, now I'm getting this :/\", \"created_utc\": 1467825695.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EMy code:- \\nimport praw\\nr = praw.Reddit(user_agent=\\u0026#39;my_cool_application\\u0026#39;)\\nsubmissions = r.get_subreddit(\\u0026#39;AskReddit\\u0026#39;).get_hot(limit=25)\\nfor x in submissions:\\n    print x\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EIt prints just the comment and the title of each submission of \\u0026#39;AskReddit\\u0026#39;, how to print all the info like, url, domain, comments,etc too?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"My code:- \\nimport praw\\nr = praw.Reddit(user_agent='my_cool_application')\\nsubmissions = r.get_subreddit('AskReddit').get_hot(limit=25)\\nfor x in submissions:\\n\\tprint x\\n\\nIt prints just the comment and the title of each submission of 'AskReddit', how to print all the info like, url, domain, comments,etc too?\\n\\nThanks.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4rhsma\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"evilmage93\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4rhsma/prawpython_get_all_the_submissions_details_form_a/\", \"locked\": false, \"name\": \"t3_4rhsma\", \"created\": 1467828188.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4rhsma/prawpython_get_all_the_submissions_details_form_a/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW][PYTHON] Get all the submission's details form a subreddit.\", \"created_utc\": 1467799388.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi, I\\u0026#39;m not sure if this is expected behavior, or if I\\u0026#39;m doing something wrong (leaning toward the latter, because it\\u0026#39;s me).\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhen I go (in a browser) to the traffic/.json page of a subreddit where the traffic is marked as private, I can still view the json as long as I am a moderator of that subreddit.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHowever, when I try to do the same thing programmatically after authenticating as the same user, I get a 403 response. Switching the path to a subreddit whose traffic stats are public results in a successful 200 response.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ETest code is as follows, for what it\\u0026#39;s worth:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EHttpRequest request = client.request().host(\\u0026quot;www.reddit.com\\u0026quot;)\\n                .path(\\u0026quot;/r/analog/about/traffic.json\\u0026quot;)\\n                .build();\\n\\nRestResponse response = client.execute(request);\\nSystem.out.println(\\u0026quot;response status code: \\u0026quot;+response.getStatusCode());\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EIn this case, if I\\u0026#39;m logged in with a moderator account, I get a 403 even though I can paste the URL into a browser and see the response json just fine. I know I\\u0026#39;m authenticated correctly because I can perform other tasks just fine.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks in advance!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi, I'm not sure if this is expected behavior, or if I'm doing something wrong (leaning toward the latter, because it's me).\\n\\nWhen I go (in a browser) to the traffic/.json page of a subreddit where the traffic is marked as private, I can still view the json as long as I am a moderator of that subreddit.\\n\\nHowever, when I try to do the same thing programmatically after authenticating as the same user, I get a 403 response. Switching the path to a subreddit whose traffic stats are public results in a successful 200 response.\\n\\nTest code is as follows, for what it's worth:\\n\\n    HttpRequest request = client.request().host(\\\"www.reddit.com\\\")\\n\\t                .path(\\\"/r/analog/about/traffic.json\\\")\\n\\t                .build();\\n \\n    RestResponse response = client.execute(request);\\n    System.out.println(\\\"response status code: \\\"+response.getStatusCode());\\n\\nIn this case, if I'm logged in with a moderator account, I get a 403 even though I can paste the URL into a browser and see the response json just fine. I know I'm authenticated correctly because I can perform other tasks just fine.\\n\\nThanks in advance!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4rfol4\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"jeffk42\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4rfol4/getting_traffic_stats_from_subreddit_where_its/\", \"locked\": false, \"name\": \"t3_4rfol4\", \"created\": 1467791941.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4rfol4/getting_traffic_stats_from_subreddit_where_its/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Getting traffic stats from subreddit where it's marked private, but authenticated with moderator account (JRAW)\", \"created_utc\": 1467763141.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cpre\\u003E\\u003Ccode\\u003E\\u0026gt;\\u0026gt;\\u0026gt; r.get_mentions\\n\\u0026lt;bound method Reddit.get_mentions of \\u0026lt;praw.Reddit object         at 0x0000000003855F98\\u0026gt;\\u0026gt;\\n\\n\\u0026gt;\\u0026gt;\\u0026gt; r.get_mentions()\\n\\u0026lt;generator object get_content at 0x0000000004635F78\\u0026gt;\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"    \\u003E\\u003E\\u003E r.get_mentions\\n    \\u003Cbound method Reddit.get_mentions of \\u003Cpraw.Reddit object         at 0x0000000003855F98\\u003E\\u003E\\n\\n    \\u003E\\u003E\\u003E r.get_mentions()\\n    \\u003Cgenerator object get_content at 0x0000000004635F78\\u003E\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4rcbhc\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"123icebuggy\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4rcbhc/how_to_get_mentions_with_praw/\", \"locked\": false, \"name\": \"t3_4rcbhc\", \"created\": 1467748639.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4rcbhc/how_to_get_mentions_with_praw/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How to get mentions with praw?\", \"created_utc\": 1467719839.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESorry if this is an easy one, but I couldn\\u0026#39;t find a direct answer with my searches.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHere\\u0026#39;s a snippet of my code:  \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Esubmission.replace_more_comments(limit=None, threshold=0)\\nall_comments = submission.comments\\nfor comment in all_comments:    \\n    blah blah blah\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003E\\u0026quot;blah\\u0026quot; is where the action is. I\\u0026#39;m parsing 1000+ comments a thread and its taking up to 15 minutes on each cycle. Any way I can modify the above code to do the newest 100 comments?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EUsing Python and PRAW, btw. Thanks in advance.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Sorry if this is an easy one, but I couldn't find a direct answer with my searches.\\n\\nHere's a snippet of my code:  \\n\\n    submission.replace_more_comments(limit=None, threshold=0)\\n    all_comments = submission.comments\\n    for comment in all_comments:    \\n        blah blah blah\\n\\\"blah\\\" is where the action is. I'm parsing 1000+ comments a thread and its taking up to 15 minutes on each cycle. Any way I can modify the above code to do the newest 100 comments?\\n\\nUsing Python and PRAW, btw. Thanks in advance.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4r6d1g\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"zuffdaddy\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4r6d1g/need_bot_to_parse_the_last_100_new_comments_in/\", \"locked\": false, \"name\": \"t3_4r6d1g\", \"created\": 1467651203.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4r6d1g/need_bot_to_parse_the_last_100_new_comments_in/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Need bot to parse the last 100 new comments in submission\", \"created_utc\": 1467622403.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m writing a simple script to cache all of my saved (and will later maybe work on spidering out from that origin). But I\\u0026#39;m stuck on how to get the real type of a RedditContentObject.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhen I call get_saved(), I get a list of these. I know some of them are Comments and some of them are text submissions and others are link submissions, but how do I determine which an arbitrary RedditContentObject is? Do I really have to check the fullname? That seems so, so dirty. (Not to insult the devs if that really is the case. It\\u0026#39;s a wonderful library and I\\u0026#39;m very grateful for their work. I couldn\\u0026#39;t have architected it better myself, though that\\u0026#39;s not really saying much.)\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm writing a simple script to cache all of my saved (and will later maybe work on spidering out from that origin). But I'm stuck on how to get the real type of a RedditContentObject.\\n\\nWhen I call get_saved(), I get a list of these. I know some of them are Comments and some of them are text submissions and others are link submissions, but how do I determine which an arbitrary RedditContentObject is? Do I really have to check the fullname? That seems so, so dirty. (Not to insult the devs if that really is the case. It's a wonderful library and I'm very grateful for their work. I couldn't have architected it better myself, though that's not really saying much.)\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4r53vj\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"MengerianMango\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 5, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4r53vj/praw_how_do_i_determine_the_real_type_of/\", \"locked\": false, \"name\": \"t3_4r53vj\", \"created\": 1467628264.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4r53vj/praw_how_do_i_determine_the_real_type_of/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"PRAW: How do I determine the real type of arbitrary RedditContentObject?\", \"created_utc\": 1467599464.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo I\\u0026#39;ve just finished an app that works with Reddit, and have been using a script authorization through my username. Obviously, for release, I\\u0026#39;d like to change this to general purpose access, without having to log in or anything. All I need is for one of my services to read submissions from Reddit for a couple seconds, then it ends. I\\u0026#39;m not very familiar with authorization or tokens or any of that. If anyone could help me with the steps I need to take that would be amazing.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EFrom what I\\u0026#39;ve researched I need \\u0026quot;Installed App\\u0026quot; type access from Reddit (I\\u0026#39;m currently using \\u0026quot;Script\\u0026quot;). Here is the github for JRAW which I\\u0026#39;m using to connect \\u003Ca href=\\\"https://github.com/thatJavaNerd/JRAW/wiki\\\"\\u003Ehttps://github.com/thatJavaNerd/JRAW/wiki\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So I've just finished an app that works with Reddit, and have been using a script authorization through my username. Obviously, for release, I'd like to change this to general purpose access, without having to log in or anything. All I need is for one of my services to read submissions from Reddit for a couple seconds, then it ends. I'm not very familiar with authorization or tokens or any of that. If anyone could help me with the steps I need to take that would be amazing.\\n\\nFrom what I've researched I need \\\"Installed App\\\" type access from Reddit (I'm currently using \\\"Script\\\"). Here is the github for JRAW which I'm using to connect https://github.com/thatJavaNerd/JRAW/wiki\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4r4afe\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"tvm78\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4r4afe/help_with_oauth_authorization_using_jraw/\", \"locked\": false, \"name\": \"t3_4r4afe\", \"created\": 1467615535.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4r4afe/help_with_oauth_authorization_using_jraw/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Help with OAuth authorization using JRAW\", \"created_utc\": 1467586735.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EOr I am not finding it? I am thinking of building one. Any suggestions?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Or I am not finding it? I am thinking of building one. Any suggestions?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4r0r2a\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"procipher\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 9, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4r0r2a/why_theres_still_not_a_good_reddit_post_scheduler/\", \"locked\": false, \"name\": \"t3_4r0r2a\", \"created\": 1467551398.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4r0r2a/why_theres_still_not_a_good_reddit_post_scheduler/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Why there's still not a good reddit post scheduler app?\", \"created_utc\": 1467522598.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHello I\\u0026#39;m trying to create a bot to reply to a posts from a specific user in a specific subreddit. I have done the usual OAuth setup and the output of\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Er.refresh_access_information(access_info[\\u0026#39;refresh_token\\u0026#39;])\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Eshows \\u0026#39;scope\\u0026#39;: {\\u0026#39;edit\\u0026#39;, \\u0026#39;identity\\u0026#39;, \\u0026#39;read\\u0026#39;, \\u0026#39;submit\\u0026#39;}. But when I execute\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Euser = r.get_redditor(\\u0026#39;username\\u0026#39;)\\nfor thing in user.get_submitted(limit=5):\\n    if thing.subreddit.display_name == \\u0026#39;subreddit\\u0026#39;:\\n        thing.add_comment(\\u0026#39;test!\\u0026#39;)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Eit throws the OAuthInsufficientScope:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Einsufficient_scope on url https://oauth.reddit.com/user/username/submitted.json?limit=5\\u0026amp;sort=new\\u0026amp;t=all\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAnyone have any idea?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hello I'm trying to create a bot to reply to a posts from a specific user in a specific subreddit. I have done the usual OAuth setup and the output of\\n\\n    r.refresh_access_information(access_info['refresh_token'])\\n\\nshows 'scope': {'edit', 'identity', 'read', 'submit'}. But when I execute\\n\\n    user = r.get_redditor('username')\\n    for thing in user.get_submitted(limit=5):\\n        if thing.subreddit.display_name == 'subreddit':\\n            thing.add_comment('test!')\\n\\nit throws the OAuthInsufficientScope:\\n\\n    insufficient_scope on url https://oauth.reddit.com/user/username/submitted.json?limit=5\\u0026sort=new\\u0026t=all\\n\\nAnyone have any idea?\\n\\n    \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qx4gv\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"icp1994\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qx4gv/oauthinsufficientscope_praw_error/\", \"locked\": false, \"name\": \"t3_4qx4gv\", \"created\": 1467492926.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qx4gv/oauthinsufficientscope_praw_error/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"OAuthInsufficientScope praw error\", \"created_utc\": 1467464126.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EWhenever I try to get a random submission from \\u003Ca href=\\\"/r/awwnime\\\"\\u003E/r/awwnime\\u003C/a\\u003E using an unauthenticated client, I get this error:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E\\u0026gt;\\u0026gt;\\u0026gt; submission = r.get_random_submission(subreddit=\\u0026quot;awwnime\\u0026quot;)\\nTraceback (most recent call last):\\n  File \\u0026quot;\\u0026lt;pyshell#16\\u0026gt;\\u0026quot;, line 1, in \\u0026lt;module\\u0026gt;\\n    submission = r.get_random_submission(subreddit=\\u0026quot;awwnime\\u0026quot;)\\n  File \\u0026quot;[python3.5directory]\\\\lib\\\\site-packages\\\\praw\\\\__init__.py\\u0026quot;, line 983, in get_random_submission\\n    return objects.Submission.from_json(item)\\n  File \\u0026quot;[python3.5directory]\\\\lib\\\\site-packages\\\\praw\\\\objects.py\\u0026quot;, line 1075, in from_json\\n    submission = json_response[0][\\u0026#39;data\\u0026#39;][\\u0026#39;children\\u0026#39;][0]\\nKeyError: 0\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EHowever, getting a random submission from \\u003Ca href=\\\"/r/aww\\\"\\u003E/r/aww\\u003C/a\\u003E works without any hiccups.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EIt seems like it\\u0026#39;s requesting \\u003Ccode\\u003Ehttps://api.reddit.com/r/awwnime/random/\\u003C/code\\u003E and \\u003Ccode\\u003Ehttps://api.reddit.com/r/aww/random/\\u003C/code\\u003E respectively. However, the former redirects to \\u003Ccode\\u003Ehttps://www.reddit.com/r/awwnime/.api\\u003C/code\\u003E, while the latter redirects to \\u003Ccode\\u003Ehttps://www.reddit.com/r/aww/comments/thing_id/title/.api\\u003C/code\\u003E. Is there any way around this, other than catching a KeyError and doing a \\u003Ccode\\u003Erandom.choice\\u003C/code\\u003E from the submissions in \\u0026quot;new\\u0026quot;?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEdit: Related to this: requesting \\u003Ccode\\u003Ehttps://api.reddit.com/r/aww+awwnime/random/\\u003C/code\\u003Ewill result in submission from only \\u003Ca href=\\\"/r/aww\\\"\\u003E/r/aww\\u003C/a\\u003E, none from \\u003Ca href=\\\"/r/awwnime\\\"\\u003E/r/awwnime\\u003C/a\\u003E.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Whenever I try to get a random submission from /r/awwnime using an unauthenticated client, I get this error:\\n\\n    \\u003E\\u003E\\u003E submission = r.get_random_submission(subreddit=\\\"awwnime\\\")\\n    Traceback (most recent call last):\\n      File \\\"\\u003Cpyshell#16\\u003E\\\", line 1, in \\u003Cmodule\\u003E\\n        submission = r.get_random_submission(subreddit=\\\"awwnime\\\")\\n      File \\\"[python3.5directory]\\\\lib\\\\site-packages\\\\praw\\\\__init__.py\\\", line 983, in get_random_submission\\n        return objects.Submission.from_json(item)\\n      File \\\"[python3.5directory]\\\\lib\\\\site-packages\\\\praw\\\\objects.py\\\", line 1075, in from_json\\n        submission = json_response[0]['data']['children'][0]\\n    KeyError: 0\\n\\nHowever, getting a random submission from /r/aww works without any hiccups.\\n\\nIt seems like it's requesting `https://api.reddit.com/r/awwnime/random/` and `https://api.reddit.com/r/aww/random/` respectively. However, the former redirects to `https://www.reddit.com/r/awwnime/.api`, while the latter redirects to `https://www.reddit.com/r/aww/comments/thing_id/title/.api`. Is there any way around this, other than catching a KeyError and doing a `random.choice` from the submissions in \\\"new\\\"?\\n\\nEdit: Related to this: requesting `https://api.reddit.com/r/aww+awwnime/random/`will result in submission from only /r/aww, none from /r/awwnime.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qwruc\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"mcpower_\", \"media\": null, \"score\": 4, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1467456282.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qwruc/praw_350_keyerror_0_when_getting_random_submission/\", \"locked\": false, \"name\": \"t3_4qwruc\", \"created\": 1467484895.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qwruc/praw_350_keyerror_0_when_getting_random_submission/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"PRAW 3.5.0: \\\"KeyError: 0\\\" when getting random submission\", \"created_utc\": 1467456095.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 4}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m logged into Reddit using OAuth, using the scopes \\u0026quot;identity\\u0026quot; and \\u0026quot;privatemessages\\u0026quot;. The functions \\u003Ccode\\u003Er.is_oauth_session\\u003C/code\\u003E and \\u003Ccode\\u003Er.has_scope(\\u0026#39;privatemessages\\u0026#39;)\\u003C/code\\u003E confirm this. However, using the \\u003Ccode\\u003Eme.get_messages()\\u003C/code\\u003E function, as well as others corresponding to the \\u003Ccode\\u003EPrivateMessagesMixin\\u003C/code\\u003E class, do not work, giving the error that the function is not defined.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm logged into Reddit using OAuth, using the scopes \\\"identity\\\" and \\\"privatemessages\\\". The functions `r.is_oauth_session` and `r.has_scope('privatemessages')` confirm this. However, using the `me.get_messages()` function, as well as others corresponding to the `PrivateMessagesMixin` class, do not work, giving the error that the function is not defined.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qvjel\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"IamCarbonMan\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qvjel/praw_class_prawobjectsloggedinredditor_has_no/\", \"locked\": false, \"name\": \"t3_4qvjel\", \"created\": 1467458333.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qvjel/praw_class_prawobjectsloggedinredditor_has_no/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] Class 'praw.objects.LoggedInRedditor' has no attribute 'get_messages'\", \"created_utc\": 1467429533.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EJust set up a reddit on my server and made some test postings and added some comment. But i can not see the comments:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"http://imgur.com/qKY0tIj\\\"\\u003Ehttp://imgur.com/qKY0tIj\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Just set up a reddit on my server and made some test postings and added some comment. But i can not see the comments:\\n\\nhttp://imgur.com/qKY0tIj\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qt3o9\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"bitsworks\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qt3o9/where_are_the_comments/\", \"locked\": false, \"name\": \"t3_4qt3o9\", \"created\": 1467424854.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qt3o9/where_are_the_comments/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Where are the comments?\", \"created_utc\": 1467396054.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi, i get an 500 error when someone tries to sign up.\\nI checked exim (should run) and i uncommented the mail function in the cron.\\nAndy ideas?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi, i get an 500 error when someone tries to sign up.\\nI checked exim (should run) and i uncommented the mail function in the cron.\\nAndy ideas?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qr66q\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"bitsworks\", \"media\": null, \"score\": 4, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qr66q/error_500_on_signup/\", \"locked\": false, \"name\": \"t3_4qr66q\", \"created\": 1467399831.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qr66q/error_500_on_signup/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Error 500 on signup\", \"created_utc\": 1467371031.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 4}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EAre there any live reddit-clone sites based on reddit-dev?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Are there any live reddit-clone sites based on reddit-dev?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qr4zj\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"bitsworks\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qr4zj/are_there_any_live_redditclone_sites/\", \"locked\": false, \"name\": \"t3_4qr4zj\", \"created\": 1467399234.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qr4zj/are_there_any_live_redditclone_sites/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Are there any live reddit-clone sites?\", \"created_utc\": 1467370434.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m getting a lot of HTTP error 502 and 503 on OAuth access.  But regular web browsing looks 100% fine.  I didn\\u0026#39;t know that could happen (obviously).  Is this a hint that I\\u0026#39;m inadvertently being a bad citizen, or should I just turn off my bot and wait?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm getting a lot of HTTP error 502 and 503 on OAuth access.  But regular web browsing looks 100% fine.  I didn't know that could happen (obviously).  Is this a hint that I'm inadvertently being a bad citizen, or should I just turn off my bot and wait?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qn0jb\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"CogitoErgoReddit\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qn0jb/502s_and_503s_on_oauth_while_regular_www_access/\", \"locked\": false, \"name\": \"t3_4qn0jb\", \"created\": 1467338018.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qn0jb/502s_and_503s_on_oauth_while_regular_www_access/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"502's and 503's on OAuth, while regular www access looks fine. Is it me or reddit?\", \"created_utc\": 1467309218.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI have been doing some data mining from the sketchdaily subreddit. I know that there are one thread each day, but when I use the cloudsearch syntax to get some of the older posts, there are gaps in the results.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EFor example \\u003Ca href=\\\"https://www.reddit.com/r/SketchDaily/search?q=timestamp%3A1293840000..1304208000\\u0026amp;sort=new\\u0026amp;restrict_sr=on\\u0026amp;rank=title\\u0026amp;syntax=cloudsearch\\\"\\u003Ethis search of all posts from April 1st to May 1st 2011\\u003C/a\\u003E is missing several results.\\u003Cbr/\\u003E\\n\\u003Ca href=\\\"https://www.reddit.com/r/SketchDaily/comments/glawv/april_8th_sir_memes_alot/\\\"\\u003ELike this post from April the 8th\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECan anyone give an explanation of this, or even better find a way to get ALL the posts.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi\\n\\nI have been doing some data mining from the sketchdaily subreddit. I know that there are one thread each day, but when I use the cloudsearch syntax to get some of the older posts, there are gaps in the results.\\n\\nFor example [this search of all posts from April 1st to May 1st 2011](https://www.reddit.com/r/SketchDaily/search?q=timestamp%3A1293840000..1304208000\\u0026sort=new\\u0026restrict_sr=on\\u0026rank=title\\u0026syntax=cloudsearch) is missing several results.  \\n[Like this post from April the 8th](https://www.reddit.com/r/SketchDaily/comments/glawv/april_8th_sir_memes_alot/)\\n\\nCan anyone give an explanation of this, or even better find a way to get ALL the posts.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qf1ur\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"KnightofniDK\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qf1ur/search_does_not_return_all_results/\", \"locked\": false, \"name\": \"t3_4qf1ur\", \"created\": 1467229197.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qf1ur/search_does_not_return_all_results/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Search does not return all results\", \"created_utc\": 1467200397.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EThe particular error is:  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u0026quot;praw.errors.RateLimitExceeded: \\u003Ccode\\u003Eyou are doing that too much. try again in 5 minutes.\\u003C/code\\u003E on field \\u003Ccode\\u003Eratelimit\\u003C/code\\u003E\\u0026quot;\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EConsidering this is a test script that only sends one submission I am at a loss to know why its rate limited?  Or can bots only make one post every 5 minutes or something?  I\\u0026#39;m currently only posting on  testing subreddits. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI even got an error while trying to submit this post.  \\u0026quot;you are doing that too much. try again in 1 minute.\\u0026quot;  Is this just a limitation of reddit or is it something else?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAlso see related post: \\u003Ca href=\\\"https://www.reddit.com/r/NewsOnReddit/comments/4qdxpf/logos_bot_test/\\\"\\u003Ehttps://www.reddit.com/r/NewsOnReddit/comments/4qdxpf/logos_bot_test/\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI guess I should also point out that I\\u0026#39;ve got a web interface to this bot and one of the things this app can do is manually submit posts to subreddits.  That is a human fills in a form.  The posts are not sent to reddit immediately but are submitted in a cron job later.  Thus 10 minutes per post rate limit seems a bit harsh.  Especially if there is a back log of 20 posts or so.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"The particular error is:  \\n\\n\\\"praw.errors.RateLimitExceeded: `you are doing that too much. try again in 5 minutes.` on field `ratelimit`\\\"\\n\\nConsidering this is a test script that only sends one submission I am at a loss to know why its rate limited?  Or can bots only make one post every 5 minutes or something?  I'm currently only posting on  testing subreddits. \\n\\nI even got an error while trying to submit this post.  \\\"you are doing that too much. try again in 1 minute.\\\"  Is this just a limitation of reddit or is it something else?\\n\\nAlso see related post: https://www.reddit.com/r/NewsOnReddit/comments/4qdxpf/logos_bot_test/\\n\\nI guess I should also point out that I've got a web interface to this bot and one of the things this app can do is manually submit posts to subreddits.  That is a human fills in a form.  The posts are not sent to reddit immediately but are submitted in a cron job later.  Thus 10 minutes per post rate limit seems a bit harsh.  Especially if there is a back log of 20 posts or so.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qdvju\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"kiwiheretic\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1467181892.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qdvju/what_does_ratelimit_error_mean/\", \"locked\": false, \"name\": \"t3_4qdvju\", \"created\": 1467205718.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qdvju/what_does_ratelimit_error_mean/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"what does ratelimit error mean?\", \"created_utc\": 1467176918.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIt was mentioned in the announcement that there would be an mp4 saved for the gif but I couldn\\u0026#39;t find a clear connection between the urls.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://www.reddit.com/r/announcements/comments/4p5dm9/slug/d4i4gsf\\\"\\u003Ehttps://www.reddit.com/r/announcements/comments/4p5dm9/slug/d4i4gsf\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI currently have a script for taking me to the mp4 or webm version for imgur and gfycat, but I\\u0026#39;m not sure how this works for the reddit version. I tried reading that post yesterday, but when I look at the urls, they don\\u0026#39;t look similar. The links shown below are from the comments provided by the admin.\\u003C/p\\u003E\\n\\n\\u003Cblockquote\\u003E\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://i.redd.it/n9bxbvu2kzyw.gif\\\"\\u003Ehttps://i.redd.it/n9bxbvu2kzyw.gif\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://g.redditmedia.com/hQTce5W89lZLiVRIZ3OD6cA8ICSTus3rVrK6bjSl9QI.gif?w=800\\u0026amp;fm=mp4\\u0026amp;mp4-fragmented=false\\u0026amp;s=8d091f67137b9ea46a7096dc0fb6f41e\\\"\\u003Ehttps://g.redditmedia.com/hQTce5W89lZLiVRIZ3OD6cA8ICSTus3rVrK6bjSl9QI.gif?w=800\\u0026amp;fm=mp4\\u0026amp;mp4-fragmented=false\\u0026amp;s=8d091f67137b9ea46a7096dc0fb6f41e\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/blockquote\\u003E\\n\\n\\u003Cp\\u003EHow do I get the mp4 version from the first link provided? I just need this information so I can update my script.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"It was mentioned in the announcement that there would be an mp4 saved for the gif but I couldn't find a clear connection between the urls.\\n\\nhttps://www.reddit.com/r/announcements/comments/4p5dm9/slug/d4i4gsf\\n\\nI currently have a script for taking me to the mp4 or webm version for imgur and gfycat, but I'm not sure how this works for the reddit version. I tried reading that post yesterday, but when I look at the urls, they don't look similar. The links shown below are from the comments provided by the admin.\\n\\n\\u003Ehttps://i.redd.it/n9bxbvu2kzyw.gif\\n\\n\\u003Ehttps://g.redditmedia.com/hQTce5W89lZLiVRIZ3OD6cA8ICSTus3rVrK6bjSl9QI.gif?w=800\\u0026fm=mp4\\u0026mp4-fragmented=false\\u0026s=8d091f67137b9ea46a7096dc0fb6f41e\\n\\nHow do I get the mp4 version from the first link provided? I just need this information so I can update my script.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qd6w5\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"ekfslam\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qd6w5/how_do_people_change_the_new_reddit_gif_links_to/\", \"locked\": false, \"name\": \"t3_4qd6w5\", \"created\": 1467195131.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qd6w5/how_do_people_change_the_new_reddit_gif_links_to/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How do people change the new reddit gif links to mp4 links? Like imgur does with gif to gifv\", \"created_utc\": 1467166331.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;ve been working on a bot that just reads in my own accounts comments. I have been writing this in php and so far have OAuth working and I can access the /me api endpoint. Now I\\u0026#39;m looking to get a list of all my comments, and I figured the /user/username/comments endpoint would work here, but I\\u0026#39;m getting a 400 (bad request) error.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI don\\u0026#39;t believe I have any error with the code seeing as the first request is working properly. The same code is being reused for the other request with the access token being passed in the same way as the first request.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EIs this a scope issue? Or something else I\\u0026#39;m not seeing?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m willing to post code bits of any of the suggestions aren\\u0026#39;t working (or at request).\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I've been working on a bot that just reads in my own accounts comments. I have been writing this in php and so far have OAuth working and I can access the /me api endpoint. Now I'm looking to get a list of all my comments, and I figured the /user/username/comments endpoint would work here, but I'm getting a 400 (bad request) error.\\n\\nI don't believe I have any error with the code seeing as the first request is working properly. The same code is being reused for the other request with the access token being passed in the same way as the first request.\\n\\nIs this a scope issue? Or something else I'm not seeing?\\n\\nI'm willing to post code bits of any of the suggestions aren't working (or at request).\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qd1ox\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"thespacenoodles\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qd1ox/getting_a_users_comments/\", \"locked\": false, \"name\": \"t3_4qd1ox\", \"created\": 1467193122.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qd1ox/getting_a_users_comments/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Getting a users comments\", \"created_utc\": 1467164322.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI have the following script to fetch new posts on reddit using Praw:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Edef reddit_maintenance(self, port, subcommand):\\n    if subcommand == \\u0026quot;commentsonly\\u0026quot;:\\n        self.authenticate(port)\\n        self.get_comments()\\n    elif subcommand == None:\\n        self.authenticate(port)\\n        self.my_subreddits()\\n        self.get_submissions()\\n\\ndef authenticate(self, port):\\n    site = Site.objects.get(pk=settings.SITE_ID)\\n    self.r = praw.Reddit(\\u0026#39;Heretical v0.1 by /u/kiwiheretic \\u0026#39;\\n            \\u0026#39;https://github.com/kiwiheretic/logos-v2 for source\\u0026#39;)\\n    consumer_key = get_global_option(\\u0026#39;reddit-consumer-key\\u0026#39;)\\n    consumer_secret = get_global_option(\\u0026#39;reddit-consumer-secret\\u0026#39;)\\n    redirect_uri = \\u0026#39;http://\\u0026#39; + site.domain\\n    if port:\\n        redirect_uri += \\u0026quot;:\\u0026quot;+str(port)\\n    redirect_uri += \\u0026#39;/reddit/oauth-callback/\\u0026#39;\\n    self.r.set_oauth_app_info(client_id=consumer_key,\\n             client_secret=consumer_secret,\\n             redirect_uri=redirect_uri)\\n\\ndef get_submissions(self):\\n    for subr in Subreddits.objects.all():\\n        sr = self.r.get_subreddit(subr.display_name)\\n        last_sub = Submission.objects.filter(subreddit = subr).order_by(\\u0026#39;-created_at\\u0026#39;).first()\\n        if last_sub:\\n            thing = last_sub.name\\n        else:\\n            thing = None\\n        for sub in sr.get_new(limit=1000, params={\\u0026#39;after\\u0026#39;:thing}):\\n            # Don\\u0026#39;t save deleted posts (ie. author is blank)\\n            # https://www.reddit.com/r/redditdev/comments/1630jj/praw_is_returning_postauthorname_errors/c7s8zx9\\n            if not sub.author: continue\\n\\n            cdate = datetime.datetime.fromtimestamp(\\n                            int(sub.created_utc)\\n                                )\\n            udate = timezone.make_aware(cdate, timezone = pytz.utc)\\n            print sub.name, udate, sub.num_comments, repr(sub.title)\\n            try:\\n                post = Submission(name = sub.name,\\n                        created_at = udate,\\n                        subreddit = subr,\\n                        title = sub.title,\\n                        author = sub.author,\\n                        body = sub.selftext,\\n                        url = sub.url,\\n                        score = sub.score,\\n                        link_flair_text = sub.link_flair_text,\\n                        num_comments = sub.num_comments)\\n                post.save()\\n            except IntegrityError:\\n                if Submission.objects.filter(name = sub.name).exists():\\n                    print \\u0026quot;{} already exists\\u0026quot;.format(sub.name)\\n                else:\\n                    print \\u0026quot;Error: Could not insert {} {}\\u0026quot;.format(sub.name, sub.title)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EHowever I keep striking duplicates when inserting new submissions into local database.  Is there a way to avoid this?  My \\u0026#39;after\\u0026#39; field doesn\\u0026#39;t seem to be working as expected.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAn excerpt of the output I am getting:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E```\\nt3_4c5pte 2016-03-27 14:29:50+00:00 3 u\\u0026#39;HAPPY EASTER!!\\u0026#39;\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Et3_4c5pte already exists\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Et3_4c3hdo 2016-03-26 23:49:34+00:00 3 u\\u0026#39;Sermon translation.\\u0026#39;\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Et3_4c3hdo already exists\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Et3_4c34dc 2016-03-26 22:11:00+00:00 9 u\\u0026#39;Have any of you guys experienced \\u0026quot;visions\\u0026quot;?\\u0026#39;\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Et3_4c34dc already exists\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E```\\nJust not sure why I seem to be striking so many duplicates.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I have the following script to fetch new posts on reddit using Praw:\\n\\n    def reddit_maintenance(self, port, subcommand):\\n        if subcommand == \\\"commentsonly\\\":\\n            self.authenticate(port)\\n            self.get_comments()\\n        elif subcommand == None:\\n            self.authenticate(port)\\n            self.my_subreddits()\\n            self.get_submissions()\\n\\n    def authenticate(self, port):\\n        site = Site.objects.get(pk=settings.SITE_ID)\\n        self.r = praw.Reddit('Heretical v0.1 by /u/kiwiheretic '\\n                'https://github.com/kiwiheretic/logos-v2 for source')\\n        consumer_key = get_global_option('reddit-consumer-key')\\n        consumer_secret = get_global_option('reddit-consumer-secret')\\n        redirect_uri = 'http://' + site.domain\\n        if port:\\n            redirect_uri += \\\":\\\"+str(port)\\n        redirect_uri += '/reddit/oauth-callback/'\\n        self.r.set_oauth_app_info(client_id=consumer_key,\\n                 client_secret=consumer_secret,\\n                 redirect_uri=redirect_uri)\\n\\n    def get_submissions(self):\\n        for subr in Subreddits.objects.all():\\n            sr = self.r.get_subreddit(subr.display_name)\\n            last_sub = Submission.objects.filter(subreddit = subr).order_by('-created_at').first()\\n            if last_sub:\\n                thing = last_sub.name\\n            else:\\n                thing = None\\n            for sub in sr.get_new(limit=1000, params={'after':thing}):\\n                # Don't save deleted posts (ie. author is blank)\\n                # https://www.reddit.com/r/redditdev/comments/1630jj/praw_is_returning_postauthorname_errors/c7s8zx9\\n                if not sub.author: continue\\n\\n                cdate = datetime.datetime.fromtimestamp(\\n                                int(sub.created_utc)\\n                                    )\\n                udate = timezone.make_aware(cdate, timezone = pytz.utc)\\n                print sub.name, udate, sub.num_comments, repr(sub.title)\\n                try:\\n                    post = Submission(name = sub.name,\\n                            created_at = udate,\\n                            subreddit = subr,\\n                            title = sub.title,\\n                            author = sub.author,\\n                            body = sub.selftext,\\n                            url = sub.url,\\n                            score = sub.score,\\n                            link_flair_text = sub.link_flair_text,\\n                            num_comments = sub.num_comments)\\n                    post.save()\\n                except IntegrityError:\\n                    if Submission.objects.filter(name = sub.name).exists():\\n                        print \\\"{} already exists\\\".format(sub.name)\\n                    else:\\n                        print \\\"Error: Could not insert {} {}\\\".format(sub.name, sub.title)\\n\\nHowever I keep striking duplicates when inserting new submissions into local database.  Is there a way to avoid this?  My 'after' field doesn't seem to be working as expected.\\n\\nAn excerpt of the output I am getting:\\n\\n```\\nt3_4c5pte 2016-03-27 14:29:50+00:00 3 u'HAPPY EASTER!!'\\n\\nt3_4c5pte already exists\\n\\nt3_4c3hdo 2016-03-26 23:49:34+00:00 3 u'Sermon translation.'\\n\\nt3_4c3hdo already exists\\n\\nt3_4c34dc 2016-03-26 22:11:00+00:00 9 u'Have any of you guys experienced \\\"visions\\\"?'\\n\\nt3_4c34dc already exists\\n\\n```\\nJust not sure why I seem to be striking so many duplicates.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4qb85w\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"kiwiheretic\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 13, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1467141594.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4qb85w/how_to_fetch_new_posts_only/\", \"locked\": false, \"name\": \"t3_4qb85w\", \"created\": 1467170212.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4qb85w/how_to_fetch_new_posts_only/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How to fetch new posts only?\", \"created_utc\": 1467141412.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI need to move the \\u003Ca href=\\\"https://github.com/reddit/reddit/blob/master/r2/r2/templates/sidebox.html#L26-31\\\"\\u003Esubmit link and submit text buttons from the right sidebar\\u003C/a\\u003E to the \\u003Ca href=\\\"https://github.com/reddit/reddit/blob/master/r2/r2/templates/listingchooser.html\\\"\\u003Eleft sidebar.\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHow can I do this?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I need to move the [submit link and submit text buttons from the right sidebar](https://github.com/reddit/reddit/blob/master/r2/r2/templates/sidebox.html#L26-31) to the [left sidebar.](https://github.com/reddit/reddit/blob/master/r2/r2/templates/listingchooser.html)\\n\\nHow can I do this?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4q7t69\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"devnoob23\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4q7t69/how_can_i_move_the_submit_buttons_from_the_right/\", \"locked\": false, \"name\": \"t3_4q7t69\", \"created\": 1467120171.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4q7t69/how_can_i_move_the_submit_buttons_from_the_right/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How can I move the submit buttons from the right sidebar to the left sidebar?\", \"created_utc\": 1467091371.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EWhen I try to install praw on my mac I keep getting this error:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EOSError: [Errno 1] Operation not permitted: \\u0026#39;/var/folders/v6/j4fk0zqn3_s9t2lr93q4x2vw0000gn/T/pip-FGZVVU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info\\u0026#39;\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI have tried using sudo and have also downloaded python 3.5 to see it that makes a difference. Please help me\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"When I try to install praw on my mac I keep getting this error:\\n\\nOSError: [Errno 1] Operation not permitted: '/var/folders/v6/j4fk0zqn3_s9t2lr93q4x2vw0000gn/T/pip-FGZVVU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info'\\n\\nI have tried using sudo and have also downloaded python 3.5 to see it that makes a difference. Please help me\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4q7hq5\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"PizzaJose\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4q7hq5/praw_i_get_an_error_when_i_try_to_install_praw_on/\", \"locked\": false, \"name\": \"t3_4q7hq5\", \"created\": 1467114895.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4q7hq5/praw_i_get_an_error_when_i_try_to_install_praw_on/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] I get an error when I try to install praw on my mac\", \"created_utc\": 1467086095.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHello! I was just have 2 questions regarding the function. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003E1) For the function get_subreddit_recommendations(subreddits, omit=None), how does the algorithm work? I know that it says that \\u0026quot;Subreddits with activity less than a certain threshold,\\u0026quot;. But I don\\u0026#39;t understand how the algorithm would measure the activity. Is it by # of post posted by hour? or something like that.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E2) How does the function get_popular_subreddits(\\u003Cem\\u003Eargs, *\\u003C/em\\u003Ekwargs) work? It does seem like it returns the subreddit regarding their reader numbers. So the most large number of subredditer would be expected to be returned as the most popular is this true? \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"\\nHello! I was just have 2 questions regarding the function. \\n\\n1) For the function get_subreddit_recommendations(subreddits, omit=None), how does the algorithm work? I know that it says that \\\"Subreddits with activity less than a certain threshold,\\\". But I don't understand how the algorithm would measure the activity. Is it by # of post posted by hour? or something like that.\\n\\n2) How does the function get_popular_subreddits(*args, **kwargs) work? It does seem like it returns the subreddit regarding their reader numbers. So the most large number of subredditer would be expected to be returned as the most popular is this true? \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4q3a0u\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"ThisisJae2\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4q3a0u/praw_2_question_regarding_the_back_end_of_the/\", \"locked\": false, \"name\": \"t3_4q3a0u\", \"created\": 1467062318.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4q3a0u/praw_2_question_regarding_the_back_end_of_the/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] 2 Question regarding the back end of the wrapper.\", \"created_utc\": 1467033518.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EWhen I do a user.get_comments(limit = \\u0026quot;none\\u0026quot;), it does get all comments. But the comments appear to be rather chipped off when I write them to a file. I get one or two lines of the comment and not the whole comment.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI did go through the docs, but did not find anything covering this up. Any help?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"When I do a user.get_comments(limit = \\\"none\\\"), it does get all comments. But the comments appear to be rather chipped off when I write them to a file. I get one or two lines of the comment and not the whole comment.\\n\\nI did go through the docs, but did not find anything covering this up. Any help?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4q2k2b\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"NonResidingMartian\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 8, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4q2k2b/praw_help_me_understand_how_get_comments_works/\", \"locked\": false, \"name\": \"t3_4q2k2b\", \"created\": 1467049511.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4q2k2b/praw_help_me_understand_how_get_comments_works/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] Help me understand how get_comments() works?\", \"created_utc\": 1467020711.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHey guys, \\u003C/p\\u003E\\n\\n\\u003Cp\\u003ESo I\\u0026#39;m trying to work on a reddit bot that will search \\u003Ca href=\\\"/r/listentothis\\\"\\u003E/r/listentothis\\u003C/a\\u003E and based on the genre in a given post title send me a message to my user account from my bots account.  My code i sbelow and for some reason only returns the first submission. Can anyone point me in the right direction?\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E# Create a user agent and log into Reddit\\nUA = \\u0026#39;OZBOZZ v0.1\\u0026#39;\\nr = praw.Reddit(UA)\\n# Log in as bot with UA\\n\\u0026lt;Not here, duh\\u0026gt;\\n#Set Subreddit as /r/listentothis\\nsubreddit = r.get_subreddit(\\u0026#39;listentothis\\u0026#39;)\\n\\nwhile True:\\n    for submission in subreddit.get_new(limit=20):\\n        print(submission.title)\\n        exit()\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003E\\u003Cstrong\\u003EDisclosure\\u003C/strong\\u003E : I am very new to programming \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hey guys, \\n\\nSo I'm trying to work on a reddit bot that will search /r/listentothis and based on the genre in a given post title send me a message to my user account from my bots account.  My code i sbelow and for some reason only returns the first submission. Can anyone point me in the right direction?\\n\\n    # Create a user agent and log into Reddit\\n    UA = 'OZBOZZ v0.1'\\n    r = praw.Reddit(UA)\\n    # Log in as bot with UA\\n    \\u003CNot here, duh\\u003E\\n    #Set Subreddit as /r/listentothis\\n    subreddit = r.get_subreddit('listentothis')\\n\\n    while True:\\n        for submission in subreddit.get_new(limit=20):\\n            print(submission.title)\\n            exit()\\n\\n\\n\\n**Disclosure** : I am very new to programming \\n\\n\\n\\n\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4q23xj\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"OZPRI\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4q23xj/praw_only_getting_1_post_from_subreddit_despite/\", \"locked\": false, \"name\": \"t3_4q23xj\", \"created\": 1467040278.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4q23xj/praw_only_getting_1_post_from_subreddit_despite/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] Only getting 1 Post from subreddit despite setting limit much higher\", \"created_utc\": 1467011478.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EAll the other threads I can find on this all just say to make sure you call \\u003Ccode\\u003Emark_as_read()\\u003C/code\\u003E on the message, but \\u003Cem\\u003EI am\\u003C/em\\u003E, so I don\\u0026#39;t know what\\u0026#39;s going wrong. I have a wrapper function that looks like this:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Edef get_messages(self):\\n  messages = []\\n  for message in self.reddit.get_unread(update_user=True,\\n                                        unset_has_mail=True):\\n    message.mark_as_read()\\n    messages.append(message)\\n  return messages\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EWhen it runs, it gets the new unread messages, then the next iteration it gets the same messages again. What\\u0026#39;s going on? A few iterations later it stops returning the messages. It seems like some kind of caching issue, but I have no idea whats causing it or how to fix it. \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"All the other threads I can find on this all just say to make sure you call `mark_as_read()` on the message, but *I am*, so I don't know what's going wrong. I have a wrapper function that looks like this:\\n\\n    def get_messages(self):\\n      messages = []\\n      for message in self.reddit.get_unread(update_user=True,\\n                                            unset_has_mail=True):\\n        message.mark_as_read()\\n        messages.append(message)\\n      return messages\\n\\nWhen it runs, it gets the new unread messages, then the next iteration it gets the same messages again. What's going on? A few iterations later it stops returning the messages. It seems like some kind of caching issue, but I have no idea whats causing it or how to fix it. \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4q1dil\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Amablue\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4q1dil/praw_get_unread_is_returning_messages_it_has/\", \"locked\": false, \"name\": \"t3_4q1dil\", \"created\": 1467027708.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4q1dil/praw_get_unread_is_returning_messages_it_has/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] get_unread is returning messages it has already processed\", \"created_utc\": 1466998908.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI have the \\u003Ca href=\\\"https://www.reddit.com/r/bigquery/comments/3cej2b/17_billion_reddit_comments_loaded_on_bigquery/\\\"\\u003Eexample dataset\\u003C/a\\u003E of \\u003Ca href=\\\"/u/fhoofa\\\"\\u003Eu/fhoofa\\u003C/a\\u003E. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe dataset has the subreddit_id in it, but not the fitting subreddit name. How can you get the name, just with the id?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I have the [example dataset](https://www.reddit.com/r/bigquery/comments/3cej2b/17_billion_reddit_comments_loaded_on_bigquery/) of u/fhoofa. \\n\\nThe dataset has the subreddit_id in it, but not the fitting subreddit name. How can you get the name, just with the id?\\n\\nThanks\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4pxmcf\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"8byt3\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4pxmcf/convert_subreddit_id_into_subreddit_name/\", \"locked\": false, \"name\": \"t3_4pxmcf\", \"created\": 1466974154.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4pxmcf/convert_subreddit_id_into_subreddit_name/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Convert Subreddit_Id into Subreddit name?\", \"created_utc\": 1466945354.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": null, \"selftext\": \"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4pxltb\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Shubbler\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4pxltb/praw_how_do_i_get_a_redditors_account_creation/\", \"locked\": false, \"name\": \"t3_4pxltb\", \"created\": 1466973876.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4pxltb/praw_how_do_i_get_a_redditors_account_creation/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] How do I get a Redditor's account creation date?\", \"created_utc\": 1466945076.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI am writing a bot that logs into my account and upvotes/replies to every comment or submission of another user. I want to use \\u003Ccode\\u003Euser.get_comments(after=\\u0026lt;comment id\\u0026gt;)\\u003C/code\\u003E to iterate over comments newer than whatever I last saw, the id of the last comment will be cached to disk. However, this method does not seem to do what I want, or work the way I think it does.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EFor example, if I (using my own account for this example) get the id of my 3rd most recent comment using:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E for comment in me.get_comments(sort=u\\u0026#39;new\\u0026#39;,limit=3):\\n    print(comment.id)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Ethen I find that the id in question is \\u0026#39;d4mwlmu\\u0026#39;. But when I do\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Efor comment in me.get_comments(sort=u\\u0026#39;new\\u0026#39;,after=\\u0026#39;d4mwlmu\\u0026#39;):\\n    print(comment.id)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EIt simply returns my 25 most recent comments. Why is this happening and how can I get only comments that are newer (in terms of time submitted) than a specific one?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I am writing a bot that logs into my account and upvotes/replies to every comment or submission of another user. I want to use `user.get_comments(after=\\u003Ccomment id\\u003E)` to iterate over comments newer than whatever I last saw, the id of the last comment will be cached to disk. However, this method does not seem to do what I want, or work the way I think it does.\\n\\nFor example, if I (using my own account for this example) get the id of my 3rd most recent comment using:\\n\\n     for comment in me.get_comments(sort=u'new',limit=3):\\n        print(comment.id)\\n\\nthen I find that the id in question is 'd4mwlmu'. But when I do\\n\\n    for comment in me.get_comments(sort=u'new',after='d4mwlmu'):\\n        print(comment.id)\\n\\nIt simply returns my 25 most recent comments. Why is this happening and how can I get only comments that are newer (in terms of time submitted) than a specific one?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ptzuj\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"IamCarbonMan\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ptzuj/praw_how_to_get_a_redditors_comments_or/\", \"locked\": false, \"name\": \"t3_4ptzuj\", \"created\": 1466911943.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ptzuj/praw_how_to_get_a_redditors_comments_or/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] How to get a redditor's comments or submissions in sequential order, (only on those that have not been seen?)\", \"created_utc\": 1466883143.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m using PRAW to get my most recent comment id. Here\\u0026#39;s my code so far:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Eimport pickle\\nimport praw\\n\\nuser_agent = \\u0026#39;SomethingSomethingUserAgent\\u0026#39;\\nclient_id = \\u0026#39;SomethingSomethingClientID\\u0026#39;\\nclient_secret = \\u0026#39;SomethingSomethingClientSecret\\u0026#39;\\nredirect_uri = \\u0026#39;http://127.0.0.1:65010/authorize_callback\\u0026#39;\\n\\nwith open(\\u0026#39;oauth\\u0026#39;,\\u0026#39;rb\\u0026#39;) as fp:\\n    creds = pickle.load(fp)\\n    fp.close()\\n\\nr = praw.Reddit(user_agent)\\nr.set_oauth_app_info(client_id, client_secret, redirect_uri)\\nr.set_access_credentials(**creds)\\n\\nme = r.get_me()\\nfor comment in me.get_comments(sort = u\\u0026#39;new\\u0026#39;, limit=1):\\n    print(comment.id)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EThis returns an \\u003Ccode\\u003EOAuthInsufficientScopeError\\u003C/code\\u003E. However, \\u003Ccode\\u003Ecreds[\\u0026#39;scope\\u0026#39;]\\u003C/code\\u003E is \\u003Ccode\\u003E{\\u0026#39;submit\\u0026#39;, \\u0026#39;read\\u0026#39;, \\u0026#39;vote\\u0026#39;, \\u0026#39;identity\\u0026#39;}\\u003C/code\\u003E.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm using PRAW to get my most recent comment id. Here's my code so far:\\n\\n    import pickle\\n    import praw\\n\\n    user_agent = 'SomethingSomethingUserAgent'\\n    client_id = 'SomethingSomethingClientID'\\n    client_secret = 'SomethingSomethingClientSecret'\\n    redirect_uri = 'http://127.0.0.1:65010/authorize_callback'\\n\\n    with open('oauth','rb') as fp:\\n        creds = pickle.load(fp)\\n        fp.close()\\n\\n    r = praw.Reddit(user_agent)\\n    r.set_oauth_app_info(client_id, client_secret, redirect_uri)\\n    r.set_access_credentials(**creds)\\n\\n    me = r.get_me()\\n    for comment in me.get_comments(sort = u'new', limit=1):\\n        print(comment.id)\\n\\nThis returns an `OAuthInsufficientScopeError`. However, `creds['scope']` is `{'submit', 'read', 'vote', 'identity'}`.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ptfku\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"IamCarbonMan\", \"media\": null, \"score\": 4, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ptfku/praw_why_does_trying_to_read_my_comments_return/\", \"locked\": false, \"name\": \"t3_4ptfku\", \"created\": 1466904158.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ptfku/praw_why_does_trying_to_read_my_comments_return/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] Why does trying to read my comments return OAuthInsufficientScope?\", \"created_utc\": 1466875358.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 4}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003E\\u003Ca href=\\\"https://github.com/reddit/reddit/\\\"\\u003Ehttps://github.com/reddit/reddit/\\u003C/a\\u003E has the \\u003Ca href=\\\"http://www.reddit.com\\\"\\u003Ewww.reddit.com\\u003C/a\\u003E code.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://github.com/reddit/reddit-mobile/\\\"\\u003Ehttps://github.com/reddit/reddit-mobile/\\u003C/a\\u003E doesn\\u0026#39;t look like m.reddit.com.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"https://github.com/reddit/reddit/ has the www.reddit.com code.\\n\\nhttps://github.com/reddit/reddit-mobile/ doesn't look like m.reddit.com.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4pppt2\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"NewCompte\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4pppt2/where_is_the_mredditcom_code/\", \"locked\": false, \"name\": \"t3_4pppt2\", \"created\": 1466837668.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4pppt2/where_is_the_mredditcom_code/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Where is the m.reddit.com code ?\", \"created_utc\": 1466808868.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI would like to know what is the difference between the figures 0 and 10 in the \\u0026#39;get subreddit recommendation\\u0026#39; function. Thanks a lot for your answers. \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I would like to know what is the difference between the figures 0 and 10 in the 'get subreddit recommendation' function. Thanks a lot for your answers. \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4pp3fd\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"ThisisJae2\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4pp3fd/whats_the_difference_between_0_and_10_ranking_in/\", \"locked\": false, \"name\": \"t3_4pp3fd\", \"created\": 1466829606.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4pp3fd/whats_the_difference_between_0_and_10_ranking_in/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"What's the difference between 0 and 10 ranking in the 'get subreddit recommendation' function?\", \"created_utc\": 1466800806.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI keep getting a 403 when attempting to read the contents of a subreddit, take the following url as an example:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://oauth.reddit.com/r/gaming/hot/?t=day\\u0026amp;after=\\u0026amp;limit=25\\\"\\u003Ehttps://oauth.reddit.com/r/gaming/hot/?t=day\\u0026amp;after=\\u0026amp;limit=25\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe authorisation header is present and I\\u0026#39;ve tested refreshing it prior to making the request, I\\u0026#39;ve also read that an expired/invalid token should return a 401 and not a 403.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe response I get contains this header:\\n\\u003Cem\\u003Ewww-authenticate: Bearer realm=\\u0026quot;reddit\\u0026quot;, error=\\u0026quot;insufficient_scope\\u0026quot;\\u003C/em\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe scopes I request are \\u003Cem\\u003E\\u0026quot;identity,edit,flair,history,mysubreddits,privatemessages,read,report,save,submit,subscribe,vote,creddits\\u0026quot;;\\u003C/em\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAny ideas?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I keep getting a 403 when attempting to read the contents of a subreddit, take the following url as an example:\\n\\nhttps://oauth.reddit.com/r/gaming/hot/?t=day\\u0026after=\\u0026limit=25\\n\\nThe authorisation header is present and I've tested refreshing it prior to making the request, I've also read that an expired/invalid token should return a 401 and not a 403.\\n\\nThe response I get contains this header:\\n*www-authenticate: Bearer realm=\\\"reddit\\\", error=\\\"insufficient_scope\\\"*\\n\\nThe scopes I request are *\\\"identity,edit,flair,history,mysubreddits,privatemessages,read,report,save,submit,subscribe,vote,creddits\\\";*\\n\\nAny ideas?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4pma07\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Glurt\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4pma07/insufficient_scope_when_reading_from_subreddit/\", \"locked\": false, \"name\": \"t3_4pma07\", \"created\": 1466794317.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4pma07/insufficient_scope_when_reading_from_subreddit/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Insufficient scope when reading from subreddit\", \"created_utc\": 1466765517.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EThe multi right sidebar has an \\u003Ca href=\\\"https://github.com/reddit/reddit/blob/master/r2/r2/templates/multiinfobar.html#L34\\\"\\u003E\\u0026lt;a\\u0026gt; element that changes according to the multireddit the user is currently on.\\u003C/a\\u003E \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHow can I create something similar in \\u003Ca href=\\\"https://github.com/reddit/reddit/blob/master/r2/r2/templates/listingchooser.html\\\"\\u003Elistingchooser.html\\u003C/a\\u003E so that the hyperlink element also changes according to the current multi reddit?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"The multi right sidebar has an [\\u003Ca\\u003E element that changes according to the multireddit the user is currently on.](https://github.com/reddit/reddit/blob/master/r2/r2/templates/multiinfobar.html#L34) \\n\\nHow can I create something similar in [listingchooser.html](https://github.com/reddit/reddit/blob/master/r2/r2/templates/listingchooser.html) so that the hyperlink element also changes according to the current multi reddit?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4pktz0\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"devnoob23\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4pktz0/how_do_i_create_a_dynamic_a_hyperlink_element/\", \"locked\": false, \"name\": \"t3_4pktz0\", \"created\": 1466768850.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4pktz0/how_do_i_create_a_dynamic_a_hyperlink_element/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How do I create a dynamic \\u003Ca\\u003E hyperlink element like in multiinfobar.html?\", \"created_utc\": 1466740050.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m working with the API and have successfully been able to use a few methods. I went looking for the method to get posts for a subreddit and couldn\\u0026#39;t find it. I\\u0026#39;m sure I\\u0026#39;m missing the obvious, but where is that?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhile searching, I found this SO post  (\\u003Ca href=\\\"http://stackoverflow.com/questions/6183318/getting-new-posts-from-a-subreddit-in-json\\\"\\u003Ehttp://stackoverflow.com/questions/6183318/getting-new-posts-from-a-subreddit-in-json\\u003C/a\\u003E) whichi mentions you can go to a random subreddit and change the extension to json, like so:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://www.reddit.com/r/starwars/new.json?sort=new\\\"\\u003Ehttps://www.reddit.com/r/starwars/new.json?sort=new\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThis works - is easy to use - but doesn\\u0026#39;t actually seem to be documented anywhere. Is it?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm working with the API and have successfully been able to use a few methods. I went looking for the method to get posts for a subreddit and couldn't find it. I'm sure I'm missing the obvious, but where is that?\\n\\nWhile searching, I found this SO post  (http://stackoverflow.com/questions/6183318/getting-new-posts-from-a-subreddit-in-json) whichi mentions you can go to a random subreddit and change the extension to json, like so:\\n\\nhttps://www.reddit.com/r/starwars/new.json?sort=new\\n\\nThis works - is easy to use - but doesn't actually seem to be documented anywhere. Is it?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4pj7vo\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"cfjedimaster\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 9, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4pj7vo/documentation_for_redditjson_support/\", \"locked\": false, \"name\": \"t3_4pj7vo\", \"created\": 1466746748.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4pj7vo/documentation_for_redditjson_support/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Documentation for reddit.json support\", \"created_utc\": 1466717948.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EAccording to a thread I found on here, this is a way to do it :  \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Er.search(\\u0026#39;flair:\\u0026quot;searchterm\\u0026quot;\\u0026#39;, subreddit=\\u0026#39;betonaskreddit\\u0026#39;)  \\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EHowever, my function looks like this. In my function, I\\u0026#39;d want flair to be optional when calling it, just like string is optional.  \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Edef plain(subr, me, string=None):\\n    with open(\\u0026quot;_\\u0026quot;+me+\\u0026quot;.txt\\u0026quot;, \\u0026#39;w\\u0026#39;) as f:\\n        subreddit = r.get_subreddit(subr)   \\n        #f.write(\\u0026quot;\\u0026lt;h1\\u0026gt;\\u0026quot;+string + \\u0026quot; subreddit:\\u0026quot;+ subr+\\u0026quot;\\u0026lt;/h1\\u0026gt;\\\\n\\u0026quot;)     \\n        for subm in subreddit.get_hot(limit=25):\\n            not_reddit = \\u0026quot;reddit\\u0026quot; not in subm.url\\n            in_title = re.search(string, subm.title, re.IGNORECASE) if string else False\\n            if (not string and not_reddit) or (string and in_title and not_reddit):\\n                title = re.sub(\\u0026#39;\\\\[.*?\\\\]\\u0026#39;, \\u0026#39;\\u0026#39;, subm.title)\\n                f.write(title+\\u0026quot; \\u0026quot;+subm.url+\\u0026quot;\\\\n\\u0026quot;)   \\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EIt doesn\\u0026#39;t sound like a good practice to redefine the variables for every iteration in the for loop, but if I did it before the loop it would not know what subm.url is. \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"According to a thread I found on here, this is a way to do it :  \\n\\n    r.search('flair:\\\"searchterm\\\"', subreddit='betonaskreddit')  \\nHowever, my function looks like this. In my function, I'd want flair to be optional when calling it, just like string is optional.  \\n\\n    def plain(subr, me, string=None):\\n        with open(\\\"_\\\"+me+\\\".txt\\\", 'w') as f:\\n            subreddit = r.get_subreddit(subr)   \\n            #f.write(\\\"\\u003Ch1\\u003E\\\"+string + \\\" subreddit:\\\"+ subr+\\\"\\u003C/h1\\u003E\\\\n\\\")     \\n            for subm in subreddit.get_hot(limit=25):\\n            \\tnot_reddit = \\\"reddit\\\" not in subm.url\\n            \\tin_title = re.search(string, subm.title, re.IGNORECASE) if string else False\\n            \\tif (not string and not_reddit) or (string and in_title and not_reddit):\\n            \\t\\ttitle = re.sub('\\\\[.*?\\\\]', '', subm.title)\\n            \\t\\tf.write(title+\\\" \\\"+subm.url+\\\"\\\\n\\\")   \\nIt doesn't sound like a good practice to redefine the variables for every iteration in the for loop, but if I did it before the loop it would not know what subm.url is. \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4pfpmh\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"thinkvitamin\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1466670683.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4pfpmh/how_would_i_add_a_search_by_flair_into_my_function/\", \"locked\": false, \"name\": \"t3_4pfpmh\", \"created\": 1466699290.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4pfpmh/how_would_i_add_a_search_by_flair_into_my_function/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How would I add a search by flair into my function?\", \"created_utc\": 1466670490.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo, I\\u0026#39;m trying to make this bot that makes it so whenever someone comments \\u0026quot;MURICA!\\u0026quot;, it says \\u0026quot;\\u003Ca href=\\\"http://krikienoid.github.io/flagwaver/#?src=https%3A%2F%2Fupload.wikimedia.org%2Fwikipedia%2Fcommons%2Fthumb%2Fe%2Fe8%2FBandera_de_Murcia2.0.png%2F640px-Bandera_de_Murcia2.0.png\\\"\\u003E\\u0026#39;\\u00a1MURCIA!\\u003C/a\\u003E\\u0026quot;. However, whenever I try to run it, it says that it is finding comments where it does have comments saying \\u0026quot;MURICA\\u0026quot;, however it never replies to them. Could you please help me with this?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAlso, I am aware that my login system is very insecure, so it will need some fixing as well, and I thought you could help with that too.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks in advance,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EMuricaMurciaBot\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"http://i.imgur.com/and9FRe.png?1\\\"\\u003ECommand prompt image\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://github.com/AndyBotter/GreatBigBot/blob/master/murciabot.py\\\"\\u003EGithub file\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So, I'm trying to make this bot that makes it so whenever someone comments \\\"MURICA!\\\", it says \\\"['\\u00a1MURCIA!](http://krikienoid.github.io/flagwaver/#?src=https%3A%2F%2Fupload.wikimedia.org%2Fwikipedia%2Fcommons%2Fthumb%2Fe%2Fe8%2FBandera_de_Murcia2.0.png%2F640px-Bandera_de_Murcia2.0.png)\\\". However, whenever I try to run it, it says that it is finding comments where it does have comments saying \\\"MURICA\\\", however it never replies to them. Could you please help me with this?\\n\\nAlso, I am aware that my login system is very insecure, so it will need some fixing as well, and I thought you could help with that too.\\n\\nThanks in advance,\\n\\nMuricaMurciaBot\\n\\n[Command prompt image](http://i.imgur.com/and9FRe.png?1)\\n\\n[Github file](https://github.com/AndyBotter/GreatBigBot/blob/master/murciabot.py)\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4pbey1\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"MuricaMurciaBot\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 6, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4pbey1/bot_program_not_making_comments/\", \"locked\": false, \"name\": \"t3_4pbey1\", \"created\": 1466640240.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4pbey1/bot_program_not_making_comments/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Bot program not making comments\", \"created_utc\": 1466611440.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo I get a crash under \\u003Ca href=\\\"http://m.imgur.com/gzwQtVf\\\"\\u003Ethis error\\u003C/a\\u003E after about a day or two after its been running.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EIs there a fix I could implement into my code (obot.py) in that github respitory?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://github.com/gtavbeastaya/fsdfds?files=1\\\"\\u003Ehttps://github.com/gtavbeastaya/fsdfds?files=1\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So I get a crash under [this error](http://m.imgur.com/gzwQtVf) after about a day or two after its been running.\\n\\nIs there a fix I could implement into my code (obot.py) in that github respitory?\\n\\nhttps://github.com/gtavbeastaya/fsdfds?files=1\\n\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4p6pr4\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"GTAVbeastya\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4p6pr4/bots_crash_after_a_day_of_running/\", \"locked\": false, \"name\": \"t3_4p6pr4\", \"created\": 1466569128.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4p6pr4/bots_crash_after_a_day_of_running/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Bots crash after a day of running.\", \"created_utc\": 1466540328.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EFor example, if I wanted to check if \\u0026quot;\\u003Ca href=\\\"https://xkcd.com/123\\\"\\u003Ehttps://xkcd.com/123\\u003C/a\\u003E\\u0026quot; has ever been submitted to reddit, how would I do that?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E(Sorry if this is a stupid question. I\\u0026#39;m a complete newbie to the Reddit API.)\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"For example, if I wanted to check if \\\"https://xkcd.com/123\\\" has ever been submitted to reddit, how would I do that?\\n\\n(Sorry if this is a stupid question. I'm a complete newbie to the Reddit API.)\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4p6db5\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"GlaedrH\", \"media\": null, \"score\": 9, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 5, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4p6db5/is_there_a_way_to_use_the_api_to_check_if_a_url/\", \"locked\": false, \"name\": \"t3_4p6db5\", \"created\": 1466565130.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4p6db5/is_there_a_way_to_use_the_api_to_check_if_a_url/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Is there a way to use the API to check if a URL has been submitted to Reddit?\", \"created_utc\": 1466536330.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 9}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m making a change that parses through different comments, sometime 200 at a time. Is there a batch request to grab these in one go?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm making a change that parses through different comments, sometime 200 at a time. Is there a batch request to grab these in one go?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4p6595\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"MystK\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4p6595/batch_get_comments_from_different_listings/\", \"locked\": false, \"name\": \"t3_4p6595\", \"created\": 1466562649.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4p6595/batch_get_comments_from_different_listings/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Batch get comments from different listings?\", \"created_utc\": 1466533849.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHey guys, Im trying to stand up a reddit, and Ive injected some data so I got the admin user, Ive even added my own admin user and others however when I try to turn on admin mode I get this error. \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EJun 21 10:09:47 redditdevtest reddit-paster: Debug at: http://redditdevtest.test.domain/_debug/view/1466518093\\nJun 21 10:09:47 redditdevtest reddit-paster: [web frontend] error: Client Error: \\u0026quot;ReferenceError: \\u0026#39;post_form\\u0026#39; is undefined\\u0026quot; thrown at L1:14756 in http://redditdevtest.test.domain/adminon?dest=%2F Message: \\u0026quot;\\u0026#39;post_form\\u0026#39; is undefined\\u0026quot; | U: 1 FP: http://redditdevtest.test.domain/adminon?dest=%2F UA: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 10.0; WOW64; Trident/7.0; Touch; .NET4.0C; .NET4.0E; Tablet PC 2.0; .NET CLR 2.0.50727; .NET CLR 3.0.30729; .NET CLR 3.5.30729)\\nJun 21 10:10:01 redditdevtest CRON[30374]: (root) CMD (/sbin/start --quiet reddit-job-liveupdate_activity)\\nJun 21 10:10:01 redditdevtest CRON[30375]: (root) CMD (/sbin/start --quiet reddit-job-broken_things)\\nJun 21 10:10:01 redditdevtest CRON[30377]: (root) CMD (/sbin/start --quiet reddit-job-rising)\\nJun 21 10:10:01 redditdevtest CRON[30378]: (root) CMD (/sbin/start --quiet reddit-job-clean_up_hardcache)\\nJun 21 10:10:02 redditdevtest reddit-job-broken_things: Warning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\nJun 21 10:10:02 redditdevtest reddit-job-broken_things: Warning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\nJun 21 10:10:02 redditdevtest reddit-job-broken_things: Overriding g.from r2.lib.utils import utils; utils.find_recent_broken_things(delete to True)\\nJun 21 10:10:02 redditdevtest reddit-job-liveupdate_activity: Warning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\nJun 21 10:10:02 redditdevtest reddit-job-liveupdate_activity: Warning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\nJun 21 10:10:02 redditdevtest reddit-job-rising: Warning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\nJun 21 10:10:02 redditdevtest reddit-job-rising: Warning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\nJun 21 10:10:02 redditdevtest reddit-job-clean_up_hardcache: Warning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\nJun 21 10:10:02 redditdevtest reddit-job-clean_up_hardcache: Warning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\nJun 21 10:10:02 redditdevtest reddit-job-broken_things: redditdevtest:30392 started 8123b99 at 10:10:02 (took 0.61s)\\nJun 21 10:10:03 redditdevtest reddit-job-liveupdate_activity: redditdevtest:30396 started 8123b99 at 10:10:03 (took 0.63s)\\nJun 21 10:10:03 redditdevtest reddit-job-rising: redditdevtest:30393 started 8123b99 at 10:10:03 (took 0.61s)\\nJun 21 10:10:03 redditdevtest reddit-job-clean_up_hardcache: redditdevtest:30397 started 8123b99 at 10:10:03 (took 0.63s)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EI got the code from git sometime last week, used the install script\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Ewhen I try to update reddits I get\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E$sudo start reddit-job-update_reddits\\nreddit-job-update_reddits stop/waiting\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Eim not sure if this is the desired result of the update command. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI constantly get \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EWarning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\nreddit-job-liveupdate_activity: Warning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Estreaming in the logs. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe above big error also happens when trying to post to one of the subreddits that populated(But are not shown) with the test data inject. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003Eany help/advice/info/pointers would be top notch. \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hey guys, Im trying to stand up a reddit, and Ive injected some data so I got the admin user, Ive even added my own admin user and others however when I try to turn on admin mode I get this error. \\n\\n    Jun 21 10:09:47 redditdevtest reddit-paster: Debug at: http://redditdevtest.test.domain/_debug/view/1466518093\\n    Jun 21 10:09:47 redditdevtest reddit-paster: [web frontend] error: Client Error: \\\"ReferenceError: 'post_form' is undefined\\\" thrown at L1:14756 in http://redditdevtest.test.domain/adminon?dest=%2F Message: \\\"'post_form' is undefined\\\" | U: 1 FP: http://redditdevtest.test.domain/adminon?dest=%2F UA: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 10.0; WOW64; Trident/7.0; Touch; .NET4.0C; .NET4.0E; Tablet PC 2.0; .NET CLR 2.0.50727; .NET CLR 3.0.30729; .NET CLR 3.5.30729)\\n    Jun 21 10:10:01 redditdevtest CRON[30374]: (root) CMD (/sbin/start --quiet reddit-job-liveupdate_activity)\\n    Jun 21 10:10:01 redditdevtest CRON[30375]: (root) CMD (/sbin/start --quiet reddit-job-broken_things)\\n    Jun 21 10:10:01 redditdevtest CRON[30377]: (root) CMD (/sbin/start --quiet reddit-job-rising)\\n    Jun 21 10:10:01 redditdevtest CRON[30378]: (root) CMD (/sbin/start --quiet reddit-job-clean_up_hardcache)\\n    Jun 21 10:10:02 redditdevtest reddit-job-broken_things: Warning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\n    Jun 21 10:10:02 redditdevtest reddit-job-broken_things: Warning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\n    Jun 21 10:10:02 redditdevtest reddit-job-broken_things: Overriding g.from r2.lib.utils import utils; utils.find_recent_broken_things(delete to True)\\n    Jun 21 10:10:02 redditdevtest reddit-job-liveupdate_activity: Warning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\n    Jun 21 10:10:02 redditdevtest reddit-job-liveupdate_activity: Warning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\n    Jun 21 10:10:02 redditdevtest reddit-job-rising: Warning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\n    Jun 21 10:10:02 redditdevtest reddit-job-rising: Warning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\n    Jun 21 10:10:02 redditdevtest reddit-job-clean_up_hardcache: Warning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\n    Jun 21 10:10:02 redditdevtest reddit-job-clean_up_hardcache: Warning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\n    Jun 21 10:10:02 redditdevtest reddit-job-broken_things: redditdevtest:30392 started 8123b99 at 10:10:02 (took 0.61s)\\n    Jun 21 10:10:03 redditdevtest reddit-job-liveupdate_activity: redditdevtest:30396 started 8123b99 at 10:10:03 (took 0.63s)\\n    Jun 21 10:10:03 redditdevtest reddit-job-rising: redditdevtest:30393 started 8123b99 at 10:10:03 (took 0.61s)\\n    Jun 21 10:10:03 redditdevtest reddit-job-clean_up_hardcache: redditdevtest:30397 started 8123b99 at 10:10:03 (took 0.63s)\\n\\n\\nI got the code from git sometime last week, used the install script\\n\\nwhen I try to update reddits I get\\n\\n    $sudo start reddit-job-update_reddits\\n    reddit-job-update_reddits stop/waiting\\nim not sure if this is the desired result of the update command. \\n\\nI constantly get \\n    \\n    Warning: g.media_domain == g.domain. This may give untrusted content access to user cookies\\n    reddit-job-liveupdate_activity: Warning: g.oauth_domain == g.domain. CORS requests to g.domain will be allowed\\n streaming in the logs. \\n\\nThe above big error also happens when trying to post to one of the subreddits that populated(But are not shown) with the test data inject. \\n\\nany help/advice/info/pointers would be top notch. \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4p4vjd\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"blandhair\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 7, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4p4vjd/something_broken/\", \"locked\": false, \"name\": \"t3_4p4vjd\", \"created\": 1466548161.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4p4vjd/something_broken/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Something broken\", \"created_utc\": 1466519361.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;d like to only show new posts (i.e. posts that are not visited).\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWould it be possible to send this as a param?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'd like to only show new posts (i.e. posts that are not visited).\\n\\nWould it be possible to send this as a param?\\n\\nThanks\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ozcvf\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"ljdawson\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ozcvf/is_there_any_way_to_only_request_new_posts/\", \"locked\": false, \"name\": \"t3_4ozcvf\", \"created\": 1466466265.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ozcvf/is_there_any_way_to_only_request_new_posts/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Is there any way to only request new posts?\", \"created_utc\": 1466437465.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHey!,\\nI\\u0026#39;m trying to create a simple bot that keeps track of all reddit comments. I\\u0026#39;m having trouble with keeping track of how many comments I\\u0026#39;ve obtained. Supposedly \\u0026#39;z\\u0026#39; holds the total number of comments logged. It is being set to 200 every time a block of comments is processed but it\\u0026#39;s being set back to 0 each cycle because of line 7.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECode Here: \\u003Ca href=\\\"http://pastebin.com/gpgKAjPd\\\"\\u003Ehttp://pastebin.com/gpgKAjPd\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ETL;DR: How do I make \\u0026#39;z\\u0026#39; not turn 0 every time the bot runs?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hey!,\\nI'm trying to create a simple bot that keeps track of all reddit comments. I'm having trouble with keeping track of how many comments I've obtained. Supposedly 'z' holds the total number of comments logged. It is being set to 200 every time a block of comments is processed but it's being set back to 0 each cycle because of line 7.\\n\\nCode Here: http://pastebin.com/gpgKAjPd\\n\\nTL;DR: How do I make 'z' not turn 0 every time the bot runs?\\n\\n                       \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4oz84t\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Nobodok\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1466439605.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4oz84t/basic_problem_regarding_variables/\", \"locked\": false, \"name\": \"t3_4oz84t\", \"created\": 1466464670.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4oz84t/basic_problem_regarding_variables/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Basic problem regarding variables.\", \"created_utc\": 1466435870.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI am trying to bring over a group who are presently using forums and mailing lists.  The biggest difference I see between these and Reddit is that, the first page of forums show the most recently active threads, while Reddit only show the most upvoted threads.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhile in most news-focused subreddits the default \\u0026quot;hot\\u0026quot; algorithm could be the right one, it cannot be the case for every subreddit. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI wonder if the developers of Reddit can consider a feature request to allow subreddit moderators to choose their default \\u0026quot;hotness\\u0026quot; sort algorithm, whether based on votes or based on latest comments.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I am trying to bring over a group who are presently using forums and mailing lists.  The biggest difference I see between these and Reddit is that, the first page of forums show the most recently active threads, while Reddit only show the most upvoted threads.\\n\\nWhile in most news-focused subreddits the default \\\"hot\\\" algorithm could be the right one, it cannot be the case for every subreddit. \\n\\nI wonder if the developers of Reddit can consider a feature request to allow subreddit moderators to choose their default \\\"hotness\\\" sort algorithm, whether based on votes or based on latest comments.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4oxy9l\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"mamborambo\", \"media\": null, \"score\": 6, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4oxy9l/can_subreddit_choose_a_sort_algorithm_based_on/\", \"locked\": false, \"name\": \"t3_4oxy9l\", \"created\": 1466444589.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4oxy9l/can_subreddit_choose_a_sort_algorithm_based_on/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Can subreddit choose a sort algorithm based on \\\"Active\\\", i.e. threads that have been viewed or commented recently?\", \"created_utc\": 1466415789.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 6}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI was recently made aware of an interesting dynamic: subreddits which are blocked by a large number of users may find it easier to hit the front page, as their content is not seen by these users and is therefore not subject to their downvotes.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI thought about this issue and had a weird idea: what if someone were to create some kind of service (maybe a browser extension?) that would enable a user\\u0026#39;s \\u0026quot;don\\u0026#39;t show me submissions after I\\u0026#39;ve downvoted them\\u0026quot; setting and then auto-downvote any front-page posts from that subreddit, allowing the user to hide the subreddit while also registering their disapproval of that sub\\u0026#39;s content.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThis idea seems to exist in an ethically gray area, and I was curious if it was even allowed from the standpoint of Reddit\\u0026#39;s TOS. What do you guys think? Would this app be ethical, or even allowed at all?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I was recently made aware of an interesting dynamic: subreddits which are blocked by a large number of users may find it easier to hit the front page, as their content is not seen by these users and is therefore not subject to their downvotes.\\n\\nI thought about this issue and had a weird idea: what if someone were to create some kind of service (maybe a browser extension?) that would enable a user's \\\"don't show me submissions after I've downvoted them\\\" setting and then auto-downvote any front-page posts from that subreddit, allowing the user to hide the subreddit while also registering their disapproval of that sub's content.\\n\\nThis idea seems to exist in an ethically gray area, and I was curious if it was even allowed from the standpoint of Reddit's TOS. What do you guys think? Would this app be ethical, or even allowed at all?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ouzjt\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"tacobellscannon\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 10, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ouzjt/would_it_be_against_the_rules_andor_unethical_to/\", \"locked\": false, \"name\": \"t3_4ouzjt\", \"created\": 1466396311.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ouzjt/would_it_be_against_the_rules_andor_unethical_to/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Would it be against the rules and/or unethical to create a service that allows individual users to auto-downvote front page posts from subreddits of their choosing?\", \"created_utc\": 1466367511.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m working on a bot written in Java using JRAW and \\u003Ca href=\\\"https://github.com/janpetryk/reddit-bot\\\"\\u003Ethis TweetInCommentsBot\\u003C/a\\u003E code. Whenever I try to reply to a comment I get a RATELIMIT error back, while I\\u0026#39;m only sending 1 request. (I think)\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThese are the methods where I reply to comments:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E@Override\\n    public PostCommentResult replyToComment(String parentCommentFullName, String responseCommentBody) throws NetworkConnectionException, RedditApiException{\\n        try {\\n            RedditResponse response = redditClient.execute(redditClient.request()\\n                .endpoint(Endpoints.COMMENT)\\n                .post(JrawUtils.args(\\n                    \\u0026quot;api_type\\u0026quot;, \\u0026quot;json\\u0026quot;,\\n                    \\u0026quot;text\\u0026quot;, responseCommentBody,\\n                    \\u0026quot;thing_id\\u0026quot;, parentCommentFullName))\\n                .build());\\n            return processResponse(response);\\n        } catch (NetworkException e) {\\n            if (e.getCode() == 403) {\\n                return PostCommentResult.bannedFromThisSub();\\n            }\\n            throw new NetworkConnectionException(e);\\n        }\\n    }\\n\\n    private PostCommentResult processResponse(RedditResponse response) {\\n        if (response.hasErrors()) {\\n            String message = response.getErrors()[0].getMessage();\\n            if (message.contains(\\u0026quot;DELETED_COMMENT\\u0026quot;)) {\\n                return PostCommentResult.commentDeleted();\\n            } else {\\n                return PostCommentResult.unsuccessful(message);\\n            }\\n\\n        } else {\\n            return PostCommentResult.successful(response.getJson().get(\\u0026quot;json\\u0026quot;).get(\\u0026quot;data\\u0026quot;).get(\\u0026quot;things\\u0026quot;).get(0)\\n                .get(\\u0026quot;data\\u0026quot;).get(\\u0026quot;id\\u0026quot;).toString().substring(3));\\n        }\\n    }    \\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EI run a task every 30 seconds to let the bot get new posts:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Etimer = new Timer();\\ntimer.schedule(new ExecuteBot(), 30000);\\nSystem.out.println(\\u0026quot;Start bot.\\u0026quot;);\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EIn executebot I login using oAuth:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003ERedditPost rp;\\n\\npublic ExecuteBot()\\n{\\n\\n}\\n\\n@Override\\npublic void run()\\n{\\n    if (rp == null)\\n    {\\n        rp = new RedditPost(\\u0026quot;desktop:beans.redditbean:v0.1 (by /u/HenkDeVries013)\\u0026quot;, \\u0026quot;user\\u0026quot;, \\u0026quot;hunter2\\u0026quot;, \\u0026quot;secret/id\\u0026quot;, \\u0026quot;secret/id\\u0026quot;);\\n    }\\n    rp.getStreamNameFromComment();\\n}\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAnd my RedditPost method to login:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E    @Inject\\n    public RedditPost(@Named(\\u0026quot;reddit-useragent\\u0026quot;) String userAgent,\\n        @Named(\\u0026quot;reddit-login\\u0026quot;) String login,\\n        @Named(\\u0026quot;reddit-password\\u0026quot;) String password,\\n        @Named(\\u0026quot;reddit-client-id\\u0026quot;) String clientId,\\n        @Named(\\u0026quot;reddit-client-secret\\u0026quot;) String clientSecret) {\\n        redditClient = new RedditClient(userAgent, 60);\\n        loginOAuth(login, password, clientId, clientSecret);\\n    }\\n\\n    void loginOAuth(String username, String password, String clientId, String clientSecret) {\\n        try {\\n            redditClient.login(Credentials.webapp(username, password, clientId, clientSecret));\\n        } catch (NetworkException ex) {\\n            Logger.getLogger(RedditPost.class.getName()).log(Level.SEVERE, null, ex);\\n        } catch (ApiException ex) {\\n            Logger.getLogger(RedditPost.class.getName()).log(Level.SEVERE, null, ex);\\n        }\\n\\n    }\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EWhere do I make the mistake? I have no clue why I get the RATELIMIT since in my understanding I can make up to 60 requests per minute and I\\u0026#39;m no where near that amount..\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi,\\n\\nI'm working on a bot written in Java using JRAW and [this TweetInCommentsBot](https://github.com/janpetryk/reddit-bot) code. Whenever I try to reply to a comment I get a RATELIMIT error back, while I'm only sending 1 request. (I think)\\n\\nThese are the methods where I reply to comments:\\n    \\n    @Override\\n    \\tpublic PostCommentResult replyToComment(String parentCommentFullName, String responseCommentBody) throws NetworkConnectionException, RedditApiException{\\n    \\t\\ttry {\\n    \\t\\t\\tRedditResponse response = redditClient.execute(redditClient.request()\\n    \\t\\t\\t\\t.endpoint(Endpoints.COMMENT)\\n    \\t\\t\\t\\t.post(JrawUtils.args(\\n    \\t\\t\\t\\t\\t\\\"api_type\\\", \\\"json\\\",\\n    \\t\\t\\t\\t\\t\\\"text\\\", responseCommentBody,\\n    \\t\\t\\t\\t\\t\\\"thing_id\\\", parentCommentFullName))\\n    \\t\\t\\t\\t.build());\\n    \\t\\t\\treturn processResponse(response);\\n    \\t\\t} catch (NetworkException e) {\\n    \\t\\t\\tif (e.getCode() == 403) {\\n    \\t\\t\\t\\treturn PostCommentResult.bannedFromThisSub();\\n    \\t\\t\\t}\\n    \\t\\t\\tthrow new NetworkConnectionException(e);\\n    \\t\\t}\\n    \\t}\\n    \\n    \\tprivate PostCommentResult processResponse(RedditResponse response) {\\n    \\t\\tif (response.hasErrors()) {\\n    \\t\\t\\tString message = response.getErrors()[0].getMessage();\\n    \\t\\t\\tif (message.contains(\\\"DELETED_COMMENT\\\")) {\\n    \\t\\t\\t\\treturn PostCommentResult.commentDeleted();\\n    \\t\\t\\t} else {\\n    \\t\\t\\t\\treturn PostCommentResult.unsuccessful(message);\\n    \\t\\t\\t}\\n    \\n    \\t\\t} else {\\n    \\t\\t\\treturn PostCommentResult.successful(response.getJson().get(\\\"json\\\").get(\\\"data\\\").get(\\\"things\\\").get(0)\\n    \\t\\t\\t\\t.get(\\\"data\\\").get(\\\"id\\\").toString().substring(3));\\n    \\t\\t}\\n    \\t}    \\n\\nI run a task every 30 seconds to let the bot get new posts:\\n\\n    timer = new Timer();\\n    timer.schedule(new ExecuteBot(), 30000);\\n    System.out.println(\\\"Start bot.\\\");\\n\\nIn executebot I login using oAuth:\\n\\n    RedditPost rp;\\n\\t\\n\\tpublic ExecuteBot()\\n\\t{\\n\\t\\t\\n\\t}\\n\\t\\n\\t@Override\\n\\tpublic void run()\\n\\t{\\n\\t\\tif (rp == null)\\n\\t\\t{\\n\\t\\t\\trp = new RedditPost(\\\"desktop:beans.redditbean:v0.1 (by /u/HenkDeVries013)\\\", \\\"user\\\", \\\"hunter2\\\", \\\"secret/id\\\", \\\"secret/id\\\");\\n\\t\\t}\\n\\t\\trp.getStreamNameFromComment();\\n\\t}\\n\\nAnd my RedditPost method to login:\\n    \\n    \\t@Inject\\n    \\tpublic RedditPost(@Named(\\\"reddit-useragent\\\") String userAgent,\\n    \\t\\t@Named(\\\"reddit-login\\\") String login,\\n    \\t\\t@Named(\\\"reddit-password\\\") String password,\\n    \\t\\t@Named(\\\"reddit-client-id\\\") String clientId,\\n    \\t\\t@Named(\\\"reddit-client-secret\\\") String clientSecret) {\\n    \\t\\tredditClient = new RedditClient(userAgent, 60);\\n    \\t\\tloginOAuth(login, password, clientId, clientSecret);\\n    \\t}\\n    \\n    \\tvoid loginOAuth(String username, String password, String clientId, String clientSecret) {\\n    \\t\\ttry {\\n    \\t\\t\\tredditClient.login(Credentials.webapp(username, password, clientId, clientSecret));\\n    \\t\\t} catch (NetworkException ex) {\\n    \\t\\t\\tLogger.getLogger(RedditPost.class.getName()).log(Level.SEVERE, null, ex);\\n    \\t\\t} catch (ApiException ex) {\\n    \\t\\t\\tLogger.getLogger(RedditPost.class.getName()).log(Level.SEVERE, null, ex);\\n    \\t\\t}\\n    \\n    \\t}\\n\\nWhere do I make the mistake? I have no clue why I get the RATELIMIT since in my understanding I can make up to 60 requests per minute and I'm no where near that amount..\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4osr3v\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"HenkDeVries013\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4osr3v/ratelimit_when_i_try_to_reply_on_someones_comment/\", \"locked\": false, \"name\": \"t3_4osr3v\", \"created\": 1466359957.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4osr3v/ratelimit_when_i_try_to_reply_on_someones_comment/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"RATELIMIT when I try to reply on someone's comment\", \"created_utc\": 1466331157.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m writing a bot to do minor mod work for me. I\\u0026#39;ve managed to login using oauth, but with the wrong permissions, how can I update the permissions? I tried to follow the same steps as the first time, and add  \\u003Ccode\\u003Emodconfig\\u003C/code\\u003E to the scope, but it throws \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Epraw.errors.OAuthInvalidGrant: invalid_grant on url https://api.reddit.com/api/v1/access_token/\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EThis is what I use:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Er = praw.Reddit(user_agent=user_agent)\\nr.set_oauth_app_info(CLIENT_ID, CLIEAND_SECRET, REDIRECT_URI)\\n#authenticating\\naccess_information = r.get_access_information(AUTH_CODE)\\nr.set_access_credentials(**access_information)\\nurl = r.get_authorize_url(\\u0026#39;uniqueKey identity read modconfig\\u0026#39;,True)\\nimport webbrowser\\nwebbrowser.open(url)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAnd the line that throws the error is the third code line (the one starting with \\u003Ccode\\u003Eaccess_information\\u003C/code\\u003E.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHow should I do this properly? \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi. \\n\\nI'm writing a bot to do minor mod work for me. I've managed to login using oauth, but with the wrong permissions, how can I update the permissions? I tried to follow the same steps as the first time, and add  ``modconfig`` to the scope, but it throws \\n\\n    praw.errors.OAuthInvalidGrant: invalid_grant on url https://api.reddit.com/api/v1/access_token/\\n\\n\\nThis is what I use:\\n\\n    r = praw.Reddit(user_agent=user_agent)\\n    r.set_oauth_app_info(CLIENT_ID, CLIEAND_SECRET, REDIRECT_URI)\\n    #authenticating\\n    access_information = r.get_access_information(AUTH_CODE)\\n    r.set_access_credentials(**access_information)\\n    url = r.get_authorize_url('uniqueKey identity read modconfig',True)\\n    import webbrowser\\n    webbrowser.open(url)\\n\\nAnd the line that throws the error is the third code line (the one starting with ``access_information``.\\n\\nHow should I do this properly? \\n\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4opvn9\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"yotama9\", \"media\": null, \"score\": 7, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 10, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4opvn9/how_do_i_set_a_bot_to_connect_via_oauth2_and_edit/\", \"locked\": false, \"name\": \"t3_4opvn9\", \"created\": 1466306347.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4opvn9/how_do_i_set_a_bot_to_connect_via_oauth2_and_edit/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"how do I set a bot to connect via oauth2 and edit subreddit sidebar\", \"created_utc\": 1466277547.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 7}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI am using praw to get submission id of a post through a url entered by a user. I can\\u0026#39;t understand why the r.get_submission method is failing. Can someone suggest any improvements?\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E     def UrlRoutine(thrd_url):\\n            \\u0026quot;\\u0026quot;\\u0026quot; Returns the unique submission id from the match thread url \\u0026quot;\\u0026quot;\\u0026quot;\\n            football_url = urlparse(thrd_url)\\n            submission_id =  r.get_submission(football_url.path.split(\\u0026#39;/\\u0026#39;)[4])\\n            return submission_id\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I am using praw to get submission id of a post through a url entered by a user. I can't understand why the r.get_submission method is failing. Can someone suggest any improvements?\\n\\n\\n\\n\\n\\n         def UrlRoutine(thrd_url):\\n                \\\"\\\"\\\" Returns the unique submission id from the match thread url \\\"\\\"\\\"\\n                football_url = urlparse(thrd_url)\\n                submission_id =  r.get_submission(football_url.path.split('/')[4])\\n                return submission_id\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4onn23\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"theresasnakeinmysuit\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4onn23/trying_to_get_submission_id_from_url/\", \"locked\": false, \"name\": \"t3_4onn23\", \"created\": 1466264935.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4onn23/trying_to_get_submission_id_from_url/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Trying to get submission id from url\", \"created_utc\": 1466236135.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Ch1\\u003EDISCLAIMER:\\u003C/h1\\u003E\\n\\n\\u003Cp\\u003EThis is literally the first program I have ever written in \\u003Cem\\u003Eany\\u003C/em\\u003E programming language. I\\u0026#39;m pretty proud of it despite its flaws.\\u003C/p\\u003E\\n\\n\\u003Ch1\\u003EThe Code:\\u003C/h1\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Eimport praw\\nimport pdb\\nimport re\\nimport os\\nimport time\\nimport markovify\\nfrom ConfigBot import *\\n\\n\\nr = praw.Reddit(user_agent = \\u0026quot;A chatbot by /u/Gingerale947 that just wants to say stupid things :)\\u0026quot;)\\nr.login(REDDIT_USERNAME, REDDIT_PASS)\\nprint(\\u0026quot;Logging in...\\u0026quot;)\\n\\nalready_read = []\\nmatch = [\\u0026quot;SHITPOST\\u0026quot;]\\nmy_name = [\\u0026quot;GAs_ShitPostBot\\u0026quot;]\\n\\ndef run_bot():\\n    print(\\u0026quot;Connecting to /r/Homestuck\\u0026quot;)\\n    subreddit = r.get_subreddit(\\u0026quot;\\u0026lt;My test subreddit\\u0026gt;\\u0026quot;)\\n    for submission in subreddit.get_hot(limit=5):\\n        if submission.id not in already_read:\\n            r.search(\\u0026#39;flair:\\u0026quot;SHITPOST\\u0026quot;\\u0026#39;, submission.link_flair_text)\\n            if submission.link_flair_text in match:\\n                print(\\u0026quot;Title: \\u0026quot;, submission.title)\\n                print(\\u0026quot;Text: \\u0026quot;, submission.selftext)\\n                print(\\u0026quot;Score: \\u0026quot;, submission.score)\\n                print(\\u0026quot;Author: \\u0026quot;, submission.author)\\n                print(submission.link_flair_css_class)\\n                print(\\u0026quot;---------------------------------\\\\n\\u0026quot;)\\n                already_read.append(submission.id)\\n                print(\\u0026quot;SHITPOSTING...\\u0026quot;)\\n                submission.add_comment(text_model.make_short_sentence(500))\\n                time.sleep(180)\\n\\ndef find_replies():\\n    print(\\u0026quot;Checking replies\\u0026quot;)\\n    subreddit = r.get_subreddit(\\u0026quot;\\u0026lt;My test subreddit\\u0026gt;\\u0026quot;)\\n    comment = subreddit.get_comments(limit=25)\\n    for comment in comments:\\n        comment_text = comment.body.lower()\\n        if comment.parent_id in my_name:\\n            comment.reply(text_model.make_short_sentence(500))\\n            time.sleep(5)\\n\\nwith open(\\u0026#39;C:/Users/Ginge/Desktop/GAs_ShitCommentBot/ShitPostComments.txt\\u0026#39;, encoding=\\u0026quot;utf-8\\u0026quot;) as f:\\n    text = f.read()\\n\\ntext_model = markovify.Text(text, state_size=1)\\n\\nwhile True:\\n    run_bot()\\n    find_replies()\\n    time.sleep(20)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003E(\\u0026quot;\\u0026lt;My test subreddit\\u0026gt;\\u0026quot; isnt actually part of the code its just where I put the name of my test subreddit)\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe run_bot() function works perfectly, it\\u0026#39;s set to find all the posts on a given subreddit that are labeled \\u0026quot;SHITPOST\\u0026quot; (/r/homestuck has a lot of these), and reply with a comment generated with \\u003Ca href=\\\"https://github.com/jsvine/markovify\\\"\\u003Emarkovify\\u003C/a\\u003E. The find_replies() function doesn\\u0026#39;t work at all, sadly, but it\\u0026#39;s intended function is to reply to any comment that replied to the bot\\u0026#39;s comment. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe sad thing is, I want this bot to say MORE things, and I\\u0026#39;m at a loss as to how to do it. I know that putting \\u0026quot;text_model.make_short_sentence(500)\\u0026quot; in the \\u0026quot;submission.add_comment()\\u0026quot; field will make it generate a sentence, but I was hoping it would generate a whole paragraph rather than single sentences. Is this even possible with markovify? \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAlso, the subreddit that I want to use this bot on allows emotes (formatted like \\u0026quot;[](/emote)\\u0026quot;), but as far as I know, markovify only looks at alphanumeric characters in the source text, so generating the brackets and parentheses needed to type an emote just isn\\u0026#39;t possible. Has anyone figured out how to do something like this? Is markovify just a bad program to use for the task I want my bot to perform?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"#DISCLAIMER:\\n\\nThis is literally the first program I have ever written in *any* programming language. I'm pretty proud of it despite its flaws.\\n\\n#The Code:\\n\\n    import praw\\n    import pdb\\n    import re\\n    import os\\n    import time\\n    import markovify\\n    from ConfigBot import *\\n    \\n    \\n    r = praw.Reddit(user_agent = \\\"A chatbot by /u/Gingerale947 that just wants to say stupid things :)\\\")\\n    r.login(REDDIT_USERNAME, REDDIT_PASS)\\n    print(\\\"Logging in...\\\")\\n    \\n    already_read = []\\n    match = [\\\"SHITPOST\\\"]\\n    my_name = [\\\"GAs_ShitPostBot\\\"]\\n    \\n    def run_bot():\\n        print(\\\"Connecting to /r/Homestuck\\\")\\n        subreddit = r.get_subreddit(\\\"\\u003CMy test subreddit\\u003E\\\")\\n        for submission in subreddit.get_hot(limit=5):\\n            if submission.id not in already_read:\\n                r.search('flair:\\\"SHITPOST\\\"', submission.link_flair_text)\\n                if submission.link_flair_text in match:\\n                    print(\\\"Title: \\\", submission.title)\\n                    print(\\\"Text: \\\", submission.selftext)\\n                    print(\\\"Score: \\\", submission.score)\\n                    print(\\\"Author: \\\", submission.author)\\n                    print(submission.link_flair_css_class)\\n                    print(\\\"---------------------------------\\\\n\\\")\\n                    already_read.append(submission.id)\\n                    print(\\\"SHITPOSTING...\\\")\\n                    submission.add_comment(text_model.make_short_sentence(500))\\n                    time.sleep(180)\\n    \\n    def find_replies():\\n        print(\\\"Checking replies\\\")\\n        subreddit = r.get_subreddit(\\\"\\u003CMy test subreddit\\u003E\\\")\\n        comment = subreddit.get_comments(limit=25)\\n        for comment in comments:\\n            comment_text = comment.body.lower()\\n            if comment.parent_id in my_name:\\n                comment.reply(text_model.make_short_sentence(500))\\n                time.sleep(5)\\n    \\n    with open('C:/Users/Ginge/Desktop/GAs_ShitCommentBot/ShitPostComments.txt', encoding=\\\"utf-8\\\") as f:\\n        text = f.read()\\n    \\n    text_model = markovify.Text(text, state_size=1)\\n    \\n    while True:\\n        run_bot()\\n        find_replies()\\n        time.sleep(20)\\n(\\\"\\u003CMy test subreddit\\u003E\\\" isnt actually part of the code its just where I put the name of my test subreddit)\\n\\nThe run_bot() function works perfectly, it's set to find all the posts on a given subreddit that are labeled \\\"SHITPOST\\\" (\\\\/r/homestuck has a lot of these), and reply with a comment generated with [markovify](https://github.com/jsvine/markovify). The find_replies() function doesn't work at all, sadly, but it's intended function is to reply to any comment that replied to the bot's comment. \\n\\nThe sad thing is, I want this bot to say MORE things, and I'm at a loss as to how to do it. I know that putting \\\"text_model.make_short_sentence(500)\\\" in the \\\"submission.add_comment()\\\" field will make it generate a sentence, but I was hoping it would generate a whole paragraph rather than single sentences. Is this even possible with markovify? \\n\\nAlso, the subreddit that I want to use this bot on allows emotes (formatted like \\\"\\\\[](/emote)\\\"), but as far as I know, markovify only looks at alphanumeric characters in the source text, so generating the brackets and parentheses needed to type an emote just isn't possible. Has anyone figured out how to do something like this? Is markovify just a bad program to use for the task I want my bot to perform?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4okv1u\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Gingerale947\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4okv1u/xpost_from_rcritiquemycode_making_a_reddit_bot/\", \"locked\": false, \"name\": \"t3_4okv1u\", \"created\": 1466219579.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4okv1u/xpost_from_rcritiquemycode_making_a_reddit_bot/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"(Xpost from /r/CritiqueMyCode) Making a reddit bot that generates inane and stupid sentences with markov chains, can anyone help me improve it?\", \"created_utc\": 1466190779.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003Ewhen would one justify webscraping instead of using the API?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"when would one justify webscraping instead of using the API?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4okh65\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"fantapeach1\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4okh65/webscraping_vs_api/\", \"locked\": false, \"name\": \"t3_4okh65\", \"created\": 1466214976.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4okh65/webscraping_vs_api/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Webscraping vs API\", \"created_utc\": 1466186176.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHello, I\\u0026#39;m trying to add an attribute (multi) to a class (ListingChooser) in \\u003Ca href=\\\"https://github.com/reddit/reddit/blob/master/r2/r2/lib/pages/pages.py#L5546\\\"\\u003Epages.py\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI changed \\u003Ccode\\u003Eclass ListingChooser(Templated): def __init__(self):\\u003C/code\\u003E to  \\u003Ccode\\u003Eclass ListingChooser(Templated): def __init__(self, multi):\\u003C/code\\u003E but I when I do I get \\u003Ccode\\u003ETypeError: __init__() takes exactly 2 arguments (1 given)\\u003C/code\\u003E. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI fooled around with the few lines of code for the Class ListingChooser in pages.py but wasn\\u0026#39;t able to fix it. I\\u0026#39;ve already defined \\u003Cem\\u003Einit\\u003C/em\\u003E to take 2 arguments, but where  is it only giving the 1 argument instead of the 2 needed?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hello, I'm trying to add an attribute (multi) to a class (ListingChooser) in [pages.py](https://github.com/reddit/reddit/blob/master/r2/r2/lib/pages/pages.py#L5546)\\n\\nI changed `class ListingChooser(Templated): def __init__(self):` to  `class ListingChooser(Templated): def __init__(self, multi):` but I when I do I get `TypeError: __init__() takes exactly 2 arguments (1 given)`. \\n\\nI fooled around with the few lines of code for the Class ListingChooser in pages.py but wasn't able to fix it. I've already defined _init_ to take 2 arguments, but where  is it only giving the 1 argument instead of the 2 needed?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ofttl\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"devnoob23\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ofttl/typeerror_init_takes_exactly_2_arguments_1_given/\", \"locked\": false, \"name\": \"t3_4ofttl\", \"created\": 1466141926.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ofttl/typeerror_init_takes_exactly_2_arguments_1_given/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"\\\"TypeError: __init__() takes exactly 2 arguments (1 given)\\\" when adding an attribute to existing object\", \"created_utc\": 1466113126.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI have a local install of reddit that for some reason has links that are both SSL and Non-SSL.  The links to comment, submit a new post and many others.  Its causing an issue with my SSO implementation.  In my ini I have the scheme set to https but that doesn\\u0026#39;t seem to have any impact.  What controls the build of the pages so the actual href\\u0026#39;s on pages are https:// and not http://\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I have a local install of reddit that for some reason has links that are both SSL and Non-SSL.  The links to comment, submit a new post and many others.  Its causing an issue with my SSO implementation.  In my ini I have the scheme set to https but that doesn't seem to have any impact.  What controls the build of the pages so the actual href's on pages are https:// and not http://\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4oe67r\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"toddh13\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1466094758.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4oe67r/local_install_has_mixed_sslnonssl_links/\", \"locked\": false, \"name\": \"t3_4oe67r\", \"created\": 1466122908.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4oe67r/local_install_has_mixed_sslnonssl_links/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Local install has mixed SSL/non-ssl links\", \"created_utc\": 1466094108.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI am not a developer myself but I was facing a problem . I am using \\u0026quot;redditor\\u0026quot; client on my iPhone up to a week ago when the app started showing \\u0026quot;there doesn\\u0026#39;t seem to be anything here\\u0026quot; on all the subreddits and front page , after investigation I found that the app is getting message \\u0026quot;Request forbidden by administrative rules\\u0026quot; from \\n\\u003Ca href=\\\"https://www.reddit.com/message/unread.json?limit=100\\\"\\u003Ehttps://www.reddit.com/message/unread.json?limit=100\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI am trying to figure out a solution for this problem ? is there anything can be done ?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I am not a developer myself but I was facing a problem . I am using \\\"redditor\\\" client on my iPhone up to a week ago when the app started showing \\\"there doesn't seem to be anything here\\\" on all the subreddits and front page , after investigation I found that the app is getting message \\\"Request forbidden by administrative rules\\\" from \\nhttps://www.reddit.com/message/unread.json?limit=100\\n\\nI am trying to figure out a solution for this problem ? is there anything can be done ?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ocunh\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Maxwell500\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ocunh/request_forbidden_by_administrative_rules/\", \"locked\": false, \"name\": \"t3_4ocunh\", \"created\": 1466105366.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ocunh/request_forbidden_by_administrative_rules/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Request forbidden by administrative rules ?\", \"created_utc\": 1466076566.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cpre\\u003E\\u003Ccode\\u003ESo I\\u0026#39;m completely new at this, I need to program a Reddit Bot using Java. I am using the JRAW and am developing in Netbeans. I use messagedriven beans to communicate with another application, but when I try to create a RedditClient it won\\u0026#39;t work and give me a AccessControlException:\\n\\n*SNIP*\\n\\nHere is the code I use to create the client (pretty straight forward): \\n\\nUserAgent myUserAgent = UserAgent.of(\\u0026quot;desktop\\u0026quot;, \\u0026quot;beans.redditbean\\u0026quot;, \\u0026quot;v0.1\\u0026quot;, \\u0026quot;DPIBot\\u0026quot;);\\nRedditClient redditClient;\\nredditClient = new RedditClient(myUserAgent);    \\n\\nI have absolutely no clue why it won\\u0026#39;t work. I don\\u0026#39;t know if it is a configuration error or if it is just my code. Could someone point me in the right way? \\n\\nI\\u0026#39;m sorry if this isn\\u0026#39;t the place to ask this question. ~~\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003ESolved the above problem, onto a new one. I needed to disable the security manager in my glassfish server. Only now I have a new problem.\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003ECredentials credentials = Credentials.script(\\u0026quot;*username*\\u0026quot;, \\u0026quot;*hunter2(\\u0026quot;, \\u0026quot;stuff\\u0026quot;, \\u0026quot;otherstuff\\u0026quot;);\\n            OAuthData authData = redditClient.getOAuthHelper().easyAuth(credentials);\\n            redditClient.authenticate(authData);\\n            System.out.println(redditClient.me());\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EWhen I run the code above in a simple Java application everything works, but when I use this in a MessageDriven Bean I get the following exception:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EWarning:   MQJMSRA_MR2001: run:Caught Exception from onMessage():Redelivering:\\njavax.ejb.EJBException: message-driven bean method public abstract void javax.jms.MessageListener.onMessage(javax.jms.Message) system exception\\n    at org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1254)\\n    at org.glassfish.ejb.mdb.MessageBeanListenerImpl.deliverMessage(MessageBeanListenerImpl.java:81)\\n    at com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:171)\\n    at com.sun.proxy.$Proxy345.onMessage(Unknown Source)\\n    at com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:283)\\n    at com.sun.enterprise.connectors.work.OneWork.doWork(OneWork.java:107)\\n    at com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.performWork(ThreadPoolImpl.java:497)\\n    at com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.run(ThreadPoolImpl.java:540)\\nCaused by: java.lang.NoSuchMethodError: com.google.common.util.concurrent.RateLimiter.tryAcquire()Z\\n    at net.dean.jraw.http.RestClient.execute(RestClient.java:106)\\n    at net.dean.jraw.RedditClient.execute(RedditClient.java:143)\\n    at net.dean.jraw.RedditClient.execute(RedditClient.java:137)\\n    at net.dean.jraw.http.oauth.OAuthHelper.doScriptApp(OAuthHelper.java:211)\\n    at net.dean.jraw.http.oauth.OAuthHelper.easyAuth(OAuthHelper.java:186)\\n    at service.RedditCommunicate.PostToReddit(RedditCommunicate.java:33)\\n    at beans.RedditBean.onMessage(RedditBean.java:43)\\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    at java.lang.reflect.Method.invoke(Method.java:497)\\n    at org.glassfish.ejb.security.application.EJBSecurityManager.runMethod(EJBSecurityManager.java:1081)\\n    at org.glassfish.ejb.security.application.EJBSecurityManager.invoke(EJBSecurityManager.java:1153)\\n    at com.sun.ejb.containers.BaseContainer.invokeBeanMethod(BaseContainer.java:4786)\\n    at com.sun.ejb.EjbInvocation.invokeBeanMethod(EjbInvocation.java:656)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    at com.sun.ejb.EjbInvocation.proceed(EjbInvocation.java:608)\\n    at org.jboss.weld.ejb.AbstractEJBRequestScopeActivationInterceptor.aroundInvoke(AbstractEJBRequestScopeActivationInterceptor.java:73)\\n    at org.jboss.weld.ejb.SessionBeanInterceptor.aroundInvoke(SessionBeanInterceptor.java:52)\\n    at sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)\\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    at java.lang.reflect.Method.invoke(Method.java:497)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeInterceptor.intercept(InterceptorManager.java:883)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    at com.sun.ejb.containers.interceptors.InterceptorManager.intercept(InterceptorManager.java:369)\\n    at com.sun.ejb.containers.BaseContainer.__intercept(BaseContainer.java:4758)\\n    at com.sun.ejb.containers.BaseContainer.intercept(BaseContainer.java:4746)\\n    at org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1219)\\n    ... 7 more\\n\\nInfo:   MQJMSRA_MR1101: run:Message returned \\u0026amp; marked for routing to the DMQ\\nWarning:   MDB00037: [WebTwitchScraper:RedditBean]: Message-driven bean invocation exception: [javax.ejb.EJBException]\\nWarning:   javax.ejb.EJBException\\njavax.ejb.EJBException\\n    at com.sun.ejb.containers.EJBContainerTransactionManager.processSystemException(EJBContainerTransactionManager.java:750)\\n    at com.sun.ejb.containers.EJBContainerTransactionManager.completeNewTx(EJBContainerTransactionManager.java:700)\\n    at com.sun.ejb.containers.EJBContainerTransactionManager.postInvokeTx(EJBContainerTransactionManager.java:505)\\n    at com.sun.ejb.containers.BaseContainer.postInvokeTx(BaseContainer.java:4566)\\n    at org.glassfish.ejb.mdb.MessageBeanContainer.afterMessageDeliveryInternal(MessageBeanContainer.java:1326)\\n    at org.glassfish.ejb.mdb.MessageBeanContainer.afterMessageDelivery(MessageBeanContainer.java:1301)\\n    at org.glassfish.ejb.mdb.MessageBeanListenerImpl.afterMessageDelivery(MessageBeanListenerImpl.java:86)\\n    at com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:143)\\n    at com.sun.proxy.$Proxy345.afterDelivery(Unknown Source)\\n    at com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:361)\\n    at com.sun.enterprise.connectors.work.OneWork.doWork(OneWork.java:107)\\n    at com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.performWork(ThreadPoolImpl.java:497)\\n    at com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.run(ThreadPoolImpl.java:540)\\nCaused by: java.lang.NoSuchMethodError: com.google.common.util.concurrent.RateLimiter.tryAcquire()Z\\n    at net.dean.jraw.http.RestClient.execute(RestClient.java:106)\\n    at net.dean.jraw.RedditClient.execute(RedditClient.java:143)\\n    at net.dean.jraw.RedditClient.execute(RedditClient.java:137)\\n    at net.dean.jraw.http.oauth.OAuthHelper.doScriptApp(OAuthHelper.java:211)\\n    at net.dean.jraw.http.oauth.OAuthHelper.easyAuth(OAuthHelper.java:186)\\n    at service.RedditCommunicate.PostToReddit(RedditCommunicate.java:33)\\n    at beans.RedditBean.onMessage(RedditBean.java:43)\\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    at java.lang.reflect.Method.invoke(Method.java:497)\\n    at org.glassfish.ejb.security.application.EJBSecurityManager.runMethod(EJBSecurityManager.java:1081)\\n    at org.glassfish.ejb.security.application.EJBSecurityManager.invoke(EJBSecurityManager.java:1153)\\n    at com.sun.ejb.containers.BaseContainer.invokeBeanMethod(BaseContainer.java:4786)\\n    at com.sun.ejb.EjbInvocation.invokeBeanMethod(EjbInvocation.java:656)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    at com.sun.ejb.EjbInvocation.proceed(EjbInvocation.java:608)\\n    at org.jboss.weld.ejb.AbstractEJBRequestScopeActivationInterceptor.aroundInvoke(AbstractEJBRequestScopeActivationInterceptor.java:73)\\n    at org.jboss.weld.ejb.SessionBeanInterceptor.aroundInvoke(SessionBeanInterceptor.java:52)\\n    at sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)\\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    at java.lang.reflect.Method.invoke(Method.java:497)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeInterceptor.intercept(InterceptorManager.java:883)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    at com.sun.ejb.containers.interceptors.InterceptorManager.intercept(InterceptorManager.java:369)\\n    at com.sun.ejb.containers.BaseContainer.__intercept(BaseContainer.java:4758)\\n    at com.sun.ejb.containers.BaseContainer.intercept(BaseContainer.java:4746)\\n    at org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1219)\\n    at org.glassfish.ejb.mdb.MessageBeanListenerImpl.deliverMessage(MessageBeanListenerImpl.java:81)\\n    at com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:171)\\n    at com.sun.proxy.$Proxy345.onMessage(Unknown Source)\\n    at com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:283)\\n    ... 3 more\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EIs this something I need to disable somewhere in my config? I don\\u0026#39;t care about the security since that isn\\u0026#39;t really important in my case.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"    So I'm completely new at this, I need to program a Reddit Bot using Java. I am using the JRAW and am developing in Netbeans. I use messagedriven beans to communicate with another application, but when I try to create a RedditClient it won't work and give me a AccessControlException:\\n\\n    *SNIP*\\n\\n    Here is the code I use to create the client (pretty straight forward): \\n\\n    UserAgent myUserAgent = UserAgent.of(\\\"desktop\\\", \\\"beans.redditbean\\\", \\\"v0.1\\\", \\\"DPIBot\\\");\\n    RedditClient redditClient;\\n    redditClient = new RedditClient(myUserAgent);    \\n\\n    I have absolutely no clue why it won't work. I don't know if it is a configuration error or if it is just my code. Could someone point me in the right way? \\n\\n    I'm sorry if this isn't the place to ask this question. ~~\\n\\nSolved the above problem, onto a new one. I needed to disable the security manager in my glassfish server. Only now I have a new problem.\\n\\n    Credentials credentials = Credentials.script(\\\"*username*\\\", \\\"*hunter2(\\\", \\\"stuff\\\", \\\"otherstuff\\\");\\n    \\t\\t\\tOAuthData authData = redditClient.getOAuthHelper().easyAuth(credentials);\\n    \\t\\t\\tredditClient.authenticate(authData);\\n    \\t\\t\\tSystem.out.println(redditClient.me());\\n\\nWhen I run the code above in a simple Java application everything works, but when I use this in a MessageDriven Bean I get the following exception:\\n\\n    Warning:   MQJMSRA_MR2001: run:Caught Exception from onMessage():Redelivering:\\n    javax.ejb.EJBException: message-driven bean method public abstract void javax.jms.MessageListener.onMessage(javax.jms.Message) system exception\\n    \\tat org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1254)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanListenerImpl.deliverMessage(MessageBeanListenerImpl.java:81)\\n    \\tat com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:171)\\n    \\tat com.sun.proxy.$Proxy345.onMessage(Unknown Source)\\n    \\tat com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:283)\\n    \\tat com.sun.enterprise.connectors.work.OneWork.doWork(OneWork.java:107)\\n    \\tat com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.performWork(ThreadPoolImpl.java:497)\\n    \\tat com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.run(ThreadPoolImpl.java:540)\\n    Caused by: java.lang.NoSuchMethodError: com.google.common.util.concurrent.RateLimiter.tryAcquire()Z\\n    \\tat net.dean.jraw.http.RestClient.execute(RestClient.java:106)\\n    \\tat net.dean.jraw.RedditClient.execute(RedditClient.java:143)\\n    \\tat net.dean.jraw.RedditClient.execute(RedditClient.java:137)\\n    \\tat net.dean.jraw.http.oauth.OAuthHelper.doScriptApp(OAuthHelper.java:211)\\n    \\tat net.dean.jraw.http.oauth.OAuthHelper.easyAuth(OAuthHelper.java:186)\\n    \\tat service.RedditCommunicate.PostToReddit(RedditCommunicate.java:33)\\n    \\tat beans.RedditBean.onMessage(RedditBean.java:43)\\n    \\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n    \\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n    \\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    \\tat java.lang.reflect.Method.invoke(Method.java:497)\\n    \\tat org.glassfish.ejb.security.application.EJBSecurityManager.runMethod(EJBSecurityManager.java:1081)\\n    \\tat org.glassfish.ejb.security.application.EJBSecurityManager.invoke(EJBSecurityManager.java:1153)\\n    \\tat com.sun.ejb.containers.BaseContainer.invokeBeanMethod(BaseContainer.java:4786)\\n    \\tat com.sun.ejb.EjbInvocation.invokeBeanMethod(EjbInvocation.java:656)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    \\tat com.sun.ejb.EjbInvocation.proceed(EjbInvocation.java:608)\\n    \\tat org.jboss.weld.ejb.AbstractEJBRequestScopeActivationInterceptor.aroundInvoke(AbstractEJBRequestScopeActivationInterceptor.java:73)\\n    \\tat org.jboss.weld.ejb.SessionBeanInterceptor.aroundInvoke(SessionBeanInterceptor.java:52)\\n    \\tat sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)\\n    \\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    \\tat java.lang.reflect.Method.invoke(Method.java:497)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeInterceptor.intercept(InterceptorManager.java:883)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    \\tat com.sun.ejb.containers.interceptors.InterceptorManager.intercept(InterceptorManager.java:369)\\n    \\tat com.sun.ejb.containers.BaseContainer.__intercept(BaseContainer.java:4758)\\n    \\tat com.sun.ejb.containers.BaseContainer.intercept(BaseContainer.java:4746)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1219)\\n    \\t... 7 more\\n    \\n    Info:   MQJMSRA_MR1101: run:Message returned \\u0026 marked for routing to the DMQ\\n    Warning:   MDB00037: [WebTwitchScraper:RedditBean]: Message-driven bean invocation exception: [javax.ejb.EJBException]\\n    Warning:   javax.ejb.EJBException\\n    javax.ejb.EJBException\\n    \\tat com.sun.ejb.containers.EJBContainerTransactionManager.processSystemException(EJBContainerTransactionManager.java:750)\\n    \\tat com.sun.ejb.containers.EJBContainerTransactionManager.completeNewTx(EJBContainerTransactionManager.java:700)\\n    \\tat com.sun.ejb.containers.EJBContainerTransactionManager.postInvokeTx(EJBContainerTransactionManager.java:505)\\n    \\tat com.sun.ejb.containers.BaseContainer.postInvokeTx(BaseContainer.java:4566)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanContainer.afterMessageDeliveryInternal(MessageBeanContainer.java:1326)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanContainer.afterMessageDelivery(MessageBeanContainer.java:1301)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanListenerImpl.afterMessageDelivery(MessageBeanListenerImpl.java:86)\\n    \\tat com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:143)\\n    \\tat com.sun.proxy.$Proxy345.afterDelivery(Unknown Source)\\n    \\tat com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:361)\\n    \\tat com.sun.enterprise.connectors.work.OneWork.doWork(OneWork.java:107)\\n    \\tat com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.performWork(ThreadPoolImpl.java:497)\\n    \\tat com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.run(ThreadPoolImpl.java:540)\\n    Caused by: java.lang.NoSuchMethodError: com.google.common.util.concurrent.RateLimiter.tryAcquire()Z\\n    \\tat net.dean.jraw.http.RestClient.execute(RestClient.java:106)\\n    \\tat net.dean.jraw.RedditClient.execute(RedditClient.java:143)\\n    \\tat net.dean.jraw.RedditClient.execute(RedditClient.java:137)\\n    \\tat net.dean.jraw.http.oauth.OAuthHelper.doScriptApp(OAuthHelper.java:211)\\n    \\tat net.dean.jraw.http.oauth.OAuthHelper.easyAuth(OAuthHelper.java:186)\\n    \\tat service.RedditCommunicate.PostToReddit(RedditCommunicate.java:33)\\n    \\tat beans.RedditBean.onMessage(RedditBean.java:43)\\n    \\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n    \\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n    \\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    \\tat java.lang.reflect.Method.invoke(Method.java:497)\\n    \\tat org.glassfish.ejb.security.application.EJBSecurityManager.runMethod(EJBSecurityManager.java:1081)\\n    \\tat org.glassfish.ejb.security.application.EJBSecurityManager.invoke(EJBSecurityManager.java:1153)\\n    \\tat com.sun.ejb.containers.BaseContainer.invokeBeanMethod(BaseContainer.java:4786)\\n    \\tat com.sun.ejb.EjbInvocation.invokeBeanMethod(EjbInvocation.java:656)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    \\tat com.sun.ejb.EjbInvocation.proceed(EjbInvocation.java:608)\\n    \\tat org.jboss.weld.ejb.AbstractEJBRequestScopeActivationInterceptor.aroundInvoke(AbstractEJBRequestScopeActivationInterceptor.java:73)\\n    \\tat org.jboss.weld.ejb.SessionBeanInterceptor.aroundInvoke(SessionBeanInterceptor.java:52)\\n    \\tat sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)\\n    \\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    \\tat java.lang.reflect.Method.invoke(Method.java:497)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeInterceptor.intercept(InterceptorManager.java:883)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    \\tat com.sun.ejb.containers.interceptors.InterceptorManager.intercept(InterceptorManager.java:369)\\n    \\tat com.sun.ejb.containers.BaseContainer.__intercept(BaseContainer.java:4758)\\n    \\tat com.sun.ejb.containers.BaseContainer.intercept(BaseContainer.java:4746)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1219)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanListenerImpl.deliverMessage(MessageBeanListenerImpl.java:81)\\n    \\tat com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:171)\\n    \\tat com.sun.proxy.$Proxy345.onMessage(Unknown Source)\\n    \\tat com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:283)\\n    \\t... 3 more\\n    \\n\\nIs this something I need to disable somewhere in my config? I don't care about the security since that isn't really important in my case.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ocqfu\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"HenkDeVries013\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1466079236.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ocqfu/java_jraw_exception_while_instantiating_new/\", \"locked\": false, \"name\": \"t3_4ocqfu\", \"created\": 1466103087.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ocqfu/java_jraw_exception_while_instantiating_new/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[Java] [JRAW] Exception while instantiating new RedditClient\", \"created_utc\": 1466074287.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": null, \"selftext\": \"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ocq9v\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Le_9k_Redditor\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ocq9v/is_there_an_easy_praw_function_to_fetch_all/\", \"locked\": false, \"name\": \"t3_4ocq9v\", \"created\": 1466102992.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ocq9v/is_there_an_easy_praw_function_to_fetch_all/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Is there an easy praw function to fetch all comments from permalink/context url?\", \"created_utc\": 1466074192.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI am a Redditor who is also a Voater and I\\u0026#39;ve noticed that Voat has lots of checks when you either login or create an account, especially the image CAPTCHA checks, whereas Reddit just allows one to click a few buttons and register.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHow does Reddit ensure that a crawler or a bot doesn\\u0026#39;t programmatically register all the usernames, or cause a DDOS?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I am a Redditor who is also a Voater and I've noticed that Voat has lots of checks when you either login or create an account, especially the image CAPTCHA checks, whereas Reddit just allows one to click a few buttons and register.\\n\\nHow does Reddit ensure that a crawler or a bot doesn't programmatically register all the usernames, or cause a DDOS?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4oc66k\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"prahladyeri\", \"media\": null, \"score\": 9, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 10, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4oc66k/what_does_reddit_use_for_ddos_protection/\", \"locked\": false, \"name\": \"t3_4oc66k\", \"created\": 1466091056.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4oc66k/what_does_reddit_use_for_ddos_protection/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"What does Reddit use for DDOS protection?\", \"created_utc\": 1466062256.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 9}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EOkay so I\\u0026#39;m completely new to scripting and I\\u0026#39;d like to create bot that I can run from my raspberry pi(2). web based or something like that. It\\u0026#39;s purpose will be to post about twice a week to a clan recruiting subreddit. But I have no idea where to start.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECould someone help me out?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Okay so I'm completely new to scripting and I'd like to create bot that I can run from my raspberry pi(2). web based or something like that. It's purpose will be to post about twice a week to a clan recruiting subreddit. But I have no idea where to start.\\n\\nCould someone help me out?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4o9vqm\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"SnowFreak_\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 8, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4o9vqm/creating_a_auto_posting_bot_for_reddit/\", \"locked\": false, \"name\": \"t3_4o9vqm\", \"created\": 1466055973.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4o9vqm/creating_a_auto_posting_bot_for_reddit/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Creating a auto posting bot for reddit\", \"created_utc\": 1466027173.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo, in trying to get the reddit open source stack deployed with the install-reddit.sh script on Ubuntu, I had to go in to the cassandra config and tweak a bit. It initially wouldn\\u0026#39;t start due to stack size and that was relatively straightfoward to \\u0026quot;fix\\u0026quot;, but left me wondering what the \\u0026quot;typical\\u0026quot; config is out there for people running the reddit stack (outside the massively scaled environment of reddit.com)  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThings like rpc_max_threads, MAX_HEAP_SIZE, the java memory config, and so forth. There\\u0026#39;s some \\u0026quot;automatic\\u0026quot; sizing stuff in cassandra-env.sh but again, somehow that didn\\u0026#39;t do the magic. Google search reveals interesting \\u003Cem\\u003Eleads\\u003C/em\\u003E, but it seems much more straightforward to just ask:  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u0026quot;Hey, what does your cassandra configuration look like?\\u0026quot; \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So, in trying to get the reddit open source stack deployed with the install-reddit.sh script on Ubuntu, I had to go in to the cassandra config and tweak a bit. It initially wouldn't start due to stack size and that was relatively straightfoward to \\\"fix\\\", but left me wondering what the \\\"typical\\\" config is out there for people running the reddit stack (outside the massively scaled environment of reddit.com)  \\n \\nThings like rpc_max_threads, MAX_HEAP_SIZE, the java memory config, and so forth. There's some \\\"automatic\\\" sizing stuff in cassandra-env.sh but again, somehow that didn't do the magic. Google search reveals interesting *leads*, but it seems much more straightforward to just ask:  \\n\\n\\\"Hey, what does your cassandra configuration look like?\\\" \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4o95x7\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"L0AD_M0RE_C0MMENTS\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4o95x7/cassandra_optimal_singleserver_config/\", \"locked\": false, \"name\": \"t3_4o95x7\", \"created\": 1466047872.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4o95x7/cassandra_optimal_singleserver_config/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Cassandra \\\"optimal\\\" single-server config?\", \"created_utc\": 1466019072.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi, I\\u0026#39;m currently working on \\u003Ca href=\\\"http://www.saywhat.lol\\\"\\u003Ewww.saywhat.lol\\u003C/a\\u003E and one of our top priorities is getting links shared from our site to preview and autoplay on reddit (like the ones from imgur do). We\\u0026#39;ve followed all the instructions but we still can\\u0026#39;t get them to work. Here\\u0026#39;s a sample url to share a gif: \\u003Ca href=\\\"https://saywhat.lol/share-gif?id=the%20simpsons-s06e18-43\\u0026amp;st=206244\\u0026amp;d=3598\\\"\\u003Ehttps://saywhat.lol/share-gif?id=the%20simpsons-s06e18-43\\u0026amp;st=206244\\u0026amp;d=3598\\u003C/a\\u003E We do not even see reddit hitting our oembed endpoint to generate a preview. Any pointers as to what we may be doing wrong will be greatly appreciated.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi, I'm currently working on www.saywhat.lol and one of our top priorities is getting links shared from our site to preview and autoplay on reddit (like the ones from imgur do). We've followed all the instructions but we still can't get them to work. Here's a sample url to share a gif: https://saywhat.lol/share-gif?id=the%20simpsons-s06e18-43\\u0026st=206244\\u0026d=3598 We do not even see reddit hitting our oembed endpoint to generate a preview. Any pointers as to what we may be doing wrong will be greatly appreciated.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4o7ng3\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"elibud\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 7, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4o7ng3/getting_gifs_and_mp4_videos_to_autoplay/\", \"locked\": false, \"name\": \"t3_4o7ng3\", \"created\": 1466030751.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4o7ng3/getting_gifs_and_mp4_videos_to_autoplay/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Getting gifs and mp4 videos to autoplay\", \"created_utc\": 1466001951.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo I\\u0026#39;ve been trying to make a bot with the \\u003Ca href=\\\"https://github.com/jcleblanc/reddit-php-sdk\\\"\\u003Ereddit php api\\u003C/a\\u003E, but I can\\u0026#39;t seem to get it working.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;ve created a personal script app on reddit, entered the client id and client secret in the config.php, but I can\\u0026#39;t do anything. The reply I get for any action I do is an empty string.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe code I am using to try to submit something is this:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Erequire_once(\\u0026#39;reddit.php\\u0026#39;);\\n$reddit = new reddit();\\n\\n$title = \\u0026#39;Test of my bot\\u0026#39;;\\n$link = \\u0026#39;http://example.com/\\u0026#39;;\\n$subreddit = \\u0026#39;test\\u0026#39;;\\n$response = $reddit-\\u0026gt;createStory($title, $link, $subreddit);\\necho $response . \\u0026quot;\\\\n\\u0026quot;;\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAny help would be appreciated.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So I've been trying to make a bot with the [reddit php api](https://github.com/jcleblanc/reddit-php-sdk), but I can't seem to get it working.\\n\\nI've created a personal script app on reddit, entered the client id and client secret in the config.php, but I can't do anything. The reply I get for any action I do is an empty string.\\n\\nThe code I am using to try to submit something is this:\\n\\n    require_once('reddit.php');\\n    $reddit = new reddit();\\n    \\n    $title = 'Test of my bot';\\n    $link = 'http://example.com/';\\n    $subreddit = 'test';\\n    $response = $reddit-\\u003EcreateStory($title, $link, $subreddit);\\n    echo $response . \\\"\\\\n\\\";\\n\\nAny help would be appreciated.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4o703d\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"itchyDoggy\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4o703d/help_with_the_reddit_php_api/\", \"locked\": false, \"name\": \"t3_4o703d\", \"created\": 1466021688.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4o703d/help_with_the_reddit_php_api/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Help with the reddit php api\", \"created_utc\": 1465992888.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHey guys, I just graduated college with a double major in Bio and Economics and I am heading in to the finance field; specifically focusing on telecom, data, and cloud firms.  Turns out you don\\u0026#39;t learn much about technology in either of those fields.  One of the things I am trying to learn are the basics of tech including APIs, SaaS, CPaaS, and basic Cloud Services.  Could y\\u0026#39;all direct me to the right sub where I could learn about these things? I found this sub after trying to scan Reddit trying to learn about APIs and their functions.  \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hey guys, I just graduated college with a double major in Bio and Economics and I am heading in to the finance field; specifically focusing on telecom, data, and cloud firms.  Turns out you don't learn much about technology in either of those fields.  One of the things I am trying to learn are the basics of tech including APIs, SaaS, CPaaS, and basic Cloud Services.  Could y'all direct me to the right sub where I could learn about these things? I found this sub after trying to scan Reddit trying to learn about APIs and their functions.  \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4o3uxy\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"3oh3banker\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4o3uxy/help_with_basic_tech_understanding/\", \"locked\": false, \"name\": \"t3_4o3uxy\", \"created\": 1465969208.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4o3uxy/help_with_basic_tech_understanding/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Help with basic Tech understanding?\", \"created_utc\": 1465940408.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHere\\u0026#39;s what he told me:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u0026quot; It\\u0026#39;s   installed fine (apparently) and you can register, but that\\u0026#39;s about it. When you try to create a subreddit, for example, it gives this nasty error:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ENotImplementedError: Action u\\u0026#39;POST_submit\\u0026#39; is not implemented\\nWhich seems pretty odd. Debugging output is whargarble to me as it\\u0026#39;s just too specific to what\\u0026#39;s going on with this code, and google searches for that error seem to be about other servers/services.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAlso, the Submit a new... form won\\u0026#39;t let you select Text, AND the Create button for Link posts doesn\\u0026#39;t seem to trigger / \\u0026quot;do anything\\u0026quot; either. Just discovered that attempting to comment gives a similar \\u0026quot;post not implemented\\u0026quot; error that\\u0026#39;s visible via firebug.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAnyone have insight / clue / pointers / experience? If it were just Java, or just front-end / js code, or just SQL, I might have a fighting chance... but with all this fucking cassandra, rabbit, memcache stuff that I don\\u0026#39;t have experience with... whew. I don\\u0026#39;t know where to look.\\u0026quot;\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Here's what he told me:\\n\\n\\\" It's   installed fine (apparently) and you can register, but that's about it. When you try to create a subreddit, for example, it gives this nasty error:\\n\\nNotImplementedError: Action u'POST_submit' is not implemented\\nWhich seems pretty odd. Debugging output is whargarble to me as it's just too specific to what's going on with this code, and google searches for that error seem to be about other servers/services.\\n\\nAlso, the Submit a new... form won't let you select Text, AND the Create button for Link posts doesn't seem to trigger / \\\"do anything\\\" either. Just discovered that attempting to comment gives a similar \\\"post not implemented\\\" error that's visible via firebug.\\n\\nAnyone have insight / clue / pointers / experience? If it were just Java, or just front-end / js code, or just SQL, I might have a fighting chance... but with all this fucking cassandra, rabbit, memcache stuff that I don't have experience with... whew. I don't know where to look.\\\"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4nzcwh\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Francois_Rapiste\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 28, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4nzcwh/friend_of_mine_is_trying_to_create_a_reddit_clone/\", \"locked\": false, \"name\": \"t3_4nzcwh\", \"created\": 1465901453.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4nzcwh/friend_of_mine_is_trying_to_create_a_reddit_clone/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Friend of mine is trying to create a Reddit clone. Help?\", \"created_utc\": 1465872653.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m playing around with the reddit api using the \\u003Ca href=\\\"https://github.com/jcleblanc/reddit-php-sdk\\\"\\u003EReddit php skd\\u003C/a\\u003E and i want to make it so that i don\\u0026#39;t need to authorize every hour, like i need to do now.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks for any help!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm playing around with the reddit api using the [Reddit php skd](https://github.com/jcleblanc/reddit-php-sdk) and i want to make it so that i don't need to authorize every hour, like i need to do now.\\n\\nThanks for any help!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4nvak7\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"theo65_theo01\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 8, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4nvak7/reddit_php_sdk_can_i_make_it_so_that_i_dont_need/\", \"locked\": false, \"name\": \"t3_4nvak7\", \"created\": 1465848165.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4nvak7/reddit_php_sdk_can_i_make_it_so_that_i_dont_need/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Reddit PHP SDK - Can i make it so that I don't need to authorize every hour?\", \"created_utc\": 1465819365.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EPRAW version is 3.5.0, I am 100% certain this is the issue. \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"PRAW version is 3.5.0, I am 100% certain this is the issue. \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4nu8x1\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"thirdegree\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 5, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4nu8x1/praw_edit_wiki_page_raising_forbidden_when/\", \"locked\": false, \"name\": \"t3_4nu8x1\", \"created\": 1465824771.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4nu8x1/praw_edit_wiki_page_raising_forbidden_when/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"PRAW edit_wiki_page raising Forbidden when content is larger than 5120 chars\", \"created_utc\": 1465795971.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}], \"after\": \"t3_4nu8x1\", \"before\": null}}"
        },
        "headers": {
          "CF-RAY": "2c3e929039ae0673-LAX",
          "Connection": "keep-alive",
          "Content-Type": "application/json; charset=UTF-8",
          "Date": "Sun, 17 Jul 2016 15:02:02 GMT",
          "Server": "cloudflare-nginx",
          "Strict-Transport-Security": "max-age=15552000; includeSubDomains; preload",
          "Transfer-Encoding": "chunked",
          "Vary": "accept-encoding",
          "X-Moose": "majestic",
          "cache-control": "private, s-maxage=0, max-age=0, must-revalidate",
          "expires": "-1",
          "x-content-type-options": "nosniff",
          "x-frame-options": "SAMEORIGIN",
          "x-ratelimit-remaining": "598.0",
          "x-ratelimit-reset": "479",
          "x-ratelimit-used": "2",
          "x-reddit-tracking": "https://pixel.redditmedia.com/pixel/of_destiny.png?v=rBKgewfdX%2B89%2BLjjpa%2Fli38cr0u%2BVDO0zwLqzMju6awz5DuKJ4HDxy443h6okdTIFHpcjoK0%2BhjC%2Fbvx%2BgrtdLa58z5qF8KP",
          "x-ua-compatible": "IE=edge",
          "x-xss-protection": "1; mode=block"
        },
        "status": {
          "code": 200,
          "message": "OK"
        },
        "url": "https://oauth.reddit.com/user/<USERNAME>/m/praw_renamed/new?raw_json=1&limit=100"
      }
    }
  ],
  "recorded_with": "betamax/0.7.1"
}
